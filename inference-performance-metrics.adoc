:_module-type: CONCEPT

[id="inference-performance-metrics_{context}"]
= Inference performance metrics
[role="_abstract"]

*Latency*, *throughput* and *cost per million tokens* are key metrics to consider when evaluating the response generation efficiency of a model during inferencing.

*Latency* is critical for real-time performance, and is measured using the following metrics:

* *Time-to-First-Token (TTFT)*: The delay in milliseconds between the initial request and the generation of the first token. This metric is important for streaming responses.
* *Inter-Token Latency (ITL)*: The time taken in milliseconds to generate each subsequent token after the first, also relevant for streaming.
* *Time-Per-Output-Token (TPOT)*: For non-streaming requests, the average time taken in milliseconds to generate each token in an output sequence.

*Throughput* measures the overall efficiency of a model server and is expressed with the following metrics:

* *Tokens per Second (TPS)*: The total number of tokens generated per second across all active requests.
* *Requests per Second (RPS)*: The number of requests processed per second. Note that RPS, like response time, is sensitive to sequence length.

*Cost per Million Tokens* measures the cost-effectiveness of a model's inference, indicating the expense incurred per million tokens generated. This metric helps to assess both the economic feasibility and scalability of deploying the model.


These metrics combined provide a comprehensive view of a modelâ€™s inference performance and can help balance speed, efficiency, and cost for different use cases.


//[role="_additional-resources"]
//.Additional resources
