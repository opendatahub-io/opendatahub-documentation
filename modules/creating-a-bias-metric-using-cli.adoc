:_module-type: PROCEDURE

[id='creating-a-bias-metric-using-cli_{context}']
= Creating a bias metric by using the CLI

[role='_abstract']
The following procedure describes how to use the OpenShift command-line interface (CLI) to create a bias metric for a model.

//The example in this procedure is from the demo here: https://github.com/trustyai-explainability/odh-trustyai-demos/tree/main/2-BiasMonitoring

.Prerequisites

ifndef::upstream[]
* You are familiar with link:{rhoaidocshome}{default-format-url}/monitoring_data_science_models/supported-bias-metrics_monitor[the bias metrics that {productname-short} supports] and how to interpret them.
endif::[]
ifdef::upstream[]
* You are familiar with link:{odhdocshome}/monitoring-data-science-models/#supported-bias-metrics_monitor[the bias metrics that {productname-short} supports] and how to interpret them.
endif::[]

* You are familiar with the specific data set schema and understand the names and meanings of the inputs and outputs.

* Your OpenShift cluster administrator has installed {productname-short} and enabled the TrustyAI service for the data science project where the models are deployed.

* You installed the OpenShift command line interface (`oc`) as described in link:https://docs.openshift.com/container-platform/{ocp-latest-version}/cli_reference/openshift_cli/getting-started-cli.html[Get Started with the CLI].

ifndef::upstream[]
* You have a user token for authentication as described in link:{rhoaidocshome}{default-format-url}/monitoring_data_science_models/authenticating-trustyai-service_monitor[Authenticating the TrustyAI service].
* You have sent training data to your models as described in link:{rhoaidocshome}{default-format-url}/monitoring_data_science_models/sending-training-data-to-a-model_monitor[Sending training data to a model].
endif::[]
ifdef::upstream[]
* You have a user token for authentication as described in link:{odhdocshome}/monitoring-data-science-models/#authenticating-trustyai-service_monitor[Authenticating the TrustyAI service].
* You have sent training data to your models as described in link:{odhdocshome}/monitoring-data-science-models/#sending-training-data-to-a-model_monitor[Sending training data to a model].
endif::[]

.Procedure

. In a terminal window, log in to the OpenShift cluster where {productname-short} is deployed.
+
----
oc login
----

. Set the `TRUSTY_ROUTE` variable to the external route for the TrustyAI service pod.
+
----
TRUSTY_ROUTE=https://$(oc get route/trustyai-service --template={{.spec.host}})
----

.  Optionally, get the full list of TrustyAI service endpoints and payloads.
+
----
curl -H "Authorization: Bearer $TOKEN" --location $TRUSTY_ROUTE/q/openapi
----

. Configure bias metrics by running a command that uses the following syntax and payload structure:
+
*Syntax*:
+
----
curl -sk -H "Authorization: Bearer $TOKEN" -X POST --location $TRUSTY_ROUTE/metrics/spd/request \
 --header 'Content-Type: application/json' \
 --data <payload>
----
+
*Payload structure*:

`modelId`:: The name of the model to query.
`protectedAttribute`:: The name of the feature that distinguishes the groups that you are checking for fairness.
`privilegedAttribute`:: The suspected favored (positively biased) class.
`unprivilegedAttribute`:: The suspected unfavored (negatively biased) class.
`outcomeName`:: The name of the output that provides the output you are examining for fairness.
`favorableOutcome`:: The value of the `outcomeName` output that describes the favorable or desired model prediction.
`batchSize`:: The number of previous inferences to include in the calculation.

For example:

----
curl -sk -H "Authorization: Bearer $TOKEN" -X POST --location $TRUSTY_ROUTE/metrics/group/fairness/spd/ \
     --header 'Content-Type: application/json' \
     --data "{
                 \"modelId\": \"demo-loan-nn-onnx-alpha\",
                 \"protectedAttribute\": \"Is Male-Identifying?\",
                 \"privilegedAttribute\": 1.0,
                 \"unprivilegedAttribute\": 0.0,
                 \"outcomeName\": \"Will Default?\",
                 \"favorableOutcome\": 0,
                 \"batchSize\": 5000
             }"
----

.Verification

The bias metrics request should return output similar to the following:

----
{
   "timestamp":"2023-10-24T12:06:04.586+00:00",
   "type":"metric",
   "value":-0.0029676404469311524,
   "namedValues":null,
   "specificDefinition":"The SPD of -0.002968 indicates that the likelihood of Group:Is Male-Identifying?=1.0 receiving Outcome:Will Default?=0 was -0.296764 percentage points lower than that of Group:Is Male-Identifying?=0.0.",
   "name":"SPD",
   "id":"d2707d5b-cae9-41aa-bcd3-d950176cbbaf",
   "thresholds":{"lowerBound":-0.1,"upperBound":0.1,"outsideBounds":false}
}
----

The `specificDefinition` field is useful in understanding the real-world interpretation of these metric values. For this example, the model is quite fair over the `Is Male-Identifying?` field, with the rate of positive outcome only differing by approximately -0.3%.
