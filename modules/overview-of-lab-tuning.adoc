:_module-type: CONCEPT

[id='overview-of-lab-tuning_{context}']
= Overview of LAB-tuning

[role='_abstract']

ifndef::upstream[]
[IMPORTANT]
====
ifdef::self-managed[]
LAB-tuning is currently available in {productname-long} {vernum} as a Technology Preview feature.
endif::[]
ifdef::cloud-service[]
LAB-tuning is currently available in {productname-long} as a Technology Preview feature.
endif::[]
Technology Preview features are not supported with {org-name} production service level agreements (SLAs) and might not be functionally complete.
{org-name} does not recommend using them in production.
These features provide early access to upcoming product features, enabling customers to test functionality and provide feedback during the development process.

For more information about the support scope of {org-name} Technology Preview features, see link:https://access.redhat.com/support/offerings/techpreview/[Technology Preview Features Support Scope].
====
endif::[]

You can use LAB-tuning in {productname-short} to run an end-to-end workflow for customizing large language models (LLMs). The link:https://arxiv.org/abs/2403.01081[LAB (Large-scale Alignment for chatBots)] method offers a more efficient alternative to traditional fine-tuning by combining taxonomy-guided synthetic data generation (SDG) with a multi-phase training process. You can run LAB-tuning workflows directly from the {productname-short} dashboard using the preconfigured InstructLab pipeline, which simplifies the tuning process.

LAB-tuning provides the following benefits:

* Create LLMs that reflect your domain-specific knowledge.
* Automatically generate high-quality training data from a structured taxonomy.
* Fine-tune models faster with a streamlined, multi-phase training process.
* Improve performance and scalability by running training as distributed workloads across the cluster.
* Run the entire workflow securely within {productname-short}.

== LAB-tuning workflow
LAB-tuning simplifies model customization through the preconfigured InstructLab pipeline, which follows this workflow:

. Your structured taxonomy defines the knowledge and skills the model should learn.
. A teacher model uses the taxonomy to generate synthetic training data.
. A judge model reviews and scores the synthetic data to ensure quality.
. The synthetic data is used to fine-tune a base model through a multi-phase training pipeline.

The result is a fine-tuned model that you can version, review, and deploy from the model registry.

== Model customization page

ifndef::upstream[]
* You can use the *Models* -> *Model customization* page in {productname-short} to guide you through the LAB-tuning process. To view the *Model customization* page, your cluster administrator must configure LAB-tuning in your cluster, as described in link:{rhoaidocshome}{default-format-url}/enabling_lab-tuning/index[Enabling LAB-tuning].
endif::[]
ifdef::upstream[]
* You can use the *Models* -> *Model customization* page in {productname-short} to guide you through the LAB-tuning process. To view the *Model customization* page, your cluster administrator must configure LAB-tuning in your cluster, as described in link:{odhdocshome}/customizing-models-with-lab-tuning/#enabling-lab-tuning_lab-tuning[Enabling LAB-tuning].
endif::[]

To use LAB-tuning, complete the following tasks:

* Create a taxonomy in a Git repository.
* Prepare an OCI storage location for the LAB-tuned model.
* Create a data science project and configure its pipeline server.
* Deploy the teacher and judge models.

Then, use LAB-tuning to customize a model by completing following tasks:

* Register a base model from the model catalog.
* Start a LAB-tuning run from the registered model.
* Monitor the run's progress.
* Review and deploy the tuned model from the registry.
