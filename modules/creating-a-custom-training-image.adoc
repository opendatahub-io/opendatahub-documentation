:_module-type: PROCEDURE

[id='creating-a-custom-training-image_{context}']
= Creating a custom training image

You can create a custom training image by adding packages to a base training image.

.Prerequisites

* You can access the training image that you have chosen to use as the base for your custom image. 
+
Select the image based on the _image type_ (for example, Ray or Kubeflow Training Operator), the _accelerator framework_ (for example, CUDA for NVIDIA GPUs, or ROCm for AMD GPUs), and the _Python version_ (for example, 3.9 or 3.11).
+
The following table shows some example base training images:
+
.Example base training images
[cols="7%,15%,10%,33%,35%"]
|===
| Image type | Accelerator framework | Python version | Example base training image | Preinstalled packages

| Ray
| CUDA
| 3.9
| `ray:2.35.0-py39-cu121`
| Ray 2.35.0, Python 3.9, CUDA 12.1

| Ray
| CUDA
| 3.11
| `ray:2.46.0-py311-cu121`
| Ray 2.46.0, Python 3.11, CUDA 12.1

| Ray
| ROCm
| 3.9
| `ray:2.35.0-py39-rocm62`
| Ray 2.35.0, Python 3.9, ROCm 6.2

| Ray
| ROCm
| 3.11
| `ray:2.46.0-py311-rocm62`
| Ray 2.46.0, Python 3.11, ROCm 6.2

| KFTO
| CUDA
| 3.11
| `training:py311-cuda124-torch251`
| Python 3.11, CUDA 12.4, PyTorch 2.5.1

| KFTO
| ROCm
| 3.11
| `training:py311-rocm62-torch251`
| Python 3.11, ROCm 6.2, PyTorch 2.5.1

|===

ifndef::upstream[]
+
For a complete list of the {productname-short} base training images and their preinstalled packages, see link:https://access.redhat.com/articles/rhoai-supported-configs[Supported Configurations].
endif::[]

* You have Podman installed in your local environment, and you can access a container registry.
+
For more information about Podman and container registries, see link:https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/9/html/building_running_and_managing_containers/index[Building, running, and managing containers].


.Procedure

. In a terminal window, create a directory for your work, and change to that directory. 

. Set the `IMG` environment variable to the name of your custom image.
In the example commands in this section, `my_training_image` is the name of the custom image.
+
[source,subs="+quotes"]
----
export IMG=my_training_image
----

. Create a file named `Dockerfile` with the following content:

.. Use the `FROM` instruction to specify the location of a suitable base training image.
+
In the following command, replace `_<base-training-image>_` with the name of your chosen base training image:
+
[source,subs="+quotes"]
----
FROM quay.io/modh/__<base-training-image>__
----
+
Examples:
+
[source,bash]
----
FROM quay.io/modh/ray:2.46.0-py311-cu121
----
+
[source,bash]
----
FROM quay.io/modh/training:py311-rocm62-torch251
----

.. Use the `RUN` instruction to install additional packages.
You can also add comments to the Dockerfile by prefixing each comment line with a number sign (`#`).
+
The following example shows how to install a specific version of the Python PyTorch package:
+
[source,bash]
----
# Install PyTorch
RUN python3 -m pip install torch==2.5.1
----


. Build the image file. 
Use the `-t` option with the `podman build` command to create an image tag that specifies the custom image name and version, to make it easier to reference and manage the image: 
+
[source,subs="+quotes"]
----
podman build -t _<custom-image-name>_:_<version>_ -f Dockerfile
----
+
Example:
+
[source,bash]
----
podman build -t ${IMG}:0.0.1 -f Dockerfile
----
+
The build output indicates when the build process is complete.

. Display a list of your images:
+
[source,subs="+quotes"]
----
podman images
----
+
If your new image was created successfully, it is included in the list of images.

. Push the image to your container registry:
+
[source,bash]
----
podman push ${IMG}:0.0.1
----

ifndef::upstream[]
. Optional: Make your new image available to other users, as described in link:{rhoaidocshome}{default-format-url}/working_with_distributed_workloads/preparing-the-distributed-training-environment_distributed-workloads#pushing-an-image-to-the-integrated-openshift-image-registry_distributed-workloads[Pushing an image to the integrated OpenShift image registry].
endif::[]
ifdef::upstream[]
. Optional: Make your new image available to other users, as described in link:{odhdocshome}/working-with-distributed-workloads/#pushing-an-image-to-the-integrated-openshift-image-registry_distributed-workloads[Pushing an image to the integrated OpenShift image registry].
endif::[]