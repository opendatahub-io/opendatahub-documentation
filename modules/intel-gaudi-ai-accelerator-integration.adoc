:_module-type: CONCEPT

[id='intel-gaudi-ai-accelerator-integration_{context}']
= Intel Gaudi AI Accelerator integration

[role='_abstract']
To accelerate your high-performance deep learning (DL) models, you can integrate Intel® Gaudi® AI accelerators in {productname-short}. {productname-short} also includes the HabanaAI workbench image, which is pre-built and ready for your data scientists to use after you install or upgrade {productname-short}. 

Before you can enable Intel Gaudi AI accelerators in {productname-short}, you must install the necessary dependencies and the version of the HabanaAI Operator that matches the Habana version of the HabanaAI workbench image in your deployment. This allows your data scientists to use Habana libraries and software associated with Intel Gaudi AI accelerators from their workbench. 

For more information about how to enable your OpenShift environment for Intel Gaudi AI accelerators, see link:https://docs.habana.ai/en/v1.10.0/Orchestration/HabanaAI_Operator/index.html[HabanaAI Operator v1.10 for OpenShift] and link:https://docs.habana.ai/en/v1.13.0/Orchestration/HabanaAI_Operator/index.html[HabanaAI Operator v1.13 for OpenShift].

[IMPORTANT]
====
Currently, Intel Gaudi AI Accelerator integration is only supported in OpenShift {ocp-minimum-version}. 

You can use Intel Gaudi AI accelerators on {productname-short} with versions 1.10.0 and 1.13.0 of the Habana AI Operator. The version of the HabanaAI Operator that you install must match the Habana version of the HabanaAI workbench image in your deployment. This means that only one version of HabanaAI workbench image will work for you at a time.

For information about the supported configurations for versions 1.10 and 1.13 of the Habana AI Operator, see link:https://docs.habana.ai/en/latest/Support_Matrix/Support_Matrix_v1.10.0.html#support-matrix-1-10-0[Support Matrix v1.10.0] and link:https://docs.habana.ai/en/latest/Support_Matrix/Support_Matrix_v1.13.0.html#support-matrix-1-13-0[Support Matrix v1.13.0].
====

You can use Intel Gaudi AI accelerators in an Amazon EC2 DL1 instance on OpenShift. Therefore, your OpenShift platform must support EC2 DL1 instances. Intel Gaudi AI accelerators are available to your data scientists when they create a workbench instance or serve a model.

To identify the Intel Gaudi AI accelerators present in your deployment, use the `lspci` utility. For more information, see link:https://linux.die.net/man/8/lspci[lspci(8) - Linux man page].

[IMPORTANT]
====
If the `lspci` utility indicates that Intel Gaudi AI accelerators are present in your deployment, it does not necessarily mean that the devices are ready to use. 

Before you can use your Intel Gaudi AI accelerators, you must enable them in your OpenShift environment and configure an accelerator profile for each device. For more information about how to enable your OpenShift environment for Intel Gaudi AI accelerators, see link:https://docs.habana.ai/en/v1.10.0/Orchestration/HabanaAI_Operator/index.html[HabanaAI Operator for OpenShift].   
====

[role="_additional-resources"]
.Additional resources
* link:https://docs.habana.ai/en/v1.10.0/Orchestration/HabanaAI_Operator/index.html[HabanaAI Operator v1.10 for OpenShift]
* link:https://docs.habana.ai/en/v1.13.0/Orchestration/HabanaAI_Operator/index.html[HabanaAI Operator v1.13 for OpenShift]
* link:https://linux.die.net/man/8/lspci[lspci(8) - Linux man page] 
* link:https://aws.amazon.com/ec2/instance-types/dl1/[Amazon EC2 DL1 Instances]
* link:https://docs.habana.ai/en/latest/Support_Matrix/Support_Matrix_v1.10.0.html#support-matrix-1-10-0[Support Matrix v1.10.0]
* link:https://docs.habana.ai/en/latest/Support_Matrix/Support_Matrix_v1.13.0.html#support-matrix-1-13-0[Support Matrix v1.13.0]
* link:https://access.redhat.com/solutions/4870701[What version of the Kubernetes API is included with each OpenShift 4.x release?]
