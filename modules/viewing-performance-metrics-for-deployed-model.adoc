:_module-type: PROCEDURE

[id="viewing-performance-metrics-for-deployed-model_{context}"]
= Viewing performance metrics for a deployed model

[role='_abstract']

You can monitor the following metrics for a specific model that is deployed on the single-model serving platform:

* *Number of requests* - The number of requests that have failed or succeeded for a specific model.
* *Average response time (ms)* - The average time it takes a specific model to respond to requests.
* *CPU utilization (%)* - The percentage of the CPU limit per model replica that is currently utilized by a specific model.
* *Memory utilization (%)* - The percentage of the memory limit per model replica that is utilized by a specific model.

You can specify a time range and a refresh interval for these metrics to help you determine, for example, when the peak usage hours are and how the model is performing at a specified time.

.Prerequisites
* You have installed {productname-long}.

ifdef::upstream,self-managed[]
* A cluster admin has enabled user workload monitoring (UWM) for user-defined projects on your OpenShift cluster. For more information, see link:https://docs.redhat.com/en/documentation/openshift_container_platform/{ocp-latest-version}/html/monitoring/enabling-monitoring-for-user-defined-projects[Enabling monitoring for user-defined projects] and link:{rhoaidocshome}{default-format-url}/serving_models/serving-large-models_serving-large-models#configuring-monitoring-for-the-single-model-serving-platform_serving-large-models[Configuring monitoring for the single-model serving platform].
endif::[]

* You have logged in to {productname-long}.
ifndef::upstream[]
* If you are using {productname-short} groups, you are part of the user group or admin group (for example, {oai-user-group} or {oai-admin-group}) in OpenShift.
endif::[]
ifdef::upstream[]
* If you are using {productname-short} groups, you are part of the user group or admin group (for example, {odh-user-group} or {odh-admin-group}) in OpenShift.
endif::[]
* The following dashboard configuration options are set to the default values as shown:
+
[source]
----
disablePerformanceMetrics:false
disableKServeMetrics:false
----
ifdef::upstream[]
For more information, see link:{odhdocshome}/managing-odh/#ref-dashboard-configuration-options_dashboard[Dashboard configuration options].
endif::[]
ifndef::upstream[]
For more information, see link:{rhoaidocshome}{default-format-url}/managing_openshift_ai/customizing-the-dashboard#ref-dashboard-configuration-options_dashboard[Dashboard configuration options].
endif::[]
* You have deployed a model on the single-model serving platform by using a preinstalled runtime.
+
[NOTE]
====
Metrics are only supported for models deployed by using a preinstalled model-serving runtime or a custom runtime that is duplicated from a preinstalled runtime.
====

.Procedure

. From the {productname-short} dashboard navigation menu, click *Data Science Projects*.
+
The *Data Science Projects* page opens.
. Click the name of the project that contains the data science models that you want to monitor.

. In the project details page, click the *Models* tab.

. Select the model that you are interested in.

. On the *Endpoint performance* tab, set the following options:

** *Time range* - Specifies how long to track the metrics. You can select one of these values: 1 hour, 24 hours, 7 days, and 30 days.

** *Refresh interval* - Specifies how frequently the graphs on the metrics page are refreshed (to show the latest data). You can select one of these values: 15 seconds, 30 seconds, 1 minute, 5 minutes, 15 minutes, 30 minutes, 1 hour, 2 hours, and 1 day.

. Scroll down to view data graphs for number of requests, average response time, CPU utilization, and memory utilization.

.Verification

The *Endpoint performance* tab shows graphs of metrics for the model.
//.See also
//Viewing HTTP request metrics for a deployed model
