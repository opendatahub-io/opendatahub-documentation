:_module-type: CONCEPT

[id='safeguard-your-AI-application-with-guardrails_{context}']
= Safeguard your AI application with Guardrails

[role='_abstract']

The 'Lemonade Stand' tutorial demonstrates how to create and deploy an LLM customer service assistant to answer queries about your product. It uses guardrailing models to ensure it focuses on your brand, avoids inappropriate language, and does not promote any competitor products. In this way, it mitigates risks associated with unstructured text generation.

The models analyze the input (the customer's prompt) and output (the response) and provide guardrailing based on three criteria:

* *Input Validation:* Is the user's question safe and relevant?
* *Business Logic:* Is the user asking about restricted topics (for example, competitors' products)?
* *Output Validation:* Is the model's generated response appropriate for a general audience?





