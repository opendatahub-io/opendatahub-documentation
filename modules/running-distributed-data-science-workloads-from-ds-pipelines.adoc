:_module-type: PROCEDURE

[id="running-distributed-data-science-workloads-from-ds-pipelines_{context}"]
= Running distributed data science workloads from data science pipelines

[role='_abstract']
To run a distributed data science workload from a data science pipeline, you must first update the pipeline to include a link to your Ray cluster image.

.Prerequisites
ifndef::upstream[]
* You have access to a data science cluster that is configured to run distributed workloads as described in link:{rhoaidocshome}{default-format-url}/working_with_distributed_workloads/configuring-distributed-workloads_distributed-workloads[Configuring distributed workloads].
endif::[]
ifdef::upstream[]
* You have access to a data science cluster that is configured to run distributed workloads as described in link:{odhdocshome}/working-with-distributed-workloads/#configuring-distributed-workloads_distributed-workloads[Configuring distributed workloads].
endif::[]

ifndef::upstream[]
* Your cluster administrator has created the required Kueue resources as described in link:{rhoaidocshome}{default-format-url}/working_with_distributed_workloads/configuring-distributed-workloads_distributed-workloads#configuring-quota-management-for-distributed-workloads_distributed-workloads[Configuring quota management for distributed workloads].
endif::[]
ifdef::upstream[]
* Your cluster administrator has created the required Kueue resources as described in link:{odhdocshome}/working-with-distributed-workloads/#configuring-quota-management-for-distributed-workloads_distributed-workloads[Configuring quota management for distributed workloads].
endif::[]

ifndef::upstream[]
* Optional: Your cluster administrator has defined a _default_ local queue for the Ray cluster by creating a `LocalQueue` resource and adding the following annotation to the configuration details for that `LocalQueue` resource, as described in link:{rhoaidocshome}{default-format-url}/working_with_distributed_workloads/configuring-distributed-workloads_distributed-workloads#configuring-quota-management-for-distributed-workloads_distributed-workloads[Configuring quota management for distributed workloads]:
+
[source,bash]
----
"kueue.x-k8s.io/default-queue": "true"
----
+
[NOTE]
====
If your cluster administrator does not define a default local queue, you must specify a local queue in each pipeline.
====
endif::[]
ifdef::upstream[]
* Optional: Your cluster administrator has defined a _default_ local queue for the Ray cluster by creating a `LocalQueue` resource and adding the following annotation to the configuration details for that `LocalQueue` resource, as described in link:{odhdocshome}/working-with-distributed-workloads/#configuring-quota-management-for-distributed-workloads_distributed-workloads[Configuring quota management for distributed workloads]:
+
[source,bash]
----
"kueue.x-k8s.io/default-queue": "true"
----
+
[NOTE]
====
If your cluster administrator does not define a default local queue, you must specify a local queue in each pipeline.
====
endif::[]


* You have access to S3-compatible object storage.
* You have logged in to {productname-long}.

ifndef::upstream[]
* You have created a data science project that contains a workbench, and the workbench is running a default notebook image that contains the CodeFlare SDK, for example, the *Standard Data Science* notebook. For information about how to create a project, see link:{rhoaidocshome}{default-format-url}/working_on_data_science_projects/using-data-science-projects_projects#creating-a-data-science-project_projects[Creating a data science project].
endif::[]
ifdef::upstream[]
* You have created a data science project that contains a workbench, and the workbench is running a default notebook image that contains the CodeFlare SDK, for example, the *Standard Data Science* notebook. For information about how to create a project, see link:{odhdocshome}/working-on-data-science-projects/#creating-a-data-science-project_projects[Creating a data science project].
endif::[]

* You have Admin access for the data science project.
** If you created the project, you automatically have Admin access. 
** If you did not create the project, your cluster administrator must give you Admin access.

.Procedure
ifndef::upstream[]
. Create a data connection to connect the object storage to your data science project, as described in link:{rhoaidocshome}{default-format-url}/working_on_data_science_projects/using-data-connections_projects#adding-a-data-connection-to-your-data-science-project_projects[Adding a data connection to your data science project].
endif::[]
ifdef::upstream[]
. Create a data connection to connect the object storage to your data science project, as described in link:{odhdocshome}/working-on-data-science-projects/#adding-a-data-connection-to-your-data-science-project_projects[Adding a data connection to your data science project].
endif::[]

ifndef::upstream[]
. Configure a pipeline server to use the data connection, as described in link:working_with_data_science_pipelines/managing-data-science-pipelines_ds-pipelines#configuring-a-pipeline-server_ds-pipelines[Configuring a pipeline server].
endif::[]
ifdef::upstream[]
. Configure a pipeline server to use the data connection, as described in link:{odhdocshome}/working-with-data-science-pipelines/#configuring-a-pipeline-server_ds-pipelines[Configuring a pipeline server].
endif::[]

. Create the data science pipeline as follows:
.. Install the `kfp` Python package, which is required for all pipelines:
+
[source,bash]
----
$ pip install kfp
----
.. Install any other dependencies that are required for your pipeline.
.. Build your data science pipeline in Python code.
+
For example, create a file named `compile_example.py` with the following content:
+
[source,Python]
----
from kfp import dsl


@dsl.component(
    base_image="registry.redhat.io/ubi8/python-39:latest",
    packages_to_install=['codeflare-sdk']
)


def ray_fn():
   import ray <1>
   from codeflare_sdk import Cluster, ClusterConfiguration, generate_cert <2>


   cluster = Cluster( <3>
       ClusterConfiguration(
           namespace="my_project", <4>
           name="raytest",
           num_workers=1,
           head_cpus="500m",
           min_memory=1,
           max_memory=1,
           num_gpus=0,
           image="quay.io/rhoai/ray:2.23.0-py39-cu121", <5>
           local_queue="local_queue_name", <6>
       )
   )


   print(cluster.status())
   cluster.up() <7>
   cluster.wait_ready() <8>
   print(cluster.status())
   print(cluster.details())


   ray_dashboard_uri = cluster.cluster_dashboard_uri()
   ray_cluster_uri = cluster.cluster_uri()
   print(ray_dashboard_uri, ray_cluster_uri)

   # Enable Ray client to connect to secure Ray cluster that has mTLS enabled
   generate_cert.generate_tls_cert(cluster.config.name, cluster.config.namespace) <9>
   generate_cert.export_env(cluster.config.name, cluster.config.namespace)


   ray.init(address=ray_cluster_uri)
   print("Ray cluster is up and running: ", ray.is_initialized())


   @ray.remote
   def train_fn(): <10>
       # complex training function
       return 100


   result = ray.get(train_fn.remote())
   assert 100 == result
   ray.shutdown()
   cluster.down() <11>
   auth.logout()
   return result


@dsl.pipeline( <12>
   name="Ray Simple Example",
   description="Ray Simple Example",
)


def ray_integration(): 
   ray_fn()


if __name__ == '__main__': <13>
    from kfp.compiler import Compiler
    Compiler().compile(ray_integration, 'compiled-example.yaml')

----
<1> Imports Ray.
<2> Imports packages from the CodeFlare SDK to define the cluster functions.
<3> Specifies the Ray cluster configuration: replace these example values with the values for your Ray cluster.
<4> Optional: Specifies the project where the Ray cluster is created. Replace the example value with the name of your project. If you omit this line, the Ray cluster is created in the current project.
<5> Specifies the location of the Ray cluster image. If you are running this code in a disconnected environment, replace the default value with the location for your environment.
<6> Specifies the local queue to which the Ray cluster will be submitted. If a default local queue is configured, you can omit this line.
<7> Creates a Ray cluster by using the specified image and configuration.
<8> Waits until the Ray cluster is ready before proceeding.
<9> Enables the Ray client to connect to a secure Ray cluster that has mutual Transport Layer Security (mTLS) enabled. mTLS is enabled by default in the CodeFlare component in {productname-short}.
<10> Replace the example details in this section with the details for your workload.
<11> Removes the Ray cluster when your workload is finished.
<12> Replace the example name and description with the values for your workload.
<13> Compiles the Python code and saves the output in a YAML file.

.. Compile the Python file (in this example, the `compile_example.py` file):
+
[source,bash]
----
$ python compile_example.py
----
This command creates a YAML file (in this example, `compiled-example.yaml`), which you can import in the next step.

ifndef::upstream[]
. Import your data science pipeline, as described in link:working_with_data_science_pipelines/managing-data-science-pipelines_ds-pipelines#importing-a-data-science-pipeline_ds-pipelines[Importing a data science pipeline].
endif::[]
ifdef::upstream[]
. Import your data science pipeline, as described in link:{odhdocshome}/working-with-data-science-pipelines/#importing-a-data-science-pipeline_ds-pipelines[Importing a data science pipeline].
endif::[]

ifndef::upstream[]
. Schedule the pipeline run, as described in link:{rhoaidocshome}{default-format-url}/working_with_data_science_pipelines/managing-pipeline-runs_ds-pipelines#scheduling-a-pipeline-run_ds-pipelines[Scheduling a pipeline run].
endif::[]
ifdef::upstream[]
. Schedule the pipeline run, as described in link:{odhdocshome}/working-with-data-science-pipelines/#scheduling-a-pipeline-run_ds-pipelines[Scheduling a pipeline run].
endif::[]

ifndef::upstream[]
. When the pipeline run is complete, confirm that it is included in the list of triggered pipeline runs, as described in link:{rhoaidocshome}{default-format-url}/working_with_data_science_pipelines/managing-pipeline-runs_ds-pipelines#viewing-the-details-of-a-pipeline-run_ds-pipelines[Viewing the details of a pipeline run].
endif::[]
ifdef::upstream[]
. When the pipeline run is complete, confirm that it is included in the list of triggered pipeline runs, as described in link:{odhdocshome}/working-with-data-science-pipelines/#viewing-the-details-of-a-pipeline-run_ds-pipelines[Viewing the details of a pipeline run].
endif::[]


.Verification
The YAML file is created and the pipeline run completes without errors.

ifndef::upstream[]
You can view the run details, as described in link:{rhoaidocshome}{default-format-url}/working_with_data_science_pipelines/managing-pipeline-runs_ds-pipelines#viewing-the-details-of-a-pipeline-run_ds-pipelines[Viewing the details of a pipeline run].
endif::[]
ifdef::upstream[]
You can view the run details, as described in link:{odhdocshome}/working-with-data-science-pipelines/#viewing-the-details-of-a-pipeline-run_ds-pipelines[Viewing the details of a pipeline run].
endif::[]

[role='_additional-resources']
.Additional resources
ifndef::upstream[]
* link:{rhoaidocshome}{default-format-url}/working_with_data_science_pipelines/[Working with data science pipelines]
endif::[]
ifdef::upstream[]
* link:{odhdocshome}/working-with-data-science-pipelines/[Working with data science pipelines]
endif::[]

* link:https://docs.ray.io/en/latest/cluster/getting-started.html[Ray Clusters documentation]
