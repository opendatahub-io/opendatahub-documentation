:_module-type: PROCEDURE

[id="running-distributed-data-science-workloads-from-ds-pipelines_{context}"]
= Running distributed data science workloads from data science pipelines

[role='_abstract']
To run a distributed workload from a pipeline, you must first update the pipeline to include a link to your Ray cluster image.

.Prerequisites
ifndef::upstream[]
* You can access a data science cluster that is configured to run distributed workloads as described in link:{rhoaidocshome}{default-format-url}/managing_openshift_ai/managing_distributed_workloads[Managing distributed workloads].
endif::[]
ifdef::upstream[]
* You can access a data science cluster that is configured to run distributed workloads as described in link:{odhdocshome}/managing-odh/#managing_distributed_workloads[Managing distributed workloads].
endif::[]


* You can access the following software from your data science cluster:
** A Ray cluster image that is compatible with your hardware architecture
** The data sets and models to be used by the workload
** The Python dependencies for the workload, either in a Ray image or in your own Python Package Index (PyPI) server

ifndef::upstream[]
* You can access a data science project that contains a workbench, and the workbench is running a default notebook image that contains the CodeFlare SDK, for example, the *Standard Data Science* notebook. 
For information about projects and workbenches, see link:{rhoaidocshome}{default-format-url}/working_on_data_science_projects[Working on data science projects].
endif::[]
ifdef::upstream[]
* You can access a data science project that contains a workbench, and the workbench is running a default notebook image that contains the CodeFlare SDK, for example, the *Standard Data Science* notebook. 
For information about projects and workbenches, see link:{odhdocshome}/working-on-data-science-projects[Working on data science projects].
endif::[]

* You have Admin access for the data science project.
** If you created the project, you automatically have Admin access. 
** If you did not create the project, your cluster administrator must give you Admin access.

* You have access to S3-compatible object storage.
* You have logged in to {productname-long}.


.Procedure
ifndef::upstream[]
. Create a connection to connect the object storage to your data science project, as described in link:{rhoaidocshome}{default-format-url}/working_on_data_science_projects/using-connections_projects#adding-a-connection-to-your-data-science-project_projects[Adding a connection to your data science project].
endif::[]
ifdef::upstream[]
. Create a connection to connect the object storage to your data science project, as described in link:{odhdocshome}/working-on-data-science-projects/#adding-a-connection-to-your-data-science-project_projects[Adding a connection to your data science project].
endif::[]

ifndef::upstream[]
. Configure a pipeline server to use the connection, as described in link:{rhoaidocshome}{default-format-url}/working_with_data_science_pipelines/managing-data-science-pipelines_ds-pipelines#configuring-a-pipeline-server_ds-pipelines[Configuring a pipeline server].
endif::[]
ifdef::upstream[]
. Configure a pipeline server to use the connection, as described in link:{odhdocshome}/working-with-data-science-pipelines/#configuring-a-pipeline-server_ds-pipelines[Configuring a pipeline server].
endif::[]

. Create the data science pipeline as follows:
.. Install the `kfp` Python package, which is required for all pipelines:
+
[source,bash]
----
$ pip install kfp
----
.. Install any other dependencies that are required for your pipeline.
.. Build your data science pipeline in Python code.
+
For example, create a file named `compile_example.py` with the following content.
ifdef::upstream[]
+
[NOTE]
--
If you copy and paste the following code example, remember to remove the _callouts_, which are not part of the code.
The callouts (parenthetical numbers, highlighted in bold font in this document) map the relevant line of code to an explanatory note in the text immediately after the code example. 
--
endif::[]
+
[source,Python]
----
from kfp import dsl


@dsl.component(
    base_image="registry.redhat.io/ubi8/python-39:latest",
    packages_to_install=['codeflare-sdk']
)


def ray_fn():
   import ray <1>
   from codeflare_sdk import Cluster, ClusterConfiguration, generate_cert <2>


   cluster = Cluster( <3>
       ClusterConfiguration(
           namespace="my_project", <4>
           name="raytest",
           num_workers=1,
           head_cpus="500m",
           min_memory=1,
           max_memory=1,
           worker_extended_resource_requests={“nvidia.com/gpu”: 1}, <5>
           image="quay.io/modh/ray:2.35.0-py39-cu121", <6>
           local_queue="local_queue_name", <7>
       )
   )


   print(cluster.status())
   cluster.up() <8>
   cluster.wait_ready() <9>
   print(cluster.status())
   print(cluster.details())


   ray_dashboard_uri = cluster.cluster_dashboard_uri()
   ray_cluster_uri = cluster.cluster_uri()
   print(ray_dashboard_uri, ray_cluster_uri)

   # Enable Ray client to connect to secure Ray cluster that has mTLS enabled
   generate_cert.generate_tls_cert(cluster.config.name, cluster.config.namespace) <10>
   generate_cert.export_env(cluster.config.name, cluster.config.namespace)


   ray.init(address=ray_cluster_uri)
   print("Ray cluster is up and running: ", ray.is_initialized())


   @ray.remote
   def train_fn(): <11>
       # complex training function
       return 100


   result = ray.get(train_fn.remote())
   assert 100 == result
   ray.shutdown()
   cluster.down() <12>
   auth.logout()
   return result


@dsl.pipeline( <13>
   name="Ray Simple Example",
   description="Ray Simple Example",
)


def ray_integration(): 
   ray_fn()


if __name__ == '__main__': <14>
    from kfp.compiler import Compiler
    Compiler().compile(ray_integration, 'compiled-example.yaml')

----
<1> Imports Ray.
<2> Imports packages from the CodeFlare SDK to define the cluster functions.
<3> Specifies the Ray cluster configuration: replace these example values with the values for your Ray cluster.
<4> Optional: Specifies the project where the Ray cluster is created. Replace the example value with the name of your project. If you omit this line, the Ray cluster is created in the current project.
<5> Optional: Specifies the requested accelerators for the Ray cluster (in this example, 1 NVIDIA GPU).
If no accelerators are required, set the value to 0 or omit the line. 
Note: To specify the requested accelerators for the Ray cluster, use the `worker_extended_resource_requests` parameter instead of the deprecated `num_gpus` parameter.
For more details, see the link:https://github.com/project-codeflare/codeflare-sdk/blob/v0.18.0/src/codeflare_sdk/cluster/config.py#L43-L73[CodeFlare SDK documentation].
<6> Specifies the location of the Ray cluster image. 
If you omit this line, one of the default CUDA-compatible Ray cluster images is used, based on the Python version detected in the workbench.
The default Ray images are AMD64 images, which might not work on other architectures.
If you are running this code in a disconnected environment, replace the default value with the location for your environment. 
ifndef::upstream[]
For information about the latest available training images and their preinstalled packages, see link:https://access.redhat.com/articles/rhoai-supported-configs[{productname-long}: Supported Configurations].
endif::[]
<7> Specifies the local queue to which the Ray cluster will be submitted. If a default local queue is configured, you can omit this line.
<8> Creates a Ray cluster by using the specified image and configuration.
<9> Waits until the Ray cluster is ready before proceeding.
<10> Enables the Ray client to connect to a secure Ray cluster that has mutual Transport Layer Security (mTLS) enabled. mTLS is enabled by default in the CodeFlare component in {productname-short}.
<11> Replace the example details in this section with the details for your workload.
<12> Removes the Ray cluster when your workload is finished.
<13> Replace the example name and description with the values for your workload.
<14> Compiles the Python code and saves the output in a YAML file.

.. Compile the Python file (in this example, the `compile_example.py` file):
+
[source,bash]
----
$ python compile_example.py
----
This command creates a YAML file (in this example, `compiled-example.yaml`), which you can import in the next step.

ifndef::upstream[]
. Import your data science pipeline, as described in link:working_with_data_science_pipelines/managing-data-science-pipelines_ds-pipelines#importing-a-data-science-pipeline_ds-pipelines[Importing a data science pipeline].
endif::[]
ifdef::upstream[]
. Import your data science pipeline, as described in link:{odhdocshome}/working-with-data-science-pipelines/#importing-a-data-science-pipeline_ds-pipelines[Importing a data science pipeline].
endif::[]

ifndef::upstream[]
. Schedule the pipeline run, as described in link:{rhoaidocshome}{default-format-url}/working_with_data_science_pipelines/managing-pipeline-runs_ds-pipelines#scheduling-a-pipeline-run_ds-pipelines[Scheduling a pipeline run].
endif::[]
ifdef::upstream[]
. Schedule the pipeline run, as described in link:{odhdocshome}/working-with-data-science-pipelines/#scheduling-a-pipeline-run_ds-pipelines[Scheduling a pipeline run].
endif::[]

ifndef::upstream[]
. When the pipeline run is complete, confirm that it is included in the list of triggered pipeline runs, as described in link:{rhoaidocshome}{default-format-url}/working_with_data_science_pipelines/managing-pipeline-runs_ds-pipelines#viewing-the-details-of-a-pipeline-run_ds-pipelines[Viewing the details of a pipeline run].
endif::[]
ifdef::upstream[]
. When the pipeline run is complete, confirm that it is included in the list of triggered pipeline runs, as described in link:{odhdocshome}/working-with-data-science-pipelines/#viewing-the-details-of-a-pipeline-run_ds-pipelines[Viewing the details of a pipeline run].
endif::[]


.Verification
The YAML file is created and the pipeline run completes without errors.

ifndef::upstream[]
You can view the run details, as described in link:{rhoaidocshome}{default-format-url}/working_with_data_science_pipelines/managing-pipeline-runs_ds-pipelines#viewing-the-details-of-a-pipeline-run_ds-pipelines[Viewing the details of a pipeline run].
endif::[]
ifdef::upstream[]
You can view the run details, as described in link:{odhdocshome}/working-with-data-science-pipelines/#viewing-the-details-of-a-pipeline-run_ds-pipelines[Viewing the details of a pipeline run].
endif::[]

[role='_additional-resources']
.Additional resources
ifndef::upstream[]
* link:{rhoaidocshome}{default-format-url}/working_with_data_science_pipelines/[Working with data science pipelines]
endif::[]
ifdef::upstream[]
* link:{odhdocshome}/working-with-data-science-pipelines/[Working with data science pipelines]
endif::[]

* link:https://docs.ray.io/en/latest/cluster/getting-started.html[Ray Clusters documentation]
