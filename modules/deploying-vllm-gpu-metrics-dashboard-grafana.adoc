:_module-type: PROCEDURE

[id="deploying-vllm-gpu-metrics-dashboard-grafana_{context}"]
= Deploying a vLLM/GPU metrics dashboard on a Grafana instance

[role='_abstract']
Deploy Grafana boards to monitor accelerator and vLLM performance metrics.

.Prerequisites
ifdef::upstream[]
* You have deployed a Grafana metrics dashboard, as described in link:{odhdocshome}/serving-models/#deploying-a-grafana-metrics-dashboard[Deploying a Grafana metrics dashboard].
endif::[]
ifndef::upstream[]
* You have deployed a Grafana metrics dashboard, as described in link:{rhoaidocshome}{default-format-url}/managing_and_monitoring_models/managing_and_monitoring_models_on_the_model_serving_platform#deploying-a-grafana-metrics-dashboard_cluster-admin[Deploying a Grafana metrics dashboard].
endif::[]

* You can access a Grafana instance. 
* You have installed `envsubst`, a command-line tool used to substitute environment variables in configuration files. For more information, see the GNU `gettext` documentation.

.Procedure

. Define a `GrafanaDashboard` object in a YAML file, similar to the following examples:
.. To monitor NVIDIA accelerator metrics, see link:https://github.com/rh-aiservices-bu/rhoai-uwm/tree/main/rhoai-uwm-grafana/overlays/rhoai-uwm-user-grafana-app/nvidia-vllm-dashboard.yaml[`nvidia-vllm-dashboard.yaml`].
.. To monitor AMD accelerator metrics, see link:https://github.com/rh-aiservices-bu/rhoai-uwm/tree/main/rhoai-uwm-grafana/overlays/rhoai-uwm-user-grafana-app/amd-vllm-dashboard.yaml[`amd-vllm-dashboard.yaml`].
.. To monitor Intel accelerator metrics, see link:https://github.com/rh-aiservices-bu/rhoai-uwm/tree/main/rhoai-uwm-grafana/overlays/rhoai-uwm-user-grafana-app/gaudi-vllm-dashboard.yaml[`gaudi-vllm-dashboard.yaml`].
.. To monitor vLLM metrics, see link:https://github.com/rh-aiservices-bu/rhoai-uwm/tree/main/rhoai-uwm-grafana/overlays/rhoai-uwm-user-grafana-app/grafana-vllm-dashboard.yaml[`grafana-vllm-dashboard.yaml`].

. Create an `inputs.env` file similar to the following example. Replace the `NAMESPACE` and `MODEL_NAME` parameters with your own values:
+
[source]
----
NAMESPACE=<namespace> <1>
MODEL_NAME=<model-name> <2>
----
<1> **NAMESPACE** is the target namespace where the model will be deployed.
<2> **MODEL_NAME** is the model name as defined in your InferenceService. The model name is also used to filter the pod name in the Grafana dashboard.

. Replace the `NAMESPACE` and `MODEL_NAME` parameters in your YAML file with the values from the `inputs.env` file by performing the following actions:

.. Export the parameters described in the `inputs.env` as environment variables:
+
[source]
----
export $(cat inputs.env | xargs)
----

.. Update the following YAML file, replacing the `${NAMESPACE}` and `${MODEL_NAME}` variables with the values of the exported environment variables, and `dashboard_template.yaml` with the name of the `GrafanaDashboard` object YAML file that you created earlier:
+
[source]
----
envsubst '${NAMESPACE} ${MODEL_NAME}' < dashboard_template.yaml > dashboard_template-replaced.yaml
----

. Confirm that your YAML file contains updated values.

. Deploy the dashboard object:
+
[source]
----
oc create -f dashboard_template-replaced.yaml
----

.Verification

You can see the accelerator and vLLM metrics dashboard on your Grafana instance.
