:_module-type: PROCEDURE

[id="experimenting-with-models-in-the-generative-ai-playground_{context}"]
= Experimenting with models in the Generative AI Playground

[role="_abstract"]
You can experiment with models in the Generative AI (GenAI) Playground to test prompt and response behavior. The configuration options allow you to modify model instructions, adjust generation temperature, and enable or disable streaming to refine how the model produces responses.

.Prerequisites
* You have installed {openshift-platform} {ocp-minimum-version} or newer. 
* You have logged in to {productname-long}.
* The `spec.OdhDashboardConfig.genAiStudio` feature flag value is set to `true` in the `OdhDashboardConfig` custom resource (CR) in {openshift-platform}. 
ifndef::upstream[]
* If you are using {productname-short} groups, you are part of the user group or admin group (for example, {oai-user-group} or {oai-admin-group}) in OpenShift.
endif::[]
ifdef::upstream[]
* If you are using {productname-short} groups, you are part of the user group or admin group (for example, {odh-user-group} or {odh-admin-group}) in OpenShift.
endif::[]
* You have access to a project where the models are deployed.
* You have activated the Llama Stack Operator.
* You have configured a LlamaStackDistribution custom resource (CR) with a vLLM inference service and a vector store.
* You have deployed one or more models that are served by a vLLM model server.
* You have configured any MCP tools in your Llama Stack instance. 
* Your environment has network access to the vector database service through {openshift-platform}.
* You have designated your deployed model as an AI asset.

.Procedure
. In the {productname-short} dashboard, click *Gen AI studio* â†’ *Playground*.
+
The *Playground* page opens.
. From the *Project* drop-down list at the top of the page, select the project that contains your deployed model.
. In the right pane, locate the *Model details* section.
. From the *Model* drop-down list, select the model that you want to use in the GenAI Playground session.
+
The interface automatically loads the selected model for interaction.
. Optional: In the *System instructions* text box, enter high-level guidance that shapes the model's behavior.  
+
For example, specify tone, domain, or persona instructions, such as "You are a helpful data science assistant that provides concise responses.".
. Use the *Temperature* slider to control the level of randomness in the model's responses:
+
* Lower values such as `0.2` produce more deterministic and focused output.
* Higher values such as `1.5` increase creativity and variability.
. Toggle *Streaming* on or off:
+
* When enabled, model responses appear progressively in the chat window as they are generated.
* When disabled, responses are displayed only after the model has completed generation.
. Enter a prompt in the chat panel, and then click *Send* to begin interacting with the selected model.

.Verification
* The GenAI Playground displays responses from the selected model according to the configured settings.  
* The active model name appears in the *Model details* section.
