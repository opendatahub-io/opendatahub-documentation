:_module-type: PROCEDURE

[id='configuring-bias-monitoring-for-a-model-cli_{context}']
= Configuring bias monitoring for a model by using the CLI

ifndef::upstream[]
[IMPORTANT]
====
The TrustyAI features are for Technology Preview only. Technology Preview features are not supported with {org-name} production service level agreements (SLAs), might not be functionally complete, and {org-name} does not recommend using them for production. These features provide early access to upcoming product features, enabling customers to test functionality and provide feedback during the development process. 			
For more information on {org-name} Technology Preview features, see link:https://access.redhat.com/support/offerings/techpreview/ [Technology Preview Features Scope]. 		
====
endif::[]

[role='_abstract']
To monitor a deployed model for bias, you must first configure bias metrics. When you configure bias metrics, you specify details relevant to your model. For example, details such as a protected attribute, privileged and unprivileged groups, a model outcome and value that you want to monitor, and the acceptable threshold for bias.

//The example in this procedure is from the demo here: https://github.com/trustyai-explainability/odh-trustyai-demos/tree/main/2-BiasMonitoring

.Prerequisites

ifndef::upstream[]
* You are familiar with link:{rhoaidocshome}{default-format-url}/monitoring_data_science_models/monitoring-models-for-bias_bias-monitoring#supported-bias-metrics_bias-monitoring[the bias metrics that {productname-short} supports] and how to interpret them.
endif::[]
ifdef::upstream[]
* You are familiar with link:{odhdocshome}/monitoring-data-science-models/#supported-bias-metrics_bias-monitoring[the bias metrics that {productname-short} supports] and how to interpret them.
endif::[]

* Your OpenShift cluster administrator has installed Open Data Hub and deployed the TrustyAI service for the data science project where the models are deployed.

* You installed the OpenShift command line interface (`oc`) as described in link:https://docs.openshift.com/container-platform/{ocp-latest-version}/cli_reference/openshift_cli/getting-started-cli.html[Get Started with the CLI].


.Procedure

. In a terminal window, log into the OpenShift cluster where {productname-short} is deployed.
+
----
oc login
----

. Set the `TRUSTY_ROUTE` variable to the external route for the TrustyAI service pod.
+
----
$TRUSTY_ROUTE=http://$(oc get route/trustyai-service --template={{.spec.host}})
----

.  Optionally, get the full list of TrustyAI service endpoints and payloads. 
+
----
curl --location $TRUSTY_ROUTE/q/openapi
----

. Configure bias metrics by running a command that uses the following syntax and payload structure:
+
*Syntax*:
+
----
curl -sk  -X POST --location $TRUSTY_ROUTE/metrics/spd/request \ 
 --header 'Content-Type: application/json' \ 
 --data <payload>
----
+
*Payload structure*:

`modelId`:: The name of the model to query.
`protectedAttribute`:: The name of the feature that distinguishes the groups that you are checking for fairness.
`privilegedAttribute`:: The suspected favored (positively biased) class.
`unprivilegedAttribute`:: The suspected unfavored (negatively biased) class.
`outcomeName`:: The name of the output that provides the output you are examining for fairness.
`favorableOutcome`:: The value of the `outcomeName` output that describes the favorable or desired model prediction.
`batchSize`:: The number of previous inferences to include in the calculation.

For example:  

----
curl -sk  -X POST --location $TRUSTY_ROUTE/metrics/group/fairness/spd/ \
     --header 'Content-Type: application/json' \
     --data "{
                 \"modelId\": \"demo-loan-nn-onnx-alpha\",
                 \"protectedAttribute\": \"Is Male-Identifying?\",
                 \"privilegedAttribute\": 1.0,
                 \"unprivilegedAttribute\": 0.0,
                 \"outcomeName\": \"Will Default?\",
                 \"favorableOutcome\": 0,
                 \"batchSize\": 5000
             }" 
----

.Verification

The bias metrics request should return output similar to the following:

----
{
   "timestamp":"2023-10-24T12:06:04.586+00:00",
   "type":"metric",
   "value":-0.0029676404469311524,
   "namedValues":null,
   "specificDefinition":"The SPD of -0.002968 indicates that the likelihood of Group:Is Male-Identifying?=1.0 receiving Outcome:Will Default?=0 was -0.296764 percentage points lower than that of Group:Is Male-Identifying?=0.0.",
   "name":"SPD",
   "id":"d2707d5b-cae9-41aa-bcd3-d950176cbbaf",
   "thresholds":{"lowerBound":-0.1,"upperBound":0.1,"outsideBounds":false}
}
----

The `specificDefinition` field is useful in understanding the real-world interpretation of these metric values. For this example, the model is quite fair over the `Is Male-Identifying?` field, with the rate of positive outcome only differing by approximately -0.3%.

