= Enabling high availability and autoscaling on Llama Stack 

Llama Stack servers can be configured to remain operational in the event of a single point of failure. 
If a pod restarts, an application crashes, or node maintenance occurs, you can maintain availability by enabling PostgreSQL high-availability settings in your Llama Stack server. 
You can also enable autoscaling settings to adjust server capacity and automatic resource adjustment. 
The following documentation displays how to configure high availability and autoscaling in your `LlamaStackDistribution` custom resource. 

.Prerequisites

* You have installed {openshift-platform} 4.19 or newer.
* You have logged in to {productname-long}.
* You have cluster administrator privileges for your OpenShift cluster.
* You have installed the PostgreSQL Operator. 
* You have activated the Llama Stack Operator in your cluster.
* You have installed the {openshift-cli} as described in the appropriate documentation for your cluster:
ifdef::upstream,self-managed[]
** link:https://docs.redhat.com/en/documentation/openshift_container_platform/{ocp-latest-version}/html/cli_tools/openshift-cli-oc#installing-openshift-cli[Installing the OpenShift CLI^] for OpenShift Container Platform
** link:https://docs.redhat.com/en/documentation/red_hat_openshift_service_on_aws/{rosa-latest-version}/html/cli_tools/openshift-cli-oc#installing-openshift-cli[Installing the OpenShift CLI^] for {rosa-productname}
endif::[]
ifdef::cloud-service[]
** link:https://docs.redhat.com/en/documentation/openshift_dedicated/{osd-latest-version}/html/cli_tools/openshift-cli-oc#installing-openshift-cli[Installing the OpenShift CLI^] for OpenShift Dedicated
** link:https://docs.redhat.com/en/documentation/red_hat_openshift_service_on_aws_classic_architecture/{rosa-classic-latest-version}/html/cli_tools/openshift-cli-oc#installing-openshift-cli[Installing the OpenShift CLI^] for {rosa-classic-productname}
endif::[]

.Procedure

. To enable high availability for your Llama Stack server, add the following parameters to your `LlamaStackDistribution` CR:
+
[source,yaml]
----
spec:
  replicas: 2 <1> 
  server:
    podDisruptionBudget:
      minAvailable: 1 <2> 
    topologySpreadConstraints: <3> 
      - maxSkew: 1 <4> 
        topologyKey: topology.kubernetes.io/zone <5>
        whenUnsatisfiable: ScheduleAnyway <6> 
        labelSelector:
          matchLabels:
            app.kubernetes.io/instance: llamastackdistribution-sample <7>
----
+
<1> This example runs two llama stack pods for high availability.
<2> Specifies voluntary disruption tolerance for the pods. For example, in a voluntary disruption, this configuration keeps at least one server pod available.
<3> Specifies how to spread matching pods in the topology. 
<4> Instructs the scheduler to minimize replica imbalance across zones. With a skew of one and two replicas, the scheduler targets one Pod per zone when multiple zones are available 
<5> Configures and uses the nodeâ€™s zone label as the failure-domain for pod spreading.
<6> Configures and allows scheduling to proceed even when spread constraints cannot be met. For example, if the cluster has insufficient capacity, Pods are scheduled instead of remaining `Pending`.
<7> Ensures that only pods from the same application instance are considered when calculating spread

. To enable autoscaling for your Llama Stack server, add the following parameters to your `LlamaStackDistribution` CR:
+
[source,yaml]
----
spec:
  server:
      autoscaling: <1> 
        minReplicas: 1 <2> 
        maxReplicas: 5 <3> 
        targetCPUUtilizationPercentage: 75 <4> 
        targetMemoryUtilizationPercentage: 70 <5> 
----
+
<1> Configures HorizontalPodAutoscaler (HPA) for the server pods.
<2> Specifies the lower bound replica count maintained by the HPA. 
<3> Specifies the upper bound replica count maintained by the HPA.
<4> Configures CPU based scaling.
<5> Configures memory based scaling.

.Additional information

* https://docs.redhat.com/en/documentation/openshift_container_platform/latest/html/nodes/controlling-pod-placement-onto-nodes-scheduling#nodes-scheduler-pod-topology-spread-constraints[Controlling pod placement by using pod topology spread constraints].
* https://docs.redhat.com/en/documentation/openshift_container_platform/4.20/html/nodes/working-with-pods#nodes-pods-autoscaling[Automatically scaling pods with the horizontal pod autoscaling]
