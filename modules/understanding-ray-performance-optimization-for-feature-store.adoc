:_module-type: CONCEPT

[id="understanding-ray-performance-optimization-for-feature-store_{context}"]

= Understanding Ray performance optimization for Feature Store

[role="_abstract"]
Ray is a distributed execution engine that scales Feast feature engineering and retrieval-augmented generation (RAG) workloads. By processing large datasets in parallel, Ray accelerates pipelines and reduces costs compared to single-node processing.

Use the Ray automatic optimizations for increased efficiency.

. Enabling automatic optimization
.. The Ray compute engine includes several automatic optimizations:
* **Partition optimization:** Automatically determines optimal partition sizes
* **Join strategy selection:** Chooses between broadcast and distributed joins
* **Resource allocation:** Scales workers based on available resources
* **Memory management:** Handles out-of-core processing for large datasets

.Manual tuning example
If you have specific workloads that require custom tuning, you can fine-tune performance:
[source,yaml]
----
batch_engine:
    type: ray.engine
    # Fine-tuning for high-throughput scenarios
    broadcast_join_threshold_mb: 200      # Larger broadcast threshold
    max_parallelism_multiplier: 1        # Conservative parallelism
    target_partition_size_mb: 512        # Larger partitions
    window_size_for_joins: "2H"          # Larger time windows
----