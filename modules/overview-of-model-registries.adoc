:_module-type: CONCEPT

[id='overview-of-model-registries_{context}']
= Overview of model registries

[role='_abstract']

ifndef::upstream[]
[IMPORTANT]
====
ifdef::self-managed[]
Model registry and model catalog are currently available in {productname-long} {vernum} as Technology Preview features.
endif::[]
ifdef::cloud-service[]
Model registry and model catalog are currently available in {productname-long} as Technology Preview features.
endif::[]
Technology Preview features are not supported with {org-name} production service level agreements (SLAs) and might not be functionally complete.
{org-name} does not recommend using them in production.
These features provide early access to upcoming product features, enabling customers to test functionality and provide feedback during the development process.

For more information about the support scope of {org-name} Technology Preview features, see link:https://access.redhat.com/support/offerings/techpreview/[Technology Preview Features Support Scope].
====
endif::[]


A model registry is an important component in the lifecycle of an artificial intelligence/machine learning (AI/ML) model, and a vital part of any machine learning operations (MLOps) platform or ML workflow. A model registry acts as a central repository, holding metadata related to machine learning models from inception to deployment. This metadata ranges from high-level information like the deployment environment and project origins, to intricate details like training hyperparameters, performance metrics, and deployment events. A model registry acts as a bridge between model experimentation and serving, offering a secure, collaborative metadata store interface for stakeholders of the ML lifecycle.

Model registries provide a structured and organized way to store, share, version, deploy, and track models. 

ifdef::upstream[]
To use model registries in {productname-short}, an {openshift-platform} cluster administrator must enable the model registry component. For more information, see link:{odhdocshome}/working-with-model-registries/#enabling-the-model-registry-component_model-registry[Enabling the model registry component].

After the model registry component is enabled, an {productname-short} administrator can create model registries in {productname-short} and grant model registry access to the data scientists that will work with them. For more information, see link:{odhdocshome}/working-with-model-registries/#creating-a-model-registry_model-registry[Creating a model registry] and link:{odhdocshome}/working-with-model-registries/#managing-model-registry-permissions_model-registry[Managing model registry permissions].

Data scientists with access to a model registry can store, share, version, deploy, and track models using the model registry feature. For more information, see link:{odhdocshome}/working-with-model-registries/#working-with-model-registries_model-registry[Working with model registries]. 
endif::[]

ifndef::upstream[]
To use model registries in {productname-short}, an {openshift-platform} cluster administrator must enable the model registry component. For more information, see link:{rhoaidocshome}{default-format-url}/enabling_the_model_registry_component/enabling-the-model-registry-component_model-registry-config[Enabling the model registry component].

After the model registry component is enabled, an {productname-short} administrator can create model registries in {productname-short} and grant model registry access to the data scientists that will work with them. For more information, see link:{rhoaidocshome}{default-format-url}/managing_model_registries[Managing model registries].

Data scientists with access to a model registry can store, share, version, deploy, and track models using the model registry feature. For more information, see link:{rhoaidocshome}{default-format-url}/working_with_model_registries[Working with model registries]. 
endif::[]

With the addition of the model catalog feature, you can discover models that are available and ready for your organization to register, deploy, and customize. This functionality starts with connecting users with the Granite family of models, as well as the teacher and judge models used with the LAB-tuning workflow. 

ifdef::upstream[]
For more information about using the LAB-tuning workflow, see link:{odhdocshome}/customizing-models-with-lab-tuning/[Customizing models with LAB-tuning].
endif::[]

ifndef::upstream[]
For more information about using the LAB-tuning workflow, see link:{rhoaidocshome}{default-format-url}/customizing_models_with_lab-tuning/[Customizing models with LAB-tuning].
endif::[]

ifndef::cloud-service[]
[IMPORTANT]
====
The model catalog feature is not currently supported for disconnected environments.
====
endif::[]

//[role="_additional-resources"]
//.Additional resources
//*