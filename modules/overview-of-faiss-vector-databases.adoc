:_module-type: CONCEPT

[id="overview-of-faiss-vector-databases_{context}"]
= Overview of FAISS vector databases

FAISS (Facebook AI Similarity Search) is an open source library for high performance vector similarity search and clustering. It is optimized for dense numerical embeddings and supports both CPU and GPU execution. In {productname-short}, you can enable FAISS as an inline vector store within a Llama Stack deployment.

When inline FAISS is enabled, vector indexing and similarity search run directly inside the `LlamaStackDistribution` server process. This configuration does not require a separate external vector database service, making it suitable for development and evaluation workflows.

Inline FAISS enables efficient similarity search as part of retrieval augmented generation (RAG) workflows. Vector indexes are managed locally by the Llama Stack server, while vector metadata persistence uses the default Llama Stack metadata backend configured for the deployment. In {productname-short} 3.2 and later, this backend is PostgreSQL.

Inline FAISS provides the following benefits:

* Simple enablement without deploying an external vector database service
* Low latency vector ingestion and query execution
* Compatibility with the OpenAI-compatible Vector Stores API
* Integration with the default PostgreSQL-backed metadata store in {productname-short}

Inline FAISS is designed for single-instance operation and does not provide distributed indexing, replication, or high availability.

[NOTE]
====
Inline FAISS is best suited for development, testing, and evaluation environments. For production-grade RAG workloads that require scalability, durability, or multi-node operation, use a remote vector database such as Milvus or PostgreSQL with pgvector.
====
