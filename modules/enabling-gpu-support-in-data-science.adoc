:_module-type: PROCEDURE

[id='enabling-gpu-support_{context}']
= Enabling GPU support in {productname-short}

[role='_abstract']
Optionally, to ensure that your data scientists can use compute-heavy workloads in their models, you can enable graphics processing units (GPUs) in {productname-short}. To enable GPUs on OpenShift, you must install the NVIDIA GPU Operator. 

.Prerequisites
* You installed the link:https://access.redhat.com/documentation/en-us/openshift_container_platform/{ocp-latest-version}/html/specialized_hardware_and_driver_enablement/node-feature-discovery-operator[Node Feature Discovery Operator]. 

ifndef::self-managed[]
[IMPORTANT]
====
The NVIDIA GPU Add-on is no longer supported. Instead, enable GPUs by installing the NVIDIA GPU Operator. If your deployment has a previously-installed NVIDIA GPU Add-on, before you install the NVIDIA GPU Operator, use OpenShift Cluster Manager to uninstall the NVIDIA GPU Add-on from your cluster.
====
endif::[]

ifdef::upstream[]
.Procedure
. Install the NVIDIA GPU Operator. For more information, see link:https://docs.nvidia.com/datacenter/cloud-native/openshift/latest/index.html[NVIDIA GPU Operator on {org-name} OpenShift Container Platform^] in the NVIDIA documentation.
. Create an accelerator profile. For more information, see link:{odhdocshome}{default-format-url}/working_on_data_science_projects/working-on-data-science-projects/#working-with-accelerator-profiles_accelerators[Working with accelerator profiles].
endif::[]

ifdef::self-managed[]
ifndef::disconnected[]
[IMPORTANT]
====
Follow the instructions in this section only if you want to enable GPU support in an unrestricted self-managed environment. To enable GPU support in a disconnected self-managed environment, see link:{rhoaidocshome}{default-format-url}/installing_and_uninstalling_{url-productname-short}_in_a_disconnected_environment/enabling-gpu-support_install[Enabling GPU support in {productname-short}] instead.
====

.Procedure
. Install the NVIDIA GPU Operator. For more information, see link:https://docs.nvidia.com/datacenter/cloud-native/openshift/latest/index.html[NVIDIA GPU Operator on {org-name} OpenShift Container Platform^] in the NVIDIA documentation.
. Create an accelerator profile. For more information, see link:{rhoaidocshome}{default-format-url}/working_on_data_science_projects/working-with-accelerators_accelerators[Working with accelerators].
endif::[]

ifdef::disconnected[]

[IMPORTANT]
====
Follow the instructions in this section only if you want to enable GPU support in a disconnected self-managed environment. To enable GPU support in an unrestricted self-managed environment, see link:{rhoaidocshome}{default-format-url}/installing_and_uninstalling_{url-productname-short}/enabling-gpu-support_install[Enabling GPU support in {productname-short}] instead.
====

.Procedure
. Deploy the NVIDIA GPU Operator on an Openshift Container Platform. For more information, see link:https://docs.nvidia.com/datacenter/cloud-native/openshift/latest/mirror-gpu-ocp-disconnected.html[Deploy GPU Operators in a disconnected or airgapped environment^] in the NVIDIA documentation.
. Create an accelerator profile. For more information, see link:{rhoaidocshome}{default-format-url}/working_on_data_science_projects/working-with-accelerators_accelerators[Working with accelerators].
endif::[]
endif::[]

