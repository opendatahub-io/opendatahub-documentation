:_module-type: PROCEDURE

[id="running-the-demo-jupyter-notebooks-from-the-codeflare-sdk_{context}"]
= Running the demo Jupyter notebooks from the CodeFlare SDK

[role='_abstract']
To run the demo Jupyter notebooks from the CodeFlare SDK, you must provide environment-specific information.

In the examples in this procedure, you edit the demo Jupyter notebooks in JupyterLab to provide the required information, and then run the Jupyter notebooks.

.Prerequisites
ifndef::upstream[]
* You can access a data science cluster that is configured to run distributed workloads as described in link:{rhoaidocshome}{default-format-url}/managing_openshift_ai/managing-distributed-workloads_managing-rhoai[Managing distributed workloads].
endif::[]
ifdef::upstream[]
* You can access a data science cluster that is configured to run distributed workloads as described in link:{odhdocshome}/managing-odh/#managing-distributed-workloads_managing-odh[Managing distributed workloads].
endif::[]

* You can access the following software from your data science cluster:
** A Ray cluster image that is compatible with your hardware architecture
** The data sets and models to be used by the workload
** The Python dependencies for the workload, either in a Ray image or in your own Python Package Index (PyPI) server

ifndef::upstream[]
* You can access a data science project that contains a workbench, and the workbench is running a default workbench image that contains the CodeFlare SDK, for example, the *Standard Data Science* workbench. 
For information about projects and workbenches, see link:{rhoaidocshome}{default-format-url}/working_on_data_science_projects[Working on data science projects].
endif::[]
ifdef::upstream[]
* You can access a data science project that contains a workbench, and the workbench is running a default workbench image that contains the CodeFlare SDK, for example, the *Standard Data Science* workbench. 
For information about projects and workbenches, see link:{odhdocshome}/working-on-data-science-projects[Working on data science projects].
endif::[]

* You have administrator access for the data science project.
** If you created the project, you automatically have administrator access. 
** If you did not create the project, your cluster administrator must give you administrator access.

* You have logged in to {productname-long}, started your workbench, and logged in to JupyterLab.

ifndef::upstream[]
* You have downloaded the demo Jupyter notebooks provided by the CodeFlare SDK, as described in link:{rhoaidocshome}{default-format-url}/working_with_distributed_workloads/running-ray-based-distributed-workloads_distributed-workloads#downloading-the-demo-jupyter-notebooks-from-the-codeflare-sdk_distributed-workloads[Downloading the demo Jupyter notebooks from the CodeFlare SDK].
endif::[]
ifdef::upstream[]
* You have downloaded the demo Jupyter notebooks provided by the CodeFlare SDK, as described in link:{odhdocshome}/working-with-distributed-workloads/#downloading-the-demo-jupyter-notebooks-from-the-codeflare-sdk_distributed-workloads[Downloading the demo Jupyter notebooks from the CodeFlare SDK].
endif::[]


.Procedure
. Check whether your cluster administrator has defined a _default_ local queue for the Ray cluster.
+
You can use the `codeflare_sdk.list_local_queues()` function to view all local queues in your current namespace, and the resource flavors associated with each local queue.
+
Alternatively, you can use the OpenShift web console as follows:

.. In the OpenShift web console, select your project from the *Project* list.
.. Click *Search*, and from the *Resources* list, select *LocalQueue* to show the list of local queues for your project.
+
If no local queue is listed, contact your cluster administrator.
.. Review the details of each local queue: 
... Click the local queue name. 
... Click the *YAML* tab, and review the `metadata.annotations` section. 
+
If the `kueue.x-k8s.io/default-queue` annotation is set to `'true'`, the queue is configured as the default local queue. 
+
[NOTE]
====
If your cluster administrator does not define a default local queue, you must specify a local queue in each Jupyter notebook.
====

. In the JupyterLab interface, open the *demo-notebooks > guided-demos* folder. 
. Open all of the Jupyter notebooks by double-clicking each Jupyter notebook file.
+
Jupyter notebook files have the `.ipynb` file name extension.
. In each Jupyter notebook, ensure that the `import` section imports the required components from the CodeFlare SDK, as follows:
+
.Example import section
[source,bash]
----
from codeflare_sdk import Cluster, ClusterConfiguration, TokenAuthentication
----

. In each Jupyter notebook, update the `TokenAuthentication` section to provide the `token` and `server` details to authenticate to the OpenShift cluster by using the CodeFlare SDK.
+
ifndef::upstream[]
For information about how to find the server and token details, see link:{rhoaidocshome}{default-format-url}/working_with_distributed_workloads/preparing-the-distributed-training-environment_distributed-workloads#using-the-cluster-server-and-token-to-authenticate_distributed-workloads[Using the cluster server and token to authenticate].
endif::[]
ifdef::upstream[]
For information about how to find the server and token details, see link:{odhdocshome}/working-with-distributed-workloads/#using-the-cluster-server-and-token-to-authenticate_distributed-workloads[Using the cluster server and token to authenticate].
endif::[]

. Optional: If you want to use custom certificates, update the `TokenAuthentication` section to add the `ca_cert_path` parameter to specify the location of the custom certificates, as shown in the following example:
+
.Example authentication section
[source,bash]
----
auth = TokenAuthentication(
    token = "XXXXX",
    server = "XXXXX",
    skip_tls=False,
    ca_cert_path="/path/to/cert"
)
auth.login()
----
+
Alternatively, you can set the `CF_SDK_CA_CERT_PATH` environment variable to specify the location of the custom certificates.

. In each Jupyter notebook, update the cluster configuration section as follows:

.. If the `namespace` value is specified, replace the example value with the name of your project.
+
If you omit this line, the Ray cluster is created in the current project. 

.. If the `image` value is specified, replace the example value with a link to a suitable Ray cluster image.
The Python version in the Ray cluster image must be the same as the Python version in the workbench.
+
--
If you omit this line, one of the following Ray cluster images is used by default, based on the Python version detected in the workbench:

* Python 3.9: `quay.io/modh/ray:2.35.0-py39-cu121`
* Python 3.11: `quay.io/modh/ray:2.46.0-py311-cu121`

The default Ray images are compatible with NVIDIA GPUs that are supported by the specified CUDA version.
The default images are AMD64 images, which might not work on other architectures. 

Additional ROCm-compatible Ray cluster images are available, which are compatible with AMD accelerators that are supported by the specified ROCm version. 
These images are AMD64 images, which might not work on other architectures.

ifndef::upstream[]
For information about the latest available training images and their preinstalled packages, including the CUDA and ROCm versions, see link:https://access.redhat.com/articles/rhoai-supported-configs[{productname-long}: Supported Configurations].
endif::[]
--

.. If your cluster administrator has not configured a default local queue, specify the local queue for the Ray cluster, as shown in the following example:
+
.Example local queue assignment
[source,bash,subs="+quotes"]
----
local_queue="_your_local_queue_name_"
----

.. Optional: Assign a dictionary of `labels` parameters to the Ray cluster for identification and management purposes, as shown in the following example:
+
.Example labels assignment
[source,bash,subs="+quotes"]
----
labels = {"exampleLabel1": "exampleLabel1Value", "exampleLabel2": "exampleLabel2Value"}
----

. In the `2_basic_interactive.ipynb` Jupyter notebook, ensure that the following Ray cluster authentication code is included after the Ray cluster creation section:
+
.Ray cluster authentication code
[source,bash,subs="+quotes"]
----
from codeflare_sdk import generate_cert
generate_cert.generate_tls_cert(cluster.config.name, cluster.config.namespace)
generate_cert.export_env(cluster.config.name, cluster.config.namespace)
----
+
[NOTE]
====
Mutual Transport Layer Security (mTLS) is enabled by default in the CodeFlare component in {productname-short}.
You must include the Ray cluster authentication code to enable the Ray client that runs within a Jupyter notebook to connect to a secure Ray cluster that has mTLS enabled.
====

. Run the Jupyter notebooks in the order indicated by the file-name prefix (`0_`, `1_`, and so on).

ifndef::upstream[]
.. In each Jupyter notebook, run each cell in turn, and review the cell output.
.. If an error is shown, review the output to find information about the problem and the required corrective action. 
For example, replace any deprecated parameters as instructed.
See also link:{rhoaidocshome}{default-format-url}/working_with_distributed_workloads/troubleshooting-common-problems-with-distributed-workloads-for-users_distributed-workloads[Troubleshooting common problems with distributed workloads for users].
.. For more information about the interactive browser controls that you can use to simplify Ray cluster tasks when working within a Jupyter notebook, see link:{rhoaidocshome}{default-format-url}/working_with_distributed_workloads/running-ray-based-distributed-workloads_distributed-workloads#managing-ray-clusters-from-within-a-jupyter-notebook_distributed-workloads[Managing Ray clusters from within a Jupyter notebook].
endif::[]
ifdef::upstream[]
.. In each Jupyter notebook, run each cell in turn, and review the cell output.
.. If an error is shown, review the output to find information about the problem and the required corrective action. 
For example, replace any deprecated parameters as instructed.
See also link:{odhdocshome}/working-with-distributed-workloads/#troubleshooting-common-problems-with-distributed-workloads-for-users_distributed-workloads[Troubleshooting common problems with distributed workloads for users].
.. For more information about the interactive browser controls that you can use to simplify Ray cluster tasks when working within a Jupyter notebook, see link:{odhdocshome}/working-with-distributed-workloads/#managing-ray-clusters-from-within-a-jupyter-notebook_distributed-workloads[Managing Ray clusters from within a Jupyter notebook].
endif::[]

.Verification
. The Jupyter notebooks run to completion without errors. 
. In the Jupyter notebooks, the output from the `cluster.status()` function or `cluster.details()` function indicates that the Ray cluster is `Active`.

////
[role='_additional-resources']
.Additional resources
<Do we want to link to additional resources?>


* link:https://url[link text]
////
