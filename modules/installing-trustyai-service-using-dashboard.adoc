:_module-type: PROCEDURE

[id='installing-trustyai-service-using-dashboard_{context}']
= Installing the TrustyAI Service by using the dashboard

[role='_abstract']
The following procedure describes how to use the {productname-short} dashboard to install an instance of the TrustyAI service.

.Prerequisites

* A cluster administrator has configured monitoring for the model serving platform, as described in xref:configuring-monitoring-for-the-multi-model-serving-platform_monitor[Configuring monitoring for the multi-model serving platform].

[NOTE]
====
Model monitoring (the TrustyAI feature) is supported only on a _multi-model serving platform_ that is based on the ModelMesh component. It is not supported on a _single-model serving platform_ that is based on the KServe component.
====

* A cluster administrator has enabled the TrustyAI component, as described in xref:enabling-trustyai-component_monitor[Enabling the TrustyAI component].

ifndef::upstream[]
* If you are using specialized {productname-short} groups, you are part of the administrator group (for example, {oai-admin-group}). If you are not using specialized groups, you are part of the {openshift-platform} administrator group.

* The data scientist has created a data science project, as described in link:{rhoaidocshome}{default-format-url}/working_on_data_science_projects/using-data-science-projects_projects#creating-a-data-science-project_projects[Creating a data science project], that contains (or will contain) the models that the data scientist wants to monitor.
endif::[]

ifdef::upstream[]
* If you are using specialized {productname-short} groups, you are part of the administrator group (for example, {odh-admin-group}). If you are not using specialized groups, you are part of the {openshift-platform} administrator group.

* The data scientist has created a data science project, as described in link:{odhdocshome}/working-on-data-science-projects/#creating-a-data-science-project_projects[Creating a data science project], that contains (or will contain) the models that the data scientist wants to monitor.
endif::[]

.Procedure
. Log in to {productname-short}.
. From the {productname-short} dashboard, click *Data Science Projects*.
+
The *Data Science Projects* page opens.
. Click the name of the project that contains (or will contain) the models that the data scientist wants to monitor.
+
A project details page opens.
. Click the *Settings* tab.
. Select the *Enable model bias monitoring* checkbox.

.Verification
ifdef::upstream,self-managed[]
. In the {openshift-platform} web console, click *Workloads* → *Pods*.
endif::[]
ifdef::cloud-service[]
. In the OpenShift web console, click *Workloads* → *Pods*.
endif::[]
. From the project list, select the project in which you installed TrustyAI.
. Confirm that the *Pods* list includes a running pod for the TrustyAI service. The pod has a naming pattern similar to the following example:
+
----
trustyai-service-5d45b5884f-96h5z
----
