:_module-type: CONCEPT

[id='overview-of-pipeline-runs_{context}']
= Overview of pipeline runs

[role='_abstract']
A pipeline run is a single execution of a data science pipeline. As data scientist, you can use {productname-short} to define, manage, and track executions of a data science pipeline. You can view a record of previously executed, scheduled, and archived runs from the *Runs* page in the {productname-short} user interface.

You can optimize your use of pipeline runs for portability and repeatability by using pipeline experiments. With experiments, you can logically group pipeline runs and try different configurations of your pipelines. You can also clone your pipeline runs to reproduce and scale them, or archive them when you want to retain a record of their execution, but no longer require them. You can delete archived runs that you no longer want to retain, or you can restore them to their former state. 

You can execute a run once, that is, immediately after its creation, or on a recurring basis. Recurring runs consist of a copy of a pipeline with all of its parameter values and a run trigger. A run trigger indicates when a recurring run executes. You can define the following run triggers:

* Periodic: used for scheduling runs to execute in intervals.
* Cron: used for scheduling runs as a cron job.

You can also configure up to 10 instances of the same run to execute concurrently. You can track the progress of a run from the run details page on the {productname-short} user interface. From here, you can view the graph and output artifacts for the run. 

A pipeline run can be in one of the following states: 

* Scheduled: A pipeline run that is scheduled to execute at least once
* Active: A pipeline run that is executing, or stopped.
* Archived: An archived pipeline run. 

You can use catch up runs to ensure your pipeline runs do not permanently fall behind schedule when paused. For example, if you re-enable a paused recurring run, the run scheduler backfills each missed run interval. If you disable catch up runs, and you have a scheduled run interval ready to execute, the run scheduler only schedules the run execution for the latest run interval. Catch up runs are enabled by default. However, if your pipeline handles backfill internally, Red Hat recommends that you disable catch up runs to avoid duplicate backfill. 

After a pipeline run executes, you can view details of its executed tasks on the *Executions* page, along with its artifacts, on the *Artifacts* page. From the *Executions* page, you can view the execution status of each task, which indicates whether it completed successfully. You can also view further information about each executed task by clicking the execution name in the list. From the *Artifacts* page, you can view the details of each pipeline artifact, such as its name, unique ID, type, and URI. Pipeline artifacts can help you to evaluate the performance of your pipeline runs and make it easier to understand your pipeline components. Pipeline artifacts can range from plain text data to detailed, interactive data visualizations.

You can view further information about each artifact by clicking the artifact name in the list. You can also view or download the content of artifacts that are stored in S3-compatible object storage by clicking the active artifact URI link in the list. 

[NOTE]
====
Artifacts that are not stored in S3-compatible object storage are not available to download, and will not appear with an active URI link.
====

If your browser can display the artifact content, for example, if the artifact is plain text, HTML, or markdown, the content does not download, but is automatically displayed in a new browser tab. If your browser cannot display the artifact content, for example, if the artifact is a model, the artifact automatically downloads instead. To download an artifact which is displayed in a browser tab, right-click on the content and then click *Save as*. 

You can review and analyze logs for each step in an active pipeline run. With the log viewer, you can search for specific log messages, view the log for each step, and download the step logs to your local machine.

//[role="_additional-resources"]
//.Additional resources
//*
