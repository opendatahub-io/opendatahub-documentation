:_module-type: CONCEPT
[id="playground-prerequisites_{context}"]
= Playground prerequisites

[role="_abstract"]
Before you can configure and use the gen AI playground feature, you must meet prerequisites at both the cluster and user levels.

== Cluster administrator prerequisites

Before a user can configure a playground instance, a cluster administrator must complete the following setup tasks:

* Ensure that {productname-short} is installed on an {openshift-platform} cluster running version 4.19 or later.
ifndef::upstream[]
* Set the value of the `spec.dashboardConfig.genAiStudio` dashboard configuration option to `true`. For more information, see link:{rhoaidocshome}{default-format-url}/managing_resources/customizing-the-dashboard#ref-dashboard-configuration-options_dashboard[Dashboard configuration options].
endif::[]
ifdef::upstream[]
* Set the value of the `spec.dashboardConfig.genAiStudio` dashboard configuration option to `true`. For more information, see link:{odhdocshome}/managing-resources/#ref-dashboard-configuration-options_dashboard[Dashboard configuration options].
endif::[]
* If using {productname-short} groups, add users to the {user-group} and {admin-group} OpenShift group.
ifndef::upstream[]
* Ensure that the Llama Stack Operator is enabled on the {openshift-platform} cluster by setting its `managementState` field to `Managed` in the `DataScienceCluster` custom resource (CR) of the {productname-short} Operator. For more information, see {rhoaidocshome}{default-format-url}/working_with_llama_stack/activating-the-llama-stack-operator_rag[Activating the Llama Stack Operator].
endif::[]
ifdef::upstream[]
* Ensure that the Llama Stack Operator is enabled on the {openshift-platform} cluster by setting its `managementState` field to `Managed` in the `DataScienceCluster` custom resource (CR) of the {productname-short} Operator. For more information, see {odhdocshome}/working-with-llama-stack/#activating-the-llama-stack-operator_rag[Activating the Llama Stack Operator].
endif::[]
ifndef::upstream[]
* Configure the Model Context Protocol (MCP) servers to test models with external tools. For more information, see link:{rhoaidocshome}{default-format-url}/experimenting_with_models_in_the_gen_ai_playground/playground-prerequisites_rhoai-user#configuring-model-context-protocol-servers_rhoai-user[Configuring model context protocol servers].
endif::[]
ifdef::upstream[]
* Configure the Model Context Protocol (MCP) servers to test models with external tools. For more information, see link:{odhdocshome}/experimenting_with_models_in_the_gen_ai_playground/#configuring-model-context-protocol-servers_odh-user[Configuring model context protocol servers].
endif::[]

== User prerequisites

After the cluster administrator completes the setup, you must complete the following tasks before you can configure your playground instance:

* You are logged in to {productname-short}.
* If you are using {productname-short} groups, you are a member of the appropriate user or admin group.
ifndef::upstream[]
* Create a project. The playground instance is tied to a project context. For more information, see link:{rhoaidocshome}{default-format-url}/working_on_projects/using-projects_projects#creating-a-project_projects[Creating a project].
endif::[]
ifdef::upstream[]
* Create a project. The playground instance is tied to a project context. For more information, see link:{odhdocshome}/working-on-projects/#creating-a-project_projects[Creating a project].
endif::[]
ifdef::upstream[]
* Add a connection to your project. For more information about creating connections, see link:{odhdocshome}/working-on-projects/#adding-a-connection-to-your-project_projects[Adding a connection to your project].
endif::[]
ifndef::upstream[]
* Add a connection to your project. For more information about creating connections, see link:{rhoaidocshome}/html/working_on_projects/using-connections_projects#adding-a-connection-to-your-project_projects[Adding a connection to your project].
endif::[]
ifdef::upstream[]
* Deploy a model in your project and make it available as an AI asset endpoint. For more information, see link:{odhdocshome}/deploying_models/#deploying-models-on-the-model-serving-platform_odh-user[Deploying models on the model serving platform^].
endif::[]
ifndef::upstream[]
* Deploy a model in your project and make it available as an AI asset endpoint. For more information, see link:{rhoaidocshome}{default-format-url}/deploying_models/deploying_models_on_the_model_serving_platform#deploying-models-on-the-model-serving-platform_rhoai-user[Deploying models on the model serving platform^].
endif::[]

After you complete these tasks, the project is ready for you to configure your playground instance.