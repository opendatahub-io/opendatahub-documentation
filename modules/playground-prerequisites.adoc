:_module-type: PROCEDURE
[id="playground-prerequisites_{context}"]
= Playground prerequisites

[role="_abstract"]
Before you can configure and use the gen AI playground feature, you must meet prerequisites at both the cluster and user levels.

== Cluster administrator prerequisites

Before a user can configure a playground instance, a cluster administrator must complete the following setup tasks:

* Ensure that {productname-short} is installed on an {openshift-platform} cluster running version 4.19 or later.
ifndef::upstream[]
* Set the value of the `spec.dashboardConfig.genAiStudio` dashboard configuration option to `true`. For more information, see link:{rhoaidocshome}{default-format-url}/managing_resources/customizing-the-dashboard#ref-dashboard-configuration-options_dashboard[Dashboard configuration options].  
endif::[]
ifdef::upstream[]
* Set the value of the `spec.dashboardConfig.genAiStudio` dashboard configuration option to `true`. For more information, see link:{odhdocshome}/managing-resources/#ref-dashboard-configuration-options_dashboard[Dashboard configuration options].
endif::[]
* If using {productname-short} groups, add users to the {user-group} and {admin-group} OpenShift group.
ifndef::upstream[]
* Ensure that the Llama Stack Operator is enabled on the {openshift-platform} cluster by setting its `managementState` field to `Managed` in the `DataScienceCluster` custom resource (CR) of the {productname-short} Operator. For more information, see {rhoaidocshome}{default-format-url}/working_with_llama_stack/activating-the-llama-stack-operator_rag[Activating the Llama Stack Operator].
endif::[]
ifdef::upstream[]
* Ensure that the Llama Stack Operator is enabled on the {openshift-platform} cluster by setting its `managementState` field to `Managed` in the `DataScienceCluster` custom resource (CR) of the {productname-short} Operator. For more information, see {odhdocshome}/working-with-llama-stack/#activating-the-llama-stack-operator_rag[Activating the Llama Stack Operator].
endif::[]

== User prerequisites

After the cluster administrator completes the setup, you must complete the following tasks before you can configure your playground instance:

* You are logged in to {productname-short}.
* If you are using {productname-short} groups, you are a member of the appropriate user or admin group.
* Create a project. The playground instance is tied to a project context.
ifndef::upstream[]
** For more information, see link:{rhoaidocshome}{default-format-url}/working_on_projects/using-projects_projects#creating-a-project_projects[Creating a project].
endif::[]
ifdef::upstream[]
** For more information, see link:{odhdocshome}/working-on-projects/#creating-a-project_projects[Creating a project].
endif::[]

* Add a connection to your project.
ifdef::upstream[]
** For more information about creating connections, see link:{odhdocshome}/working-on-projects/#adding-a-connection-to-your-project_projects[Adding a connection to your project].
endif::[]
ifndef::upstream[]
** For more information about creating connections, see link:{rhoaidocshome}/html/working_on_projects/using-connections_projects#adding-a-connection-to-your-project_projects[Adding a connection to your  project].
endif::[]

* Deploy a model in your project and make it available as an AI asset endpoint.
ifdef::upstream[]
** For more information, see link:{odhdocshome}/deploying_models/#deploying-models-on-the-model-serving-platform_odh-user[Deploying models on the model serving platform^].
endif::[]
ifndef::upstream[]
** For more information, see link:{rhoaidocshome}{default-format-url}/deploying_models/deploying_models_on_the_single_model_serving_platform#deploying-models-on-the-model-serving-platform_rhoai-user[Deploying models on the model serving platform^].
endif::[]
+
[NOTE]
====
The model that you are deploying must support tool-calling and have tool-calling capabilities enabled. For more information, see link:https://docs.vllm.ai/en/stable/features/tool_calling.html[Tool calling] in the VLLM documentation.
====

* Configure MCP server connections.
** To test models with external tools, you must configure any Model Control Protocol (MCP) servers.

After you complete these tasks, the project is ready for you to configure your playground instance.

