:_module-type: CONCEPT

[id='overview-of-accelerators_{context}']
= Overview of accelerators

[role='_abstract']
If you work with large data sets, you can use accelerators to optimize the performance of your data science models in {productname-short}. With accelerators, you can scale your work, reduce latency, and increase productivity. You can use accelerators in {productname-short} to assist your data scientists in the following tasks:

* Natural language processing (NLP)
* Inference
* Training deep neural networks
* Data cleansing and data processing

{productname-short} supports the following accelerators: 

* NVIDIA graphics processing units (GPUs)
** To use compute-heavy workloads in your models, you can enable NVIDIA graphics processing units (GPUs) in {productname-short}. 
**   To enable GPUs on OpenShift, you must install the link:https://docs.nvidia.com/datacenter/cloud-native/openshift/latest/index.html[NVIDIA GPU Operator].
* Habana Gaudi devices (HPUs)
** Habana, an Intel company, provides hardware accelerators intended for deep learning workloads. You can use the Habana libraries and software associated with Habana Gaudi devices available from your notebook.
** Before you can successfully enable Habana Gaudi devices on {productname-short}, you must install the necessary dependencies and version 1.10 of the HabanaAI Operator. For more information about how to enable your OpenShift environment for Habana Gaudi devices, see link:https://docs.habana.ai/en/v1.10.0/Orchestration/HabanaAI_Operator/index.html[HabanaAI Operator for OpenShift]. 
** Before you can enable Habana Gaudi devices in {productname-short}, you must install the necessary dependencies and the version of the HabanaAI Operator that matches the Habana version of the HabanaAI workbench image in your deployment. For more information about how to enable your OpenShift environment for Habana Gaudi devices, see link:https://docs.habana.ai/en/v1.10.0/Orchestration/HabanaAI_Operator/index.html[HabanaAI Operator v1.10 for OpenShift] and link:https://docs.habana.ai/en/v1.13.0/Orchestration/HabanaAI_Operator/index.html[HabanaAI Operator v1.13 for OpenShift].
** You can enable Habana Gaudi devices on-premises or with AWS DL1 compute nodes on an AWS instance.

Before you can use an accelerator in {productname-short}, your OpenShift instance must contain an associated accelerator profile. For accelerators that are new to your deployment, you must configure an accelerator profile for the accelerator in context. You can create an accelerator profile from the *Settings* -> *Accelerator profiles* page on the {productname-short} dashboard. If your deployment contains existing accelerators that had associated accelerator profiles already configured, an accelerator profile is automatically created after you upgrade to the latest version of {productname-short}.

[role="_additional-resources"]
.Additional resources
* link:https://docs.habana.ai/en/v1.10.0/Orchestration/HabanaAI_Operator/index.html[HabanaAI Operator v1.10 for OpenShift]
* link:https://docs.habana.ai/en/v1.13.0/Orchestration/HabanaAI_Operator/index.html[HabanaAI Operator v1.13 for OpenShift]
* link:https://habana.ai/[Habana, an Intel Company]
* link:https://aws.amazon.com/ec2/instance-types/dl1/[Amazon EC2 DL1 Instances]  
* link:https://linux.die.net/man/8/lspci[lspci(8) - Linux man page]
