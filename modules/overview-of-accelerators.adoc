:_module-type: CONCEPT

[id='overview-of-accelerators_{context}']
= Overview of accelerators

[role='_abstract']
If you work with large data sets, you can use accelerators to optimize the performance of your data science models in {productname-short}. With accelerators, you can scale your work, reduce latency, and increase productivity. You can use accelerators in {productname-short} to assist your data scientists in the following tasks:

* Natural language processing (NLP)
* Inference
* Training deep neural networks
* Data cleansing and data processing

You can use the following accelerators with {productname-short}:

* NVIDIA graphics processing units (GPUs)
** To use compute-heavy workloads in your models, you can enable NVIDIA graphics processing units (GPUs) in {productname-short}.
** To enable NVIDIA GPUs on OpenShift, you must install the link:https://docs.nvidia.com/datacenter/cloud-native/openshift/latest/index.html[NVIDIA GPU Operator].
* AMD graphics processing units (GPUs)
** Use the AMD GPU Operator to enable AMD GPUs for workloads such as AI/ML training and inference.
** To enable AMD GPUs on OpenShift, you must do the following tasks:
*** Install the AMD GPU Operator.
*** Follow the instructions for full deployment and driver configuration in the link:https://instinct.docs.amd.com/projects/gpu-operator/en/latest/index.html[AMD GPU Operator documentation].

** Once installed, the AMD GPU Operator allows you to use the ROCm workbench images to streamline AI/ML workflows on AMD GPUs.
* Intel Gaudi AI accelerators
** Intel provides hardware accelerators intended for deep learning workloads.
** Before you can enable Intel Gaudi AI accelerators in {productname-short}, you must install the necessary dependencies. Also, the version of the Intel Gaudi AI Operator that you install must match the version of the corresponding workbench image in your deployment.
** A workbench image for Intel Gaudi accelerators is not included in {productname-short} by default. Instead, you must create and configure a custom notebook to enable Intel Gaudi AI support.
** You can enable Intel Gaudi AI accelerators on-premises or with AWS DL1 compute nodes on an AWS instance.
ifndef::upstream[]
* Before you can use an accelerator in {productname-short}, you must enable GPU support in {productname-short}. This includes installing the Node Feature Discovery operator and NVIDIA GPU Operators. For more information, see link:https://docs.redhat.com/en/documentation/openshift_container_platform/{ocp-latest-version}/html/specialized_hardware_and_driver_enablement/psap-node-feature-discovery-operator#installing-the-node-feature-discovery-operator_psap-node-feature-discovery-operator[Installing the Node Feature Discovery operator^] and link:{rhoaidocshome}{default-format-url}/managing_openshift_ai/enabling_accelerators#enabling-nvidia-gpus_managing-rhoai[Enabling NVIDIA GPUs^].
endif::[]
ifdef::upstream[]
* Before you can use an accelerator in {productname-short}, you must enable GPU support in {productname-short}. This includes installing the Node Feature Discovery and NVIDIA GPU Operators. For more information, see link:https://docs.nvidia.com/datacenter/cloud-native/openshift/latest/index.html[NVIDIA GPU Operator on {org-name} OpenShift Container Platform^] in the NVIDIA documentation. 
endif::[]
In addition, your OpenShift instance must contain an associated accelerator profile. For accelerators that are new to your deployment, you must configure an accelerator profile for the accelerator in context. You can create an accelerator profile from the *Settings* -> *Accelerator profiles* page on the {productname-short} dashboard. If your deployment contains existing accelerators that had associated accelerator profiles already configured, an accelerator profile is automatically created after you upgrade to the latest version of {productname-short}.

[role="_additional-resources"]
.Additional resources
* link:https://habana.ai/[Habana, an Intel Company]
* link:https://aws.amazon.com/ec2/instance-types/dl1/[Amazon EC2 DL1 Instances]
* link:https://rocm.docs.amd.com/en/latest/[AMD ROCm documentation]
* link:https://github.com/ROCm/gpu-operator[AMD GPU Operator on GitHub]
* link:https://linux.die.net/man/8/lspci[lspci(8) - Linux man page]