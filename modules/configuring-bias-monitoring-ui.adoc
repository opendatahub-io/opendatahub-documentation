:_module-type: PROCEDURE

[id='configuring-bias-monitoring-for-a-model-ui_{context}']
= Configuring bias monitoring for a model in the dashboard

ifndef::upstream[]
[IMPORTANT]
====
The TrustyAI features are for Technology Preview only. Technology Preview features are not supported with {org-name} production service level agreements (SLAs), might not be functionally complete, and {org-name} does not recommend using them for production. These features provide early access to upcoming product features, enabling customers to test functionality and provide feedback during the development process. 			
For more information on {org-name} Technology Preview features, see link:https://access.redhat.com/support/offerings/techpreview/ [Technology Preview Features Scope]. 		
====
endif::[]

[role='_abstract']
To monitor a deployed model for bias, you must first configure bias metrics. When you configure bias metrics, you specify details relevant to your model such as a protected attribute, privileged and unprivileged groups, a model outcome and value that you want to monitor, and the acceptable threshold for bias.

.Prerequisites
* You are familiar with the bias metrics that {productname-short} supports and how to interpret them. 
* You have installed {productname-short} and deployed the TrustyAI service.
//,as described in - link to install guide

.Procedure
. In the left menu of the {productname-short} dashboard, click *Model Serving*.
+
The *Model serving* page opens.

. On the *Model serving* page, click the name of a model that you want to configure bias metrics for.
+
A metrics page for the model opens. By default, the *Endpoint Performance* tab is selected.

. Click the *Model Bias* tab.
+
The page shows that no metrics are configured by default.
. Click *Configure*.
+
The *Configure bias metrics* dialog opens.

. In the dialog, to configure bias metrics, perform the following actions:
.. In the *Metric name* field, enter a unique name for your bias metric.
.. From the *Metric type* list, select one of the metrics types that are available in {productname-short}.
.. In the *Protected attribute* field, enter the name of an attribute in your model that you want to monitor for bias.
.. In the *Privileged value* field, enter the name of a privileged group for the protected attribute that you specified.
.. In the *Unprivileged value* field, enter the name of an unprivileged group for the protected attribute that you specified.
.. In the *Output* field, enter the name of the model outcome that you want to monitor for bias.
.. In the *Output value* field enter the value of the outcome that you want to monitor for bias.
.. In the *Violation threshold* field, enter the bias threshold for your selected metric type. This threshold value defines how far the specified metric can be from the fairness value for your metric, before the model is considered biased. 
.. In the *Metric batch size* field, enter the number of model inferences that {productname-short} includes each time it calculates the metric.
. To finish, click *Configure*.
+
The *Bias metric configuration* page shows the bias metrics that you configured for the model.
. Optional: To start viewing metrics, on the *Bias metric configuration* page, click *View metrics* in the upper-right corner.

.Verification
* The *Bias metric configuration* page shows the bias metrics that you configured for your model.

