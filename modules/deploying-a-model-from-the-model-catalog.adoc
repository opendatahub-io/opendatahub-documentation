:_module-type: PROCEDURE

[id='deploying-a-model-from-the-model-catalog_{context}']
= Deploying a model from the model catalog

[role='_abstract']
You can deploy models directly from the model catalog. 

[IMPORTANT]
====
The model catalog feature is not currently supported for disconnected environments.
====

[NOTE]
====
ifdef::upstream,self-managed[]
{productname-short} model serving deployments use the global cluster pull secret to pull models in ModelCar format from the catalog. For more information about using pull secrets in {openshift-platform}, see link:https://docs.redhat.com/en/documentation/openshift_container_platform/{ocp-latest-version}/html/images/managing-images#images-update-global-pull-secret_using-image-pull-secrets[Updating the global cluster pull secret] in the {openshift-platform} documentation.

endif::[]
ifdef::cloud-service[]
{productname-short} model serving deployments use the global cluster pull secret to pull models in ModelCar format from the catalog. For more information about using pull secrets in {openshift-platform}, see link:https://docs.redhat.com/en/documentation/red_hat_openshift_service_on_aws/4/html/images/managing-images#using-image-pull-secrets[Using image pull secrets] in the Red Hat OpenShift Service on AWS documentation, or link:https://docs.redhat.com/en/documentation/openshift_dedicated/4/html/authentication_and_authorization/understanding-and-creating-service-accounts#auto-generated-sa-token-secrets_understanding-service-accounts[Automatically generated image pull secrets] in the OpenShift Dedicated documentation.
endif::[]
====

.Prerequisites
ifdef::upstream[]
* To deploy a model from the model catalog, you have fulfilled the prerequisites described in link:{odhdocshome}/serving-models/#deploying-models-on-the-single-model-serving-platform_serving-large-models[Deploying a model on the single-model serving platform].
endif::[]
ifndef::upstream[]
* To deploy a model from the model catalog, you have fulfilled the prerequisites described in link:{rhoaidocshome}{default-format-url}/serving_models/serving-large-models_serving-large-models#deploying-models-on-the-single-model-serving-platform_serving-large-models[Deploying a model by using the single-model serving platform].
endif::[]
ifdef::upstream[]
* A cluster administrator has configured and enabled the model registry component in your {productname-short} deployment. For more information, see link:{odhdocshome}/working-with-model-registries/#configuring-the-model-registry-component_model-registry[Configuring the model registry component].
endif::[]
ifndef::upstream[]
* A cluster administrator has configured and enabled the model registry component in your {productname-short} deployment. For more information, see link:{rhoaidocshome}{default-format-url}/configuring_the_model_registry_component/configuring-the-model-registry-component_model-registry-config[Configuring the model registry component].
endif::[]
ifdef::upstream[]
* You have enabled the model catalog feature as described in link:{odhdocshome}/working-with-model-registries/#enabling-the-model-catalog_model-registry[Enabling the model catalog].
endif::[]
ifndef::upstream[]
* You have enabled the model catalog feature as described ine link:{rhoaidocshome}{default-format-url}/configuring_the_model_registry_component/enabling-the-model-catalog_model-registry-config[Enabling the model catalog].
endif::[]


.Procedure
. From the {productname-short} dashboard, click *Models* -> *Model catalog*.
. From the *{org-name} models* section, click the name of the model that you want to deploy. 
+
The model details page opens.
. Click *Deploy model*.
+
The *Deploy model* dialog opens.
. From the *Project* drop-down list, select a project in which to deploy your model.
+
[NOTE]
====
Models using an OCI storage location support deployment only to the single-model serving platform. Projects using the multi-model serving platform do not appear in the project list.
====
. In the *Model deployment* section:
.. Optional: In the *Model deployment name* field, enter a unique name for your model deployment. The *Model deployment name* is autofilled with a value that contains the model name by default. 
+
This is the name of the inference service created when the model is deployed.
.. Optional: Click *Edit resource name*, and then enter a specific resource name for the model deployment in the *Resource name* field. By default, the resource name will match the name of the model registry.
+
[IMPORTANT]
====
Resource names are what your resources are labeled as in OpenShift. Your resource name cannot exceed 253 characters, must consist of lowercase alphanumeric characters or '-', and must start and end with an alphanumeric character. Resource names are not editable after creation.

The resource name must not match the name of any other model deployment resource in your {openshift-platform} cluster.
====
.. From the *Serving runtime* list, select a model-serving runtime that is installed and enabled in your {productname-short} deployment.
.. From the *Model framework* list, select a framework for your model.
+
NOTE: The *Model framework* list shows only the frameworks that are supported by the model serving runtime that you specified when you deployed your model.
+
ifndef::upstream[]
. From the **Deployment mode** list, select *Standard* or *Advanced*. For more information about deployment modes, see link:{rhoaidocshome}{default-format-url}/serving_models/serving-large-models_serving-large-models#about-kserve-deployment-modes_serving-large-models[About KServe deployment modes].
endif::[]
ifdef::upstream[]
. From the **Deployment mode** list, select *Standard* or *Advanced*. For more information about deployment modes, see link:{odhdocshome}/serving-models/#about-kserve-deployment-modes_serving-large-models[About KServe deployment modes].
endif::[]
.. In the *Number of model server replicas to deploy* field, specify a value.
.. From the *Model server size* list, select a value.
.. If you have created a hardware profile, select a hardware profile from the *Hardware profile* list.
+
[IMPORTANT]
====
By default, hardware profiles are hidden from appearing in the dashboard navigation menu and user interface. In addition, user interface components associated with the deprecated accelerator profiles functionality are still displayed. To show the *Settings -> Hardware profiles* option in the dashboard navigation menu and the user interface components associated with hardware profiles, set the `disableHardwareProfiles` value to `false` in the `OdhDashboardConfig` custom resource (CR) in {openshift-platform}. 
ifndef::upstream[]
For more information, see link:{rhoaidocshome}/html/managing_openshift_ai/customizing-the-dashboard#ref-dashboard-configuration-options_dashboard[Dashboard configuration options].
endif::[]
ifdef::upstream[]
For more information, see link:{odhdocshome}/managing-odh/#ref-dashboard-configuration-options_dashboard[Dashboard configuration options].
endif::[] 
====
..  In the *Model route* section, select the *Make deployed models available through an external route* checkbox to make your deployed models available to external clients.
.. In the *Token authentication* section, select the *Require token authentication* checkbox to require token authentication for your model server. To finish configuring token authentication, perform the following actions:
... In the *Service account name* field, enter a service account name for which the token will be generated. The generated token is created and displayed in the *Token secret* field when the model server is configured.
... To add an additional service account, click *Add a service account* and enter another service account name.
. In the *Source model location* section, select *Current URI* to deploy the selected model from the catalog.
. Optional: Customize the runtime parameters in the *Configuration parameters* section:
.. Modify the values in *Additional serving runtime arguments* to define how the deployed model behaves.
.. Modify the values in *Additional environment variables* to define variables in the model's environment.
. Click *Deploy*.

.Verification
* The model appears on the *Deployments* tab for the model version.

[role="_additional-resources"]
.Additional resources
ifdef::upstream[]
* For more information about deployment options on the single-model serving platform, seelink:{odhdocshome}/serving-models/#deploying-models-on-the-single-model-serving-platform_serving-large-models[Deploying a model on the single-model serving platform].
endif::[]
ifndef::upstream[]
* For more information about deployment options on the single-model serving platform, see link:{rhoaidocshome}{default-format-url}/serving_models/serving-large-models_serving-large-models#deploying-models-on-the-single-model-serving-platform_serving-large-models[Deploying a model by using the single-model serving platform].
endif::[]