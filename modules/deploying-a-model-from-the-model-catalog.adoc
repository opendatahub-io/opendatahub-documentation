:_module-type: PROCEDURE

[id='deploying-a-model-from-the-model-catalog_{context}']
= Deploying a model from the model catalog

[role='_abstract']
You can deploy models directly from the model catalog. 

[NOTE]
====
{productname-short} model serving deployments use the global cluster pull secret to pull models in ModelCar format from the catalog. 

ifdef::upstream,self-managed[]
For more information about using pull secrets in {openshift-platform}, see link:https://docs.redhat.com/en/documentation/openshift_container_platform/{ocp-latest-version}/html/images/managing-images#images-update-global-pull-secret_using-image-pull-secrets[Updating the global cluster pull secret] in the {openshift-platform} documentation.
endif::[]
====

.Prerequisites
ifdef::upstream[]
* You have completed the prerequisites in link:{odhdocshome}/deploying-models/#deploying-models-on-the-model-serving-platform_odh-user[Deploying models].
endif::[]
ifndef::upstream[]
* You have completed the prerequisites in link:{rhoaidocshome}{default-format-url}/deploying_models/deploying_models_on_the_model_serving_platform#deploying-models-on-the-model-serving-platform_rhoai-user[Deploying models].
endif::[]
ifdef::upstream[]
* The model registry component is enabled in your {productname-short} deployment. For more information, see link:{odhdocshome}/working-with-model-registries/#enabling-the-model-registry-component_model-registry[Enabling the model registry component].
endif::[]
ifdef::self-managed[]
* The model registry component is enabled in your {productname-short} deployment. For more information, see link:{rhoaidocshome}{default-format-url}/enabling_the_model_registry_component[Enabling the model registry component].
endif::[]


.Procedure
. From the {productname-short} dashboard, click *AI hub* -> *Catalog*.
. The *Model Catalog* page provides a high-level view of available models, including the model category, name, description, and labels such as task, license, and provider.
. You can use the search bar to search by model name, description, or provider.
. You can use the filter menu to search and select filters by task, provider, or license. 
. Click the name of a model to view the model details page.
. Click *Deploy model* to display the *Deploy model* dialog.
. From the *Project* drop-down list, select a project in which to deploy your model.
. In the *Model deployment* section:
.. Optional: In the *Model deployment name* field, enter a unique name for your model deployment. This field is autofilled with a value that contains the model name by default. 
+
This is the name of the inference service created when the model is deployed.
.. Optional: Click *Edit resource name*, and then enter a specific resource name for the model deployment in the *Resource name* field. By default, the resource name matches the name of the model deployment.
+
[IMPORTANT]
====
Resource names are what your resources are labeled as in OpenShift. Your resource name cannot exceed 253 characters, must consist of lowercase alphanumeric characters or '-', and must start and end with an alphanumeric character. Resource names are not editable after creation.

The resource name must not match the name of any other model deployment resource in your {openshift-platform} cluster.
====
.. From the *Serving runtime* list, select a model-serving runtime that is installed and enabled in your {productname-short} deployment.
If project-scoped runtimes exist, the *Serving runtime* list includes subheadings to distinguish between global runtimes and project-scoped runtimes.
.. From the *Model framework* list, select a framework for your model.
+
NOTE: The *Model framework* list shows only the frameworks that are supported by the model-serving runtime that you specified when you deployed your model.
+
ifndef::upstream[]
. From the **Deployment mode** list, select *KServe RawDeployment* or *Knative Serverless*. For more information about deployment modes, see link:{rhoaidocshome}{default-format-url}/deploying_models/deploying_models_on_the_model_serving_platform#about-kserve-deployment-modes_rhoai-user[About KServe deployment modes].
endif::[]
ifdef::upstream[]
. From the **Deployment mode** list, select *KServe RawDeployment* or *Knative Serverless*. For more information about deployment modes, see link:{odhdocshome}/deploying-models/#about-kserve-deployment-modes_odh-user[About KServe deployment modes].
endif::[]
.. In the *Number of model server replicas to deploy* field, specify a value.
.. From the *Model server size* list, select a value.
.. If you have created a hardware profile, select a hardware profile from the *Hardware profile* list.
If project-scoped hardware profiles exist, the *Hardware profile* list includes subheadings to distinguish between global hardware profiles and project-scoped hardware profiles.
..  In the *Model route* section, select the *Make deployed models available through an external route* checkbox to make your deployed models available to external clients.
.. In the *Token authentication* section, select the *Require token authentication* checkbox to require token authentication for your model server. To finish configuring token authentication, perform the following actions:
... In the *Service account name* field, enter a service account name for which the token will be generated. The generated token is created and displayed in the *Token secret* field when the model server is configured.
... To add an additional service account, click *Add a service account* and enter another service account name.
. In the *Source model location* section, select *Current URI* to deploy the selected model from the catalog.
. Optional: Customize the runtime parameters in the *Configuration parameters* section:
.. Modify the values in *Additional serving runtime arguments* to define how the deployed model behaves.
.. Modify the values in *Additional environment variables* to define variables in the model's environment.
. Click *Deploy*.

.Verification
* The model deployment is displayed on the *AI hub* -> *Deployments* page.
* The model deployment is displayed in the *Latest deployments* section of the model details page.
* The model deployment is displayed on the *Deployments* tab for the model version.

[role="_additional-resources"]
.Additional resources
ifdef::upstream[]
* link:{odhdocshome}/deploying-models/#deploying-models-on-the-model-serving-platform_odh-user[Deploying models on the model serving platform].
endif::[]
ifndef::upstream[]
* link:{rhoaidocshome}{default-format-url}/deploying_models/deploying_models_on_the_model_serving_platform#deploying-models-on-the-model-serving-platform_rhoai-user[Deploying models on the model serving platform].
endif::[]
