:_module-type: PROCEDURE

[id="deploy-models-bias-monitoring_{context}"]
= Deploying models

1. Navigate to the model-namespace created in the setup section: oc project model-namespace
2. Deploy the model's storage container: oc apply -f resources/model_storage_container.yaml
3. Deploy the OVMS 1.x serving runtime: oc apply -f resources/ovms-1.x.yaml
4. Deploy the first model: oc apply -f resources/model_alpha.yaml
5. Deploy the second model: oc apply -f resources/model_beta.yaml
6. From the OpenShift Console, navigate to the model-namespace project and look at the Workloads -> Pods screen.

[disc]
** You should see four pods: 

image::images/model_namespace_pods.png[]

** Once the TrustyAI Service registers the deployed models, you will see the  `modelmesh-serving-ovms-1.x-xxxxx` pods get re-deployed.
** Verify that the models are registered with TrustyAI by selecting one of the `modelmesh-serving-ovms-1.x-xxxxx pods`. In the Environment tab, if the field `MM_PAYLOAD_PROCESSORS` is set, then your models are successfully registered with TrustyAI:

image::images/model_environment.png[]
