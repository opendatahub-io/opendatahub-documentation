:_module-type: REFERENCE

[id="requirements-for-upgrading-odh-v1_{context}"]
= Requirements for upgrading {productname-short} version 1

[role="_abstract"]
This section describes the tasks that you should complete when upgrading {productname-short} version 1 to version 2.

[NOTE]
--
After you install {productname-short} {vernum}, pipelines created with data science pipelines 1.0 continue to run, but are inaccessible from the {productname-short} dashboard. If you are a current data science pipelines user, do not install {productname-short} with data science pipelines 2.0 until you are ready to migrate to the new pipelines solution.
--

*Check the components in the `DataScienceCluster` object*

When you upgrade to version {vernum}, the upgrade process automatically uses the values from the `DataScienceCluster` object in the previous version.

After the upgrade, you should inspect the {vernum} `DataScienceCluster` object and optionally update the status of any components as described in link:{odhdocshome}/upgrading-open-data-hub/#installing-odh-components_upgradev1[Installing Open Data Hub components].

[NOTE]
====
New components are not automatically added to the `DataScienceCluster` object during upgrade. If you want to use a new component, you must manually edit the `DataScienceCluster` object to add the component entry.
====

*Recreate existing pipeline runs*

When you upgrade to {productname-short} {vernum}, any existing pipeline runs that you created in version 1 continue to refer to the previous version's image (as expected).

After upgrading, you must delete the pipeline runs (not the pipelines) and create new pipeline runs. The pipeline runs that you create in version {vernum} correctly refer to the version {vernum} image.

For more information about pipeline runs, see link:{odhdocshome}/working-with-data-science-pipelines/#managing-pipeline-runs_ds-pipelines[Managing pipeline runs].

*Address KServe requirements*

For KServe (single-model serving platform), you must meet these requirements:

* Install dependent Operators, including the Red Hat OpenShift Serverless and Red Hat OpenShift Service Mesh Operators. For more information, see link:{odhdocshome}/configuring-your-model-serving-platform/#odh-admin_odh-admin[Configuring your model serving platform].

* After upgrading, you must inspect the default `DataScienceCluster` object and verify that the value of the  `managementState` field for the `kserve` component is `Managed`.

* In {productname-long} version 1, the KServe component is a Limited Availability feature. If you enabled the `kserve` component and created models in version 1, then after you upgrade to version {vernum}, you must update some {productname-short} resources as follows:

. Log in to the {openshift-platform} console as a cluster administrator:
+
----
$ oc login
----

. Update the *DSC Initialization* resource:
+
----
$ oc patch $(oc get dsci -A -oname) --type='json' -p='[{"op": "replace", "path": "/spec/serviceMesh/managementState", "value":"Unmanaged"}]'
----

. Update the *Data Science Cluster* resource:
+
----
$ oc patch $(oc get dsc -A -oname) --type='json' -p='[{"op": "replace", "path": "/spec/components/kserve/serving/managementState", "value":"Unmanaged"}]'
----

. Update the `InferenceServices` CRD:
+
----
$ oc patch crd inferenceservices.serving.kserve.io --type=json -p='[{"op": "remove", "path": "/spec/conversion"}]'
----

. Optionally, restart the Operator pods.
+ 

* If you deployed a model by using KServe in {productname-short} version 1, when you upgrade to version {vernum} the model does not automatically appear in the {productname-short} dashboard. To update the dashboard view, redeploy the model by using the {productname-short} dashboard.

