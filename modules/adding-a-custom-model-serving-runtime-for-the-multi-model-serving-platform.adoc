:_module-type: PROCEDURE

[id="adding-a-custom-model-serving-runtime-for-the-multi-model-serving-platform_{context}"]
= Adding a custom model-serving runtime for the multi-model serving platform

A model-serving runtime adds support for a specified set of model frameworks and the model formats supported by those frameworks. By default, the multi-model serving platform includes the OpenVINO Model Server runtime. You can also add your own custom runtime if the default runtime does not meet your needs, such as supporting a specific model format.

As an administrator, you can use the {productname-long} dashboard to add and enable a custom model-serving runtime. You can then choose the custom runtime when you create a new model server for the multi-model serving platform.

NOTE: {org-name} does not provide support for custom runtimes. You are responsible for ensuring that you are licensed to use any custom runtimes that you add, and for correctly configuring and maintaining them.

[role='_abstract']

.Prerequisites
* You have logged in to {productname-short} as a user with {productname-short} administrator privileges.
ifdef::upstream[]
* You are familiar with how to link:{odhdocshome}/serving-models/#adding-a-model-server-for-the-multi-model-serving-platform_model-serving[add a model server to your project]. When you have added a custom model-serving runtime, you must configure a new model server to use the runtime.
endif::[]
ifndef::upstream[]
* You are familiar with how to link:{rhoaidocshome}{default-format-url}/serving_models/serving-small-and-medium-sized-models_model-serving#adding-a-model-server-for-the-multi-model-serving-platform_model-serving[add a model server to your project]. When you have added a custom model-serving runtime, you must configure a new model server to use the runtime.
endif::[]
* You have reviewed the example runtimes in the https://github.com/kserve/modelmesh-serving/tree/main/config/runtimes[kserve/modelmesh-serving^] repository. You can use these examples as starting points. However, each runtime requires some further modification before you can deploy it in {productname-short}. The required modifications are described in the following procedure.
+
NOTE: {productname-short} includes the OpenVINO Model Server runtime by default. You do not need to add this runtime to {productname-short}.

.Procedure
. From the {productname-short} dashboard, click *Settings* > *Serving runtimes*.
+
The *Serving runtimes* page opens and shows the model-serving runtimes that are already installed and enabled.

. To add a custom runtime, choose one of the following options:
+
** To start with an existing runtime (for example the OpenVINO Model Server runtime), click the action menu (&#8942;) next to the existing runtime and then click *Duplicate*.
** To add a new custom runtime, click *Add serving runtime*.

. In the *Select the model serving platforms this runtime supports* list, select *Multi-model serving platform*.
+
NOTE: The multi-model serving platform supports only the REST protocol. Therefore, you cannot change the default value in the *Select the API protocol this runtime supports* list.

. Optional: If you started a new runtime (rather than duplicating an existing one), add your code by choosing one of the following options:
+
--
* *Upload a YAML file*
.. Click *Upload files*.
.. In the file browser, select a YAML file on your computer. This file might be the one of the example runtimes that you downloaded from the https://github.com/kserve/modelmesh-serving/tree/main/config/runtimes[kserve/modelmesh-serving^] repository.
+
The embedded YAML editor opens and shows the contents of the file that you uploaded.

* *Enter YAML code directly in the editor*
.. Click *Start from scratch*.
.. Enter or paste YAML code directly in the embedded editor. The YAML that you paste might be copied from one of the example runtimes in the https://github.com/kserve/modelmesh-serving/tree/main/config/runtimes[kserve/modelmesh-serving^] repository.
--

. Optional: If you are adding one of the example runtimes in the https://github.com/kserve/modelmesh-serving/tree/main/config/runtimes[kserve/modelmesh-serving^] repository, perform the following modifications:
.. In the YAML editor, locate the `kind` field for your runtime. Update the value of this field to `ServingRuntime`.
.. In the link:https://github.com/kserve/modelmesh-serving/blob/main/config/runtimes/kustomization.yaml[kustomization.yaml^] file in the https://github.com/kserve/modelmesh-serving/tree/main/config/runtimes[kserve/modelmesh-serving^] repository, take note of the `newName` and `newTag` values for the runtime that you want to add. You will specify these values in a later step.
.. In the YAML editor for your custom runtime, locate the `containers.image` field. 
.. Update the value of the `containers.image` field in the format `newName:newTag`, based on the values that you previously noted in the link:https://github.com/kserve/modelmesh-serving/blob/main/config/runtimes/kustomization.yaml[kustomization.yaml^] file. Some examples are shown.
+
--
Nvidia Triton Inference Server::
+
`image: nvcr.io/nvidia/tritonserver:23.04-py3`

Seldon Python MLServer::
+
`image: seldonio/mlserver:1.3.2`

TorchServe::
+
`image: pytorch/torchserve:0.7.1-cpu`
--

. In the `metadata.name` field, ensure that the value of the runtime you are adding is unique (that is, the value doesn't match a runtime that you have already added).

. Optional: To configure a custom display name for the runtime that you are adding, add a `metadata.annotations.openshift.io/display-name` field and specify a value, as shown in the following example:
+
[source]
----
apiVersion: serving.kserve.io/v1alpha1
kind: ServingRuntime
metadata:
  name: mlserver-0.x
  annotations:
    openshift.io/display-name: MLServer
----
+
NOTE: If you do not configure a custom display name for your runtime, {productname-short} shows the value of the `metadata.name` field.

. Click *Add*.
+
The *Serving runtimes* page opens and shows the updated list of runtimes that are installed. Observe that the runtime you added is automatically enabled.

. Optional: To edit your custom runtime, click the action menu (&#8942;) and select *Edit*.

.Verification
* The custom model-serving runtime that you added is shown in an enabled state on the *Serving runtimes* page.

[role='_additional-resources']
.Additional resources
ifndef::upstream[]
* To learn how to configure a model server that uses a custom model-serving runtime that you have added, see link:{rhoaidocshome}{default-format-url}/serving_models/serving-small-and-medium-sized-models_model-serving#adding-a-model-server-for-the-multi-model-serving-platform_model-serving[Adding a model server to your data science project].
endif::[]
ifdef::upstream[]
* To learn how to configure a model server that uses a custom model-serving runtime that you have added, see link:{odhdocshome}/serving-models/#adding-a-model-server-for-the-multi-model-serving-platform_model-serving[Adding a model server to your data science project].
endif::[]
