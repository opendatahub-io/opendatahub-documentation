:_module-type: PROCEDURE

[id="viewing-performance-metrics-for-model-server_{context}"]
= Viewing performance metrics for all models on a model server

[role='_abstract']

In {productname-short}, you can monitor the following metrics for all the models that are deployed on a model server:

* *HTTP requests* - The number of HTTP requests that have failed or succeeded for all models on the server.
+
Note: You can also view the number of HTTP requests that have failed or succeeded for a specific model, as described in xref:viewing-http-request-metrics-for-a-deployed-model_model-serving[Viewing HTTP request metrics for a deployed model].
* *Average response time (ms)* - For all models on the server, the average time it takes the model server to respond to requests.
* *CPU utilization (%)* - The percentage of the CPU's capacity that is currently being used by all models on the server.
* *Memory utilization (%)* - The percentage of the system's memory that is currently being used by all models on the server.

You can specify a time range and a refresh interval for these metrics to help you determine, for example, when the peak usage hours are and how the models are performing at a specified time.

.Prerequisites
* You have installed {productname-long}.

* On the OpenShift cluster where {productname-short} is installed, user workload monitoring is enabled.

* You have logged in to {productname-short}.
ifndef::upstream[]
* If you are using specialized {productname-short} groups, you are part of the user group or admin group (for example, {oai-user-group} or {oai-admin-group}) in OpenShift.
endif::[]
ifdef::upstream[]
* If you are using specialized {productname-short} groups, you are part of the user group or admin group (for example, {odh-user-group} or {odh-admin-group}) in OpenShift.
endif::[]
* You have deployed models on the multi-model serving platform.

.Procedure

. From the {productname-short} dashboard navigation menu, click *Data Science Projects*.
+
The *Data Science Projects* page opens.
. Click the name of the project that contains the data science models that you want to monitor.
+
A project details page opens.
. Click the *Models* tab.

. In the row for the model server that you are interested in, click the action menu (&#8942;) and then select *View model server metrics*.

. Optional: On the metrics page for the model server, set the following options:

** *Time range* - Specifies how long to track the metrics. You can select one of these values: 1 hour, 24 hours, 7 days, and 30 days.

** *Refresh interval* - Specifies how frequently the graphs on the metrics page are refreshed (to show the latest data). You can select one of these values: 15 seconds, 30 seconds, 1 minute, 5 minutes, 15 minutes, 30 minutes, 1 hour, 2 hours, and 1 day.

. Scroll down to view data graphs for HTTP requests, average response time, CPU utilization, and memory utilization.

.Verification

On the metrics page for the model server, the graphs provide performance metric data.

//.See also
//Viewing HTTP request metrics for a deployed model
