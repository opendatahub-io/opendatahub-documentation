:_module-type: REFERENCE

ifdef::context[:parent-context: {context}]
[id="guardrails-configuring-the-hugging-face-detector-serving-runtime_{context}"]
= The Hugging Face Detector serving runtime

[role='_abstract']


To use link:https://huggingface.co/docs/transformers/model_doc/auto#transformers.AutoModelForSequenceClassification[Hugging Face] `AutoModelsForSequenceClassification` as detectors within the Guardrails Orchestrator, you need to first configure a Hugging Face serving runtime.

The link:https://github.com/opendatahub-io/odh-model-controller/blob/incubating/config/runtimes/hf-detector-template.yaml[guardrails-detector-huggingface-runtime] is a KServe serving runtime for Hugging Face predictive text models. This
allows models such as the link:https://huggingface.co/ibm-granite/granite-guardian-hap-38m[ibm-granite/granite-guardian-hap-38m] to be used within the TrustyAI Guardrails ecosystem.

.Example custom serving runtime

This YAML file contains an example of a custom serving Huggingface runtime:

[source,YAML]
----
apiVersion: serving.kserve.io/v1alpha1
kind: ServingRuntime
metadata:
  name: guardrails-detector-runtime
  annotations:
    openshift.io/display-name: Guardrails Detector ServingRuntime for KServe
    opendatahub.io/recommended-accelerators: '["nvidia.com/gpu"]'
  labels:
    opendatahub.io/dashboard: 'true'
spec:
  annotations:
    prometheus.io/port: '8080'
    prometheus.io/path: '/metrics'
  multiModel: false
  supportedModelFormats:
    - autoSelect: true
      name: guardrails-detector-huggingface
  containers:
    - name: kserve-container
      image: quay.io/trustyai/guardrails-detector-huggingface-runtime:v0.2.0
      command:
        - uvicorn
        - app:app
      args:
        - "--workers=1"
        - "--host=0.0.0.0"
        - "--port=8000"
        - "--log-config=/common/log_conf.yaml"
      env:
        - name: MODEL_DIR
          value: /mnt/models
        - name: HF_HOME
          value: /tmp/hf_home
        - name: SAFE_LABELS
          value: "[0]"
      ports:
        - containerPort: 8000
          protocol: TCP
----

The above serving runtime example matches the default template used with {productname-long}, and should suffice
for the majority of use-cases. The main relevant configuration parameter is the `SAFE_LABELS` environment variable. This specifies which prediction label or labels from the `AutoModelForSequenceClassification`  constitute a "safe" response and therefore should not trigger guardrailing. For example, if `[0, 1]` is specified as `SAFE_LABELS`
for a four-class model, a predicted label of `0` or `1` is considered "safe", while a predicted label of `2` or `3` triggers guardrailing. The default value is `[0]`.

== Guardrails Detector Hugging Face serving runtime configuration values

.Template configuration
[cols="2,5"]
|===
| Property | Value

| Template Name
| `guardrails-detector-huggingface-serving-template`

| Runtime Name
| `guardrails-detector-huggingface-runtime`

| Display Name
| `Hugging Face Detector ServingRuntime for KServe`

| Model Format
| `guardrails-detector-hf-runtime`

|===


.Server configuration

[cols="2,2,3"]
|===
| Component | Configuration | Value

| Server		
| uvicorn 
| `app:app`

| Port	
| Container	
| `8000`

| Metrics Port			
| Prometheus	
| `8080`

| Metrics Path 
| Prometheus	
| `/metrics`

| Log Config		
| Path
| `/common/log_conf.yaml`
|===

.Parameters
[cols="3,2,3"]
|===
| Parameter | Default | Description

| `guardrails-detector-huggingface-runtime-image`
| -		
| Container image (required)

| `MODEL_DIR`
|	`/mnt/models`	
| Model mount path		

| `HF_HOME`
| `/tmp/hf_home`		
| HuggingFace cache

| `SAFE_LABELS`
| `[0]`
| A JSON-formatted list

| `--workers`
| 	`1`	
| Number of Uvicorn workers

| `--host`
| `0.0.0.0`	
| Server bind address		

| `--port`
| `8000`
| Server port
|===


.Parameters for API endpoints
[cols="3,2,3,2,3a"]
|===
| Endpoint | Method | Description | Content-Type | Headers

| `/health`
|	GET		
| Health check endpoint
| `-`
| `-`

| `/api/v1/text/contents`
|	POST		
| Content detection endpoint
| `application/json`
| 3 types:
* `application/json`
* `detector-id: {detector_name}`
* `Content-Type: application/json`

|===
	