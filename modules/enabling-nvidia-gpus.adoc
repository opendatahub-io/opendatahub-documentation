:_module-type: PROCEDURE
//:disconnected:
//:upstream:
//:self-managed:

[id='enabling-nvidia-gpus_{context}']
= Enabling NVIDIA GPUs

[role='_abstract']
Before you can use NVIDIA GPUs in {productname-short}, you must install the NVIDIA GPU Operator. 

//the following note applies to self-managed connected only
ifdef::self-managed[]
ifndef::disconnected[]
[IMPORTANT]
====
If you are using {productname-short} in a disconnected self-managed environment, see link:{rhoaidocshome}{default-format-url}/installing_and_uninstalling_{url-productname-short}_in_a_disconnected_environment/enabling-nvidia-gpus_install[Enabling NVIDIA GPUs] instead.
====
endif::[]
endif::[]

//the following note applies to cloud service only
ifdef::cloud-service[]
[IMPORTANT]
====
The NVIDIA GPU add-on is no longer supported. Instead, enable GPUs by installing the NVIDIA GPU Operator. If your deployment has a previously-installed NVIDIA GPU add-on, before you install the NVIDIA GPU Operator, use Red Hat OpenShift Cluster Manager to uninstall the NVIDIA GPU add-on from your cluster.
====
endif::[]


.Prerequisites
ifdef::upstream,self-managed[]
* You have logged in to your {openshift-platform} cluster.
* You have the `cluster-admin` role in your {openshift-platform} cluster.
endif::[]
ifdef::cloud-service[]
* You have logged in to your OpenShift cluster.
* You have the `cluster-admin` role in your OpenShift cluster.
endif::[]

.Procedure
//the following step applies to cloud service, self-managed connected, and upstream
ifndef::disconnected[]
. To enable GPU support on an OpenShift cluster, follow the instructions here: link:https://docs.nvidia.com/datacenter/cloud-native/openshift/latest/index.html[NVIDIA GPU Operator on {org-name} OpenShift Container Platform^] in the NVIDIA documentation.
endif::[]
//the following step applies to self-managed disconnected only
ifdef::disconnected[]
. To enable GPU support on an OpenShift cluster in a disconnected or airgapped environment, follow the instructions here: link:https://docs.nvidia.com/datacenter/cloud-native/openshift/latest/mirror-gpu-ocp-disconnected.html[Deploy GPU Operators in a disconnected or airgapped environment^] in the NVIDIA documentation.
endif::[]
//the following steps apply to upstream and downstream: self-managed (connected and disconnected) and cloud service
. Delete the *migration-gpu-status* ConfigMap.
ifdef::upstream,self-managed[]
.. In the {openshift-platform} web console, switch to the *Administrator* perspective.
endif::[]
ifdef::cloud-service[]
.. In the OpenShift web console, switch to the *Administrator* perspective.
endif::[]
.. Set the *Project* to *All Projects* or *redhat-ods-applications* to ensure you can see the appropriate ConfigMap.
.. Search for the *migration-gpu-status* ConfigMap.
.. Click the action menu (&#8942;) and select *Delete ConfigMap* from the list.
+
The *Delete ConfigMap* dialog appears.
.. Inspect the dialog and confirm that you are deleting the correct ConfigMap.
.. Click *Delete*.
. Restart the dashboard replicaset.
ifdef::upstream,self-managed[]
.. In the {openshift-platform} web console, switch to the *Administrator* perspective.
endif::[]
ifdef::cloud-service[]
.. In the OpenShift web console, switch to the *Administrator* perspective.
endif::[]
.. Click *Workloads* -> *Deployments*.
.. Set the *Project* to *All Projects* or *redhat-ods-applications* to ensure you can see the appropriate deployment.
.. Search for the *rhods-dashboard* deployment.
.. Click the action menu (&#8942;)  and select *Restart Rollout* from the list.
.. Wait until the *Status* column indicates that all pods in the rollout have fully restarted.

.Verification
ifdef::upstream,self-managed[]
* The NVIDIA GPU Operator appears on the *Operators* -> *Installed Operators* page in the {openshift-platform} web console.
endif::[]
ifdef::cloud-service[]
* The NVIDIA GPU Operator appears on the *Operators* -> *Installed Operators* page in the OpenShift web console.
endif::[]
* The reset *migration-gpu-status* instance is present on the *Instances* tab on the `AcceleratorProfile` custom resource definition (CRD) details page.

//the following note applies to downstream only: self-managed (connected and disconnected) and cloud service
ifndef::upstream[]
[NOTE]
====
In {productname-short} {vernum}, {org-name} supports the use of accelerators within the same cluster only. 
{org-name} does not support remote direct memory access (RDMA) between accelerators, or the use of accelerators across a network, for example, by using technology such as NVIDIA GPUDirect or NVLink.
====
endif::[]

//the following step applies to downstream only: self-managed (connected and disconnected) and cloud service
ifndef::upstream[]
After installing the NVIDIA GPU Operator, create an accelerator profile as described in link:{rhoaidocshome}{default-format-url}/working_with_accelerators/#working-with-accelerator-profiles_accelerators[Working with accelerator profiles].
endif::[]
//the following step applies to upstream only
ifdef::upstream[]
After installing the NVIDIA GPU Operator, create an accelerator profile as described in link:{odhdocshome}/working-with-accelerators/[Working with accelerators].
endif::[]

