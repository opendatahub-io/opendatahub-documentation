:_module-type: PROCEDURE

[id='configuring-the-opentelemetry-exporter_{context}']

= Configuring the OpenTelemetry exporter

[role='_abstract']
You can configure the OpenTelemetry exporter to collect traces and metrics from the `GuardrailsOrchestrator` service. This enables you to monitor and observe the service behavior in your environment.

.Prerequisites
* You have installed the Tempo Operator from the link:https://operatorhub.io/[OperatorHub].
* You have installed the {org-name} build of OpenTelemetry from the OperatorHub.

.Procedure
. Enable user workload monitoring to observe telemetry data in {openshift-platform}:
+
[source,terminal]
----
$ oc -n openshift-monitoring patch configmap cluster-monitoring-config --type merge -p '{"data":{"config.yaml":"enableUserWorkload: true\n"}}'
----

. Deploy a MinIO instance to serve as the storage backend for Tempo:
.. Create a YAML file named `minio.yaml` with the following content:
+
.Example `minio.yaml` configuration
[source,yaml]
----
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: minio-pvc
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 10Gi
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: minio
spec:
  replicas: 1
  selector:
    matchLabels:
      app: minio
  template:
    metadata:
      labels:
        app: minio
    spec:
      containers:
      - name: minio
        image: quay.io/minio/minio:latest
        args:
        - server
        - /data
        - --console-address
        - :9001
        env:
        - name: MINIO_ROOT_USER
          value: "minio"
        - name: MINIO_ROOT_PASSWORD
          value: "minio123"
        ports:
        - containerPort: 9000
          name: api
        - containerPort: 9001
          name: console
        volumeMounts:
        - name: data
          mountPath: /data
      volumes:
      - name: data
        persistentVolumeClaim:
          claimName: minio-pvc
---
apiVersion: v1
kind: Service
metadata:
  name: minio
spec:
  ports:
  - port: 9000
    targetPort: 9000
    name: api
  - port: 9001
    targetPort: 9001
    name: console
  selector:
    app: minio
----

.. Apply the MinIO configuration:
+
[source,terminal]
----
$ oc apply -f minio.yaml
----

.. Verify that the MinIO pod is running:
+
[source,terminal]
----
$ oc get pods -l app=minio
----
+
.Example output
[source,terminal]
----
NAME                     READY   STATUS    RESTARTS   AGE
minio-5f8c9d7b6d-abc12   1/1     Running   0          30s
----

. Create a TempoStack instance:
.. Create a secret for MinIO credentials:
+
[source,terminal]
----
$ oc create secret generic tempo-s3-secret \
  --from-literal=endpoint=http://minio:9000 \
  --from-literal=bucket=tempo \
  --from-literal=access_key_id=minio \
  --from-literal=access_key_secret=minio123
----

.. Create a bucket in MinIO for Tempo storage:
+
[source,terminal]
----
$ oc run -i --tty --rm minio-client --image=quay.io/minio/mc:latest --restart=Never -- \
  sh -c "mc alias set minio http://minio:9000 minio minio123 && mc mb minio/tempo"
----

.. Create a YAML file named `tempo.yaml` with the following content:
+
.Example `tempo.yaml` configuration
[source,yaml]
----
apiVersion: tempo.grafana.com/v1alpha1
kind: TempoStack
metadata:
  name: <tempo_stack_name>
spec:
  storage:
    secret:
      name: tempo-s3-secret
      type: s3
  storageSize: 1Gi
  resources:
    total:
      limits:
        memory: 2Gi
        cpu: 2000m
  template:
    queryFrontend:
      jaegerQuery:
        enabled: true
----

.. Apply the Tempo configuration:
+
[source,terminal]
----
$ oc apply -f tempo.yaml
----

.. Verify that the TempoStack pods are running:
+
[source,terminal]
----
$ oc get pods -l app.kubernetes.io/instance=<tempo_stack_name>
----
+
.Example output
[source,terminal]
----
NAME                                            READY   STATUS    RESTARTS   AGE
tempo-sample-compactor-0                        1/1     Running   0          2m
tempo-sample-distributor-7d9c8f5b6d-xyz12       1/1     Running   0          2m
tempo-sample-ingester-0                         1/1     Running   0          2m
tempo-sample-querier-5f8c9d7b6d-abc34           1/1     Running   0          2m
tempo-sample-query-frontend-6c7d8e9f7g-def56    1/1     Running   0          2m
----

. Configure the OpenTelemetry instance to send telemetry data to the Tempo distributor:
.. Create a YAML file named `opentelemetry.yaml` with the following content:
+
.Example `opentelemetry.yaml` configuration
[source,yaml]
----
apiVersion: opentelemetry.io/v1beta1
kind: OpenTelemetryCollector
metadata:
  name: <otelcol_name>
spec:
  observability:
    metrics:
      enableMetrics: true
  deploymentUpdateStrategy: {}
  config:
    exporters:
      debug: null
      otlp:
        endpoint: 'tempo-<tempo_stack_name>-distributor:4317'
        tls:
          insecure: true
      prometheus:
        add_metric_suffixes: false
        endpoint: '0.0.0.0:8889'
        resource_to_telemetry_conversion:
          enabled: true
    processors:
      batch:
        send_batch_size: 10000
        timeout: 10s
      memory_limiter:
        check_interval: 1s
        limit_percentage: 75
        spike_limit_percentage: 15
    receivers:
      otlp:
        protocols:
          grpc:
            endpoint: '0.0.0.0:4317'
          http:
            endpoint: '0.0.0.0:4318'
    service:
      pipelines:
        metrics:
          exporters:
            - prometheus
            - debug
          processors:
            - batch
          receivers:
            - otlp
        traces:
          exporters:
            - otlp
            - debug
          processors:
            - batch
          receivers:
            - otlp
      telemetry:
        metrics:
          readers:
            - pull:
                exporter:
                  prometheus:
                    host: 0.0.0.0
                    port: 8888
  mode: deployment
----
+
The OpenTelemetry collector configuration defines the Tempo distributor and Prometheus services as exporters, which means that the OpenTelemetry collector sends telemetry data to these backends.

.. Apply the OpenTelemetry configuration:
+
[source,terminal]
----
$ oc apply -f opentelemetry.yaml
----

.. Verify that the OpenTelemetry collector pod is running:
+
[source,terminal]
----
$ oc get pods -l app.kubernetes.io/name=<otelcol_name>-collector
----
+
.Example output
[source,terminal]
----
NAME                                      READY   STATUS    RESTARTS   AGE
<otelcol_name>-collector-7d9c8f5b6d-abc12   1/1     Running   0          45s
----

. Define a `GuardrailsOrchestrator` custom resource object to specify the `otelExporter` configurations in a YAML file named `orchestrator_otel_cr.yaml`:
+
.Example `orchestrator_otel_cr.yaml` object with OpenTelemetry configured
[source,yaml]
----
apiVersion: trustyai.opendatahub.io/v1alpha1
kind: GuardrailsOrchestrator
metadata:
  name: gorch-test
spec:
  orchestratorConfig: "fms-orchestr8-config-nlp"    <1>
  replicas: 1
  otelExporter:
    otlpProtocol: grpc    <2>
    otlpTracesEndpoint: http://<otelcol_name>-collector.<namespace>.svc.cluster.local:4317    <3>
    otlpMetricsEndpoint: http://<otelcol_name>-collector.<namespace>.svc.cluster.local:4317    <4>
    enableMetrics: true    <5>
    enableTracing: true    <6>
----
<1> This references the config map that you created when deploying the Guardrails Orchestrator service.
<2> The protocol for sending traces and metrics data. Valid values are `grpc` or `http`.
<3> The hostname and port for exporting trace data to the OpenTelemetry collector.
<4> The hostname and port for exporting metrics data to the OpenTelemetry collector.
<5> Set to `true` to enable exporting metrics data.
<6> Set to `true` to enable exporting trace data.

. Deploy the orchestrator custom resource:
+
[source,terminal]
----
$ oc apply -f orchestrator_otel_cr.yaml
----

.Verification
Send a request to the guardrails service and verify your OpenTelemetry configuration.

. Observe traces using the Jaeger UI:
.. Access the Jaeger UI by port-forwarding the Tempo traces service:
+
[source,terminal]
----
$ oc port-forward svc/tempo-<tempo_stack_name>-query-frontend 16686:16686
----
.. In a separate browser window, navigate to `http://localhost:16686` to access the Jaeger UI.
.. Under *Service*, select *fms_guardrails_orchestr8* and click *Find Traces*.

. Observe metrics using the OpenShift Metrics UI:

.. In the Administrator perspective within the {openshift-platform} web console, select Observe > Metrics and query one of the following metrics: 
+
* `incoming_request_count`
* `success_request_count`
* `server_error_response_count`
* `client_response_count`
* `client_request_duration`
