:_module-type: PROCEDURE

[id="creating-a-project-workbench_{context}"]
= Creating a project workbench

[role='_abstract']
To examine and work with models in an isolated area, you can create a workbench. You can use this workbench to create a Jupyter notebook from an existing notebook container image to access its resources and properties. For data science projects that require data retention, you can add container storage to the workbench you are creating. If you require extra power for use with large datasets, you can assign accelerators to your workbench to optimize performance. 

.Prerequisites
* You have logged in to {productname-long}.
ifndef::upstream[]
* If you use specialized {productname-short} groups, you are part of the user group or admin group (for example, `{oai-user-group}` or `{oai-admin-group}` ) in OpenShift.
endif::[]
ifdef::upstream[]
* If you use specialized {productname-short} groups, you are part of the user group or admin group (for example, `{odh-user-group}` or `{odh-admin-group}`) in OpenShift.
endif::[]
* You have created a data science project that you can add a workbench to.

.Procedure
. From the {productname-short} dashboard, click *Data Science Projects*.
+
The *Data science projects* page opens.
. Click the name of the project that you want to add the workbench to.
+
The *Details* page for the project opens.
. In the *Workbenches* section, click *Create workbench*.
+
The *Create workbench* page opens.
. Configure the properties of the workbench you are creating.
.. In the *Name* field, enter a name for your workbench.
.. Optional: In the *Description* field, enter a description to define your workbench.
.. In the *Notebook image* section, complete the fields to specify the notebook image to use with your workbench. 
... From the *Image selection* list, select a notebook image.
.. In the *Deployment size* section, specify the size of your deployment instance.
... From the *Container size* list, select a container size for your server.
... Optional: From the *Accelerator* list, select an accelerator. 
... If you selected an accelerator in the preceding step, specify the number of accelerators to use.
.. Optional: Select and specify values for any new *environment variables*.
ifdef::upstream[]
+
[NOTE]
--
To enable data science pipelines in JupyterLab, create the following environment variable:
`PIPELINES_SSL_SA_CERTS=/var/run/secrets/kubernetes.io/serviceaccount/ca.crt`
--
endif::[]
ifdef::self-managed[]
+
[NOTE]
--
To enable data science pipelines in JupyterLab in self-managed deployments, create the following environment variable:
`PIPELINES_SSL_SA_CERTS=/var/run/secrets/kubernetes.io/serviceaccount/ca.crt`
--
endif::[]
.. Configure the storage for your {productname-short} cluster.
... Select *Create new persistent storage* to create storage that is retained after you log out of {productname-short}. Complete the relevant fields to define the storage.
... Select *Use existing persistent storage* to reuse existing storage and select the storage from the *Persistent storage* list.
.. To use a data connection, in the *Data connections* section, select the *Use a data connection* checkbox.
+
--
* Create a new data connection as follows:
... Select *Create new data connection*.
... In the *Name* field, enter a unique name for the data connection.
... In the *Access key* field, enter the access key ID for your S3-compatible object storage provider.
... In the *Secret key* field, enter your secret access key for the account you specified.
... In the *Endpoint* field, enter the endpoint of your S3-compatible object storage.
... In the *Region* field, enter the default region of your S3-compatible object storage account.
... In the *Bucket* field, enter the name of the S3-compatible object storage bucket.

* Use an existing data connection as follows:
... Select *Use existing data connection*.
... From the *Data connection* list, select a data connection that you previously defined.
--
+
. Click *Create workbench*.

.Verification
* The workbench that you created appears on the *Details* page for the project.
* Any cluster storage that you associated with the workbench during the creation process appears on the *Details* page for the project.
* The *Status* column, located in the *Workbenches* section of the *Details* page, displays a status of *Starting* when the workbench server is starting, and *Running* when the workbench has successfully started.


//[role='_additional-resources']
//.Additional resources
