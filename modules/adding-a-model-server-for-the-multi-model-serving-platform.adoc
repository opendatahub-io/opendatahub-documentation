:_module-type: PROCEDURE

[id='adding-a-model-server-for-the-multi-model-serving-platform_{context}']
= Adding a model server for the multi-model serving platform

[role='_abstract']
When you have enabled the multi-model serving platform, you must configure a model server to deploy models. If you require extra computing power for use with large datasets, you can assign accelerators to your model server.

ifdef::self-managed[]
[NOTE]
====
In {productname-short} {vernum}, {org-name} supports only NVIDIA and AMD GPU accelerators for model serving.
====
endif::[]
ifdef::cloud-service[]
[NOTE]
====
In {productname-short}, {org-name} supports only NVIDIA and AMD GPU accelerators for model serving.
====
endif::[]

.Prerequisites
* You have logged in to {productname-long}.
* You have created a data science project that you can add a model server to.
* You have enabled the multi-model serving platform.
ifndef::upstream[]
* If you want to use a custom model-serving runtime for your model server, you have added and enabled the runtime. See link:{rhoaidocshome}{default-format-url}/serving_models/serving-small-and-medium-sized-models_model-serving#adding-a-custom-model-serving-runtime-for-the-multi-model-serving-platform_model-serving[Adding a custom model-serving runtime].
* If you want to use graphics processing units (GPUs) with your model server, you have enabled GPU support in {productname-short}. If you use NVIDIA GPUs, see link:{rhoaidocshome}{default-format-url}/managing_openshift_ai/enabling_accelerators#enabling-nvidia-gpus_managing-rhoai[Enabling NVIDIA GPUs^]. If you use AMD GPUs, see link:{rhoaidocshome}{default-format-url}/managing_openshift_ai/enabling_accelerators#amd-gpu-integration_managing-rhoai[AMD GPU integration^].
endif::[]
ifdef::upstream[]
* If you want to use a custom model-serving runtime for your model server, you have added and enabled the runtime. See link:{odhdocshome}/serving-models/#adding-a-custom-model-serving-runtime-for-the-multi-model-serving-platform_model-serving[Adding a custom model-serving runtime].
* If you want to use graphics processing units (GPUs) with your model server, you have enabled GPU support. This includes installing the Node Feature Discovery and NVIDIA GPU and AMD GPU Operators. For more information, see https://docs.nvidia.com/datacenter/cloud-native/openshift/latest/index.html[NVIDIA GPU Operator on {org-name} OpenShift Container Platform^] in the NVIDIA documentation.
endif::[]

.Procedure
. In the left menu of the {productname-short} dashboard, click *Data science projects*.
+
The *Data science projects* page opens.
. Click the name of the project that you want to configure a model server for.
+
A project details page opens.

. Click the *Models* tab.
. Perform one of the following actions:
+
--
* If you see a *â€‹Multi-model serving platform* tile, click *Add model server* on the tile.
* If you do not see any tiles, click the *Add model server* button.
--
+
The *Add model server* dialog opens.
. In the *Model server name* field, enter a unique name for the model server.
. From the *Serving runtime* list, select a model-serving runtime that is installed and enabled in your {productname-short} deployment.
+
[NOTE]
====
If you are using a _custom_ model-serving runtime with your model server and want to use GPUs, you must ensure that your custom runtime supports GPUs and is appropriately configured to use them.
====
. In the *Number of model replicas to deploy* field, specify a value.
. From the *Accelerator profile* list, select an accelerator profile.
+
[IMPORTANT]
====
By default, hardware profiles are hidden in the dashboard navigation menu and user interface, while accelerator profiles remain visible. In addition, user interface components associated with the deprecated accelerator profiles functionality are still displayed. If you enable hardware profiles, the *Hardware profiles* list is displayed instead of the *Accelerator profiles* list. To show the *Settings -> Hardware profiles* option in the dashboard navigation menu, and the user interface components associated with hardware profiles, set the `disableHardwareProfiles` value to `false` in the `OdhDashboardConfig` custom resource (CR) in {openshift-platform}. 
ifdef::upstream[]
For more information about setting dashboard configuration options, see link:{odhdocshome}/managing-resources/#customizing-the-dashboard[Customizing the dashboard].
endif::[]
ifndef::upstream[]
For more information about setting dashboard configuration options, see link:{rhoaidocshome}{default-format-url}/managing_resources/customizing-the-dashboard[Customizing the dashboard].
endif::[]
====

. Optional: Click *Customize resource requests and limit* and update the following values:
.. In the *CPUs requests* field, specify the number of CPUs to use with your model server. Use the list beside this field to specify the value in cores or millicores.
.. In the *CPU limits* field, specify the maximum number of CPUs to use with your model server. Use the list beside this field to specify the value in cores or millicores.
.. In the *Memory requests* field, specify the requested memory for the model server in gibibytes (Gi).
.. In the *Memory limits* field, specify the maximum memory limit for the model server in gibibytes (Gi).
. Optional: In the *Model route* section, select the *Make deployed models available through an external route* checkbox to make your deployed models available to external clients.
. Optional: In the *Token authentication* section, select the *Require token authentication* checkbox to require token authentication for your model server. To finish configuring token authentication, perform the following actions:
.. In the *Service account name* field, enter a service account name for which the token will be generated. The generated token is created and displayed in the *Token secret* field when the model server is configured.
.. To add an additional service account, click *Add a service account* and enter another service account name.
. Click *Add*.
+
* The model server that you configured is displayed on the *Models* tab for the project, in the *Models and model servers* list.
. Optional: To update the model server, click the action menu (*&#8942;*) beside the model server and select *Edit model server*.

//[role="_additional-resources"]
//.Additional resources
