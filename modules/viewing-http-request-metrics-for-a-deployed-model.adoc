:_module-type: PROCEDURE

[id="viewing-http-request-metrics-for-a-deployed-model_{context}"]
= Viewing HTTP request metrics for a deployed model

[role='_abstract']

You can view a graph that illustrates the HTTP requests that have failed or succeeded for a specific model.

.Prerequisites
* You have installed {productname-long}.

* On the OpenShift cluster where {productname-short} is installed, user workload monitoring is enabled.

* You have logged in to {productname-short}.
ifndef::upstream[]
* If you are using specialized {productname-short} groups, you are part of the user group or admin group (for example, {oai-user-group} or {oai-admin-group}) in OpenShift.
endif::[]
ifdef::upstream[]
* If you are using specialized {productname-short} groups, you are part of the user group or admin group (for example, {odh-user-group} or {odh-admin-group}) in OpenShift.
endif::[]
* You have deployed a model in a data science project.

.Procedure 

. From the {productname-short} dashboard navigation menu, select *Model Serving*.

. On the *Model Serving* page, select the model that you are interested in.

. Optional: On the *Endpoint performance* tab, set the following options:

** *Time range* - Specifies how long to track the metrics. You can select one of these values: 1 hour, 24 hours, 7 days, and 30 days.

** *Refresh interval* - Specifies how frequently the graphs on the metrics page are refreshed (to show the latest data). You can select one of these values: 15 seconds, 30 seconds, 1 minute, 5 minutes, 15 minutes, 30 minutes, 1 hour, 2 hours, and 1 day.

.Verification

The *Endpoint performance* tab shows a graph of the HTTP metrics for the model.

//See also
//Viewing performance metrics for all models on a model server


