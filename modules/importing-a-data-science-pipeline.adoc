:_module-type: PROCEDURE

[id="importing-a-data-science-pipeline_{context}"]
= Importing a data science pipeline

[role='_abstract']
To help you begin working with data science pipelines in {productname-short}, you can import a YAML file containing your pipeline's code to an active pipeline server, or you can import the YAML file from a URL. This file contains a Kubeflow pipeline compiled by using the Kubeflow compiler. After you have imported the pipeline to a pipeline server, you can execute the pipeline by creating a pipeline run.

.Prerequisites
* You have logged in to {productname-long}.
* You have previously created a data science project that is available and contains a configured pipeline server.
* You have compiled your pipeline with the Kubeflow compiler and you have access to the resulting YAML file.
* If you are uploading your pipeline from a URL, the URL is publicly accessible. 

.Procedure
. From the {productname-short} dashboard, click *Data science pipelines*  -> *Pipelines*.
. On the *Pipelines* page, from the *Project* drop-down list, select the project that you want to import a pipeline to.
. Click *Import pipeline*.
. In the *Import pipeline* dialog, enter the details for the pipeline that you want to import.
.. In the *Pipeline name* field, enter a name for the pipeline that you want to import.
.. In the *Pipeline description* field, enter a description for the pipeline that want to import.
.. Select where you want to import your pipeline from by performing one of the following actions:
* Select *Upload a file* to upload your pipeline from your local machine's file system. Import your pipeline by clicking *Upload*, or by dragging and dropping a file.
* Select *Import by url* to upload your pipeline from a URL, and then enter the URL into the text box.  
.. Click *Import pipeline*.

.Verification
* The pipeline that you imported is displayed on the *Pipelines* page and on the *Pipelines* tab on the project details page.

//[role='_additional-resources']
//.Additional resources//
