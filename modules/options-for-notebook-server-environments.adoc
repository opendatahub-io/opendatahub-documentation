:_module-type: REFERENCE

[id='options-for-notebook-server-environments_{context}']
= Options for notebook server environments

[role='_abstract']
When you start Jupyter for the first time, or after stopping your notebook server, you must select server options in the *Start a notebook server* wizard so that the software and variables that you expect are available on your server. This section explains the options available in the *Start a notebook server* wizard in detail.

The *Start a notebook server* page consists of the following sections:

Notebook image:: Specifies the container image that your notebook server is based on. Different notebook images have different packages installed by default. If the notebook image has multiple versions available, you can select the notebook image version to use from the *Versions* section.
+
ifdef::upstream[]
[NOTE]
--
When a new version of a notebook image is released, the previous version remains available on the cluster. This gives you time to migrate your work to the latest version of the notebook image. Legacy notebook image versions, that is, not the two most recent versions, might still be available for selection. Legacy image versions include a label that indicates that the image is out-of-date. To use the latest package versions, use the most recently added notebook image.

If you want to use {productname-short} with Data Science Pipelines (DSP) 2.0, you must use notebook image versions 2024.1 or later.
--
endif::[]
ifndef::upstream[]
[NOTE]
--
Notebook images are supported for a minimum of one year. Major updates to preconfigured notebook images occur about every six months. Therefore, two supported notebook image versions are typically available at any given time. Legacy notebook image versions, that is, not the two most recent versions, might still be available for selection. Legacy image versions include a label that indicates the image is out-of-date. 

Versions 1.2 and 2023.1 of notebook images are no longer supported. Notebooks that are already running on versions 1.2 or 2023.1 of an image will continue to work normally, but they are not available to select for new users or notebooks.

If you want to use {productname-short} with Data Science Pipelines (DSP) 2.0, you must use notebook image versions 2024.1 or later.

To use the latest package versions, {org-name} recommends that you use the most recently added notebook image.
--
endif::[]
+
After you start a notebook image, you can check which Python packages are installed on your notebook server and which version of the package you have by running the `pip` tool in a notebook cell.
+
The following table shows the package versions used in the available notebook images.
ifndef::upstream[]
[IMPORTANT]
====
Notebook images denoted with `(Technology Preview)` in this table are not supported with Red Hat production service level agreements (SLAs) and might not be functionally complete. Red Hat does not recommend using Technology Preview features in production. These features provide early access to upcoming product features, enabling customers to test functionality and provide feedback during the development process. For more information about the support scope of Red Hat Technology Preview features, see Technology Preview Features Support Scope.
====
endif::[]

.Notebook image options
|===
| Image name | Image version | Preinstalled packages

.3+| CUDA
| 2024.1 (Recommended)
a| * CUDA 12.1
* Python 3.9
* JupyterLab 3.6
* Notebook 6.5

| 2023.2
a| * CUDA 11.8
* Python 3.9
* JupyterLab 3.6
* Notebook 6.5

| 2023.1 (Deprecated)
a| * CUDA 11.8
* Python 3.9
* JupyterLab 3.5
* Notebook 6.5

.3+| Minimal Python (default)
| 2024.1 (Recommended)
a| * Python 3.9
* JupyterLab 3.6
* Notebook 6.5

| 2023.2
a| * Python 3.9
* JupyterLab 3.6
* Notebook 6.5

| 2023.1 (Deprecated)
a| * Python 3.9
* JupyterLab 3.5
* Notebook 6.5

.3+| PyTorch
| 2024.1 (Recommended)
a| * CUDA 12.1
* Python 3.9
* PyTorch 2.2
* JupyterLab 3.6
* Notebook 6.5
* TensorBoard 2.16
* Boto3 1.34
* Kafka-Python 2.0
* Kfp 2.7
* Matplotlib 3.8
* Numpy 1.26
* Pandas 2.2
* Scikit-learn 1.4
* SciPy 1.12
* ODH-Elyra 3.16
* PyMongo 4.6
* Pyodbc 5.1 
* Codeflare-SDK 0.16
* Sklearn-onnx 1.16
* Psycopg 3.1 
* MySQL Connector/Python 8.3

| 2023.2
a| * CUDA 11.8
* Python 3.9
* PyTorch 2.0
* JupyterLab 3.6
* Notebook 6.5
* TensorBoard 2.13
* Boto3 1.28
* Kafka-Python 2.0
* Kfp-tekton 1.5 
* Matplotlib 3.6
* Numpy 1.24
* Pandas 1.5
* Scikit-learn 1.3
* SciPy 1.11
* Elyra 3.15
* PyMongo 4.5 
* Pyodbc 4.0 
* Codeflare-SDK 0.12
* Sklearn-onnx 1.15
* Psycopg 3.1 
* MySQL Connector/Python 8.0

| 2023.1 (Deprecated)
a| * CUDA 11.8
* Python 3.9
* PyTorch 1.13
* JupyterLab 3.5
* Notebook 6.5
* TensorBoard 2.11
* Boto3 1.26
* Kafka-Python 2.0
* Kfp-tekton 1.5 
* Matplotlib 3.6
* Numpy 1.24
* Pandas 1.5
* Scikit-learn 1.2
* SciPy 1.10
* Elyra 3.15

.3+| Standard Data Science
| 2024.1 (Recommended)
a| * Python 3.9
* JupyterLab 3.6
* Notebook 6.5
* Boto3 1.34
* Kafka-Python 2.0
* Kfp 2.7
* Matplotlib 3.8
* Pandas 2.2
* Numpy 1.26
* Scikit-learn 1.4
* SciPy 1.12
* ODH-Elyra 3.16
* PyMongo 4.6 
* Pyodbc 5.1 
* Codeflare-SDK 0.16
* Sklearn-onnx 1.16
* Psycopg 3.1 
* MySQL Connector/Python 8.3

| 2023.2
a| * Python 3.9
* JupyterLab 3.6
* Notebook 6.5
* Boto3 1.28
* Kafka-Python 2.0
* Kfp-tekton 1.5
* Matplotlib 3.6
* Pandas 1.5
* Numpy 1.24
* Scikit-learn 1.3
* SciPy 1.11
* Elyra 3.15
* PyMongo 4.5 
* Pyodbc 4.0 
* Codeflare-SDK 0.12
* Sklearn-onnx 1.15
* Psycopg 3.1 
* MySQL Connector/Python 8.0

| 2023.1 (Deprecated)
a| * Python 3.9
* JupyterLab 3.5
* Notebook 6.5
* Boto3 1.26
* Kafka-Python 2.0
* Kfp-tekton 1.5
* Matplotlib 3.6
* Numpy 1.24
* Pandas 1.5
* Scikit-learn 1.2
* SciPy 1.10
* Elyra 3.15

.3+| TensorFlow
| 2024.1 (Recommended)
a| * CUDA 12.1
* Python 3.9
* JupyterLab 3.6
* Notebook 6.5
* TensorFlow 2.15
* TensorBoard 2.15
* Boto3 1.34
* Kafka-Python 2.0
* Kfp 2.5
* Matplotlib 3.8
* Numpy 1.26
* Pandas 2.2
* Scikit-learn 1.4
* SciPy 1.12
* ODH-Elyra 3.16
* PyMongo 4.6 
* Pyodbc 5.1
* Codeflare-SDK 0.16
* Sklearn-onnx 1.16
* Psycopg 3.1 
* MySQL Connector/Python 8.3

| 2023.2
a| * CUDA 11.8
* Python 3.9
* JupyterLab 3.6
* Notebook 6.5
* TensorFlow 2.13
* TensorBoard 2.13
* Boto3 1.28
* Kafka-Python 2.0
* Kfp-tekton 1.5
* Matplotlib 3.6
* Numpy 1.24
* Pandas 1.5
* Scikit-learn 1.3
* SciPy 1.11
* Elyra 3.15
* PyMongo 4.5 
* Pyodbc 4.0 
* Codeflare-SDK 0.12
* Sklearn-onnx 1.15
* Psycopg 3.1 
* MySQL Connector/Python 8.0

| 2023.1 (Deprecated)
a| * CUDA 11.8
* Python 3.9
* JupyterLab 3.5
* Notebook 6.5
* TensorFlow 2.11
* TensorBoard 2.11
* Boto3 1.26
* Kafka-Python 2.0
* Kfp-tekton 1.5
* Matplotlib 3.6
* Numpy 1.24
* Pandas 1.5
* Scikit-learn 1.2
* SciPy 1.10
* Elyra 3.15

.3+| TrustyAI
| 2024.1 (Recommended)
a| * Python 3.9
* JupyterLab 3.6
* Notebook 6.5
* TrustyAI 0.5
* Boto3 1.34
* Kafka-Python 2.0
* Kfp 2.7
* Matplotlib 3.6
* Numpy 1.24
* Pandas 1.5
* Scikit-learn 1.4
* SciPy 1.12
* ODH-Elyra 3.16
* PyMongo 4.6
* Pyodbc 5.1 
* Codeflare-SDK 0.16
* Sklearn-onnx 1.16
* Psycopg 3.1 
* MySQL Connector/Python 8.3

| 2023.2
a| * Python 3.9
* JupyterLab 3.6
* Notebook 6.5
* TrustyAI 0.3
* Boto3 1.28
* Kafka-Python 2.0
* Kfp-tekton 1.5
* Matplotlib 3.6
* Numpy 1.24
* Pandas 1.5
* Scikit-learn 1.3
* SciPy 1.11
* Elyra 3.15
* PyMongo 4.5 
* Pyodbc 4.0 
* Codeflare-SDK 0.12
* Sklearn-onnx 1.15
* Psycopg 3.1 
* MySQL Connector/Python 8.0

| 2023.1 (Deprecated)
a| * Python 3.9
* JupyterLab 3.5
* Notebook 6.5
* TrustyAI 0.3
* Boto3 1.26
* Kafka-Python 2.0
* Kfp-tekton 1.5
* Matplotlib 3.6
* Numpy 1.24
* Pandas 1.5
* Scikit-learn 1.2
* SciPy 1.10
* Elyra 3.15

.2+| HabanaAI
| 2024.1 (Recommended)
a|* Python 3.8
* Habana 1.13
* JupyterLab 3.6
* Boto3 1.34
* Kafka-Python 2.0
* Kfp 2.7
* Matplotlib 3.7
* Numpy 1.23
* Pandas 2.0
* Scikit-learn 1.3
* Scipy 1.10
* TensorFlow 2.13
* PyTorch 2.1
* ODH-Elyra v3.16


| 2023.2
a| * Python 3.8
* Habana 1.10
* JupyterLab 3.5
* TensorFlow 2.12
* Boto3 1.26
* Kafka-Python 2.0
* Kfp-tekton 1.5
* Matplotlib 3.6
* Numpy 1.23
* Pandas 1.5
* Scikit-learn 1.2
* SciPy 1.10
* PyTorch 2.0
* Elyra 3.15

ifndef::upstream[]
.2+| code-server (Technology Preview)
endif::[]
ifdef::upstream[]
.2+| code-server
endif::[]
| 2024.1 (Recommended)
a| * Python 3.9
* Boto3 1.29
* Kafka-Python 2.0
* Matplotlib 3.8
* Numpy 1.26
* Pandas 2.1
* Plotly 5.18
* Scikit-learn 1.3
* Scipy 1.11
* Sklearn-onnx 1.15
* Ipykernel 6.26
* (code-server plugin) Python 2024.2.1
* (code-server plugin) Jupyter 2023.9.100

| 2023.2
a| * Python 3.9
* Boto3 1.29
* Kafka-Python 2.0
* Matplotlib 3.8
* Numpy 1.26
* Pandas 2.1
* Plotly 5.18
* Scikit-learn 1.3
* Scipy 1.11
* Sklearn-onnx 1.15
* Ipykernel 6.26
* (code-server plugin) Python 2023.14.0
* (code-server plugin) Jupyter 2023.3.100

ifdef::upstream[]
| RStudio Server
| 2024.1 (Recommended)
a| * Python 3.9
* R 4.3
endif::[]

ifndef::upstream[]
ifdef::cloud-service[]
| RStudio Server (Technology preview)
| 2024.1 (Recommended)
a| * Python 3.9
* R 4.3
[IMPORTANT] 
====
*Disclaimer:* +
{org-name} supports managing workbenches in {productname-short}. However, {org-name} does not provide support for the RStudio software. RStudio Server is available through link:https://rstudio.org/[https://rstudio.org/] and is subject to their licensing terms. Review their licensing terms before you use this sample workbench.
====
endif::[]
endif::[]

ifdef::upstream[]
| CUDA - RStudio Server
| 2024.1 (Recommended)
a| * Python 3.9
* CUDA 12.1
* R 4.3
endif::[]

ifndef::upstream[]
ifdef::cloud-service[]
| CUDA - RStudio Server (Technology preview)
| 2024.1 (Recommended)
a| * Python 3.9
* CUDA 12.1
* R 4.3

[IMPORTANT] 
====
*Disclaimer:* +
{org-name} supports managing workbenches in {productname-short}. However, {org-name} does not provide support for the RStudio software. RStudio Server is available through link:https://rstudio.org/[https://rstudio.org/] and is subject to their licensing terms. Review their licensing terms before you use this sample workbench. +

The *CUDA - RStudio Server* notebook image contains NVIDIA CUDA technology. CUDA licensing information is available at link:https://docs.nvidia.com/cuda/[https://docs.nvidia.com/cuda/]. Review their licensing terms before you use this sample workbench.
====
endif::[]
endif::[]

|===

Deployment size:: specifies the compute resources available on your notebook server.
+
*Container size* controls the number of CPUs, the amount of memory, and the minimum and maximum request capacity of the container.
+
*Accelerators* specifies the accelerators available on your notebook server.
+
*Number of accelerators* specifies the number of accelerators to use. 
+
[IMPORTANT]
--
ifdef::upstream[]
Using accelerators is only supported with specific notebook images. For GPUs, only the PyTorch, TensorFlow, and CUDA notebook images are supported. For Habana Gaudi devices, only the HabanaAI notebook image is supported. In addition, you can only specify the number of accelerators required for your notebook server if accelerators are enabled on your cluster.
endif::[]
ifndef::upstream[]
Using accelerators is only supported with specific notebook images. For GPUs, only the PyTorch, TensorFlow, and CUDA notebook images are supported. For Habana Gaudi devices, only the HabanaAI notebook image is supported. In addition, you can only specify the number of accelerators required for your notebook server if accelerators are enabled on your cluster. To learn how to enable GPU support, see link:{rhoaidocshome}{default-format-url}/managing_resources/managing-cluster-resources_cluster-mgmt#enabling-gpu-support_cluster-mgmt[Enabling GPU support in {productname-short}].
endif::[]
--

Environment variables:: Specifies the name and value of variables to be set on the notebook server. Setting environment variables during server startup means that you do not need to define them in the body of your notebooks, or with the Jupyter command line interface. Some recommended environment variables are shown in the table.
+
.Recommended environment variables
[cols="1,4",header]
|===
| Environment variable option | Recommended variable names

| AWS
a| * `AWS_ACCESS_KEY_ID` specifies your Access Key ID for Amazon Web Services.
* `AWS_SECRET_ACCESS_KEY` specifies your Secret access key for the account specified in `AWS_ACCESS_KEY_ID`.

|===


[role="_additional-resources"]
.Additional resources
ifdef::upstream[]
* link:{odhdocshome}/getting-started-with-open-data-hub/#launching-jupyter-and-starting-a-notebook-server_get-started[Launching Jupyter and starting a notebook server]
endif::[]
ifndef::upstream[]
* link:{rhoaidocshome}{default-format-url}/getting_started_with_{url-productname-long}/creating-a-project-workbench_get-started#launching-jupyter-and-starting-a-notebook-server_get-started[Launching Jupyter and starting a notebook server]
endif::[]