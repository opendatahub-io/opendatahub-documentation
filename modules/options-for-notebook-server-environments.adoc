:_module-type: REFERENCE

[id='options-for-notebook-server-environments_{context}']
= Options for notebook server environments

[role='_abstract']
When you start Jupyter for the first time, or after stopping your notebook server, you must select server options in the *Start a notebook server* wizard so that the software and variables that you expect are available on your server. This section explains the options available in the *Start a notebook server* wizard in detail.

The *Start a notebook server* page is divided into several sections:

Notebook image:: Specifies the container image that your notebook server is based on. Different notebook images have different packages installed by default. If the notebook image contains multiple versions, you can select the notebook image version to use from the *Versions* section.
+
ifdef::upstream[]
[NOTE]
--
When a new version of a notebook image is released, the previous version remains available and supported on the cluster. This gives you time to migrate your work to the latest version of the notebook image.
--
endif::[]
ifndef::upstream[]
[NOTE]
--
Notebook images are supported for a minimum of one year. Major updates to pre-configured notebook images occur approximately every six months. Therefore, two supported notebook images are typically available at any given time. To use the latest package versions, Red Hat recommends that you use the most recently added notebook image.
--
endif::[]
+
After you start a notebook image, you can check which Python packages are installed on your notebook server and which version of the package you have by running the `pip` tool in a notebook cell.
+
The following table shows the package versions used in the available notebook images:
+
.Notebook image options
|===
| Image name | Image version | Preinstalled packages

.2+| CUDA
| 2 (Recommended)
a| * Python 3.9
* CUDA 11.8
* JupyterLab 3.5
* Notebook 6.5

| 1
a| * Python 3.8
* CUDA 11.4
* JupyterLab 3.2
* Notebook 6.4

.2+| Minimal Python (default)
| 2 (Recommended)
a| * Python 3.9
* JupyterLab 3.5
* Notebook 6.5

| 1
a| * Python 3.8
* JupyterLab 3.2
* Notebook 6.4


.2+| PyTorch
| 2 (Recommended)
a| * Python 3.9
* JupyterLab 3.5
* Notebook 6.5
* PyTorch 1.13
* CUDA 11.7
* TensorBoard 2.11
* Boto3 1.26
* Kafka-Python 2.0
* Matplotlib 3.6
* Numpy 1.24
* Pandas 1.5
* Scikit-learn 1.2
* SciPy 1.10

| 1
a| * Python 3.8
* JupyterLab 3.2
* Notebook 6.4
* PyTorch 1.8
* CUDA 10.2
* TensorBoard 2.6
* Boto3 1.17
* Kafka-Python 2.0
* Matplotlib 3.4
* Numpy 1.19
* Pandas 1.2
* Scikit-learn 0.24
* SciPy 1.6

.2+| Standard Data Science
| 2 (Recommended)
a| * Python 3.9
* JupyterLab 3.5
* Notebook 6.5
* Boto3 1.26
* Kafka-Python 2.0
* Matplotlib 3.6
* Pandas 1.5
* Numpy 1.24
* Scikit-learn 1.2
* SciPy 1.10

| 1
a| * Python 3.8
* JupyterLab 3.2
* Notebook 6.4
* Boto3 1.17
* Kafka-Python 2.0
* Matplotlib 3.4
* Pandas 1.2
* Numpy 1.19
* Scikit-learn 0.24
* SciPy 1.6

.2+| TensorFlow
| 2 (Recommended)
a| * Python 3.9
* JupyterLab 3.5
* Notebook 6.5
* TensorFlow 2.11
* TensorBoard 2.11
* CUDA 11.8
* Boto3 1.26
* Kafka-Python 2.0
* Matplotlib 3.6
* Numpy 1.24
* Pandas 1.5
* Scikit-learn 1.2
* SciPy 1.10

| 1
a| * Python 3.8
* JupyterLab 3.2
* Notebook 6.4
* TensorFlow 2.7
* TensorBoard 2.6
* CUDA 11.4
* Boto3 1.17
* Kafka-Python 2.0
* Matplotlib 3.4
* Numpy 1.19
* Pandas 1.2
* Scikit-learn 0.24
* SciPy 1.6

| TrustyAI
| 1
a| * Python 3.9
* JupyterLab 3.5
* Notebook 6.5
* TrustyAI 0.2
* Boto3 1.26
* Kafka-Python 2.0
* Matplotlib 3.6
* Numpy 1.24
* Pandas 1.5
* Scikit-learn 1.2
* SciPy 1.10

|===

Deployment size:: Specifies the compute resources available on your notebook server.
+
*Container size* controls the number of CPUs, the amount of memory, and the minimum and maximum request capacity of the container.
+
*Number of GPUs* specifies the number of graphics processing units attached to the container.
+
[IMPORTANT]
--
ifdef::upstream[]
Using GPUs to accelerate workloads is only supported with the PyTorch, TensorFlow, and CUDA notebook server images. In addition, you can specify the number of GPUs required for your notebook server only if GPUs are enabled on your cluster.
endif::[]
ifndef::upstream[]
Using GPUs to accelerate workloads is only supported with the PyTorch, TensorFlow, and CUDA notebook server images. In addition, you can specify the number of GPUs required for your notebook server only if GPUs are enabled on your cluster. To learn how to enable GPU support, see link:{rhodsdocshome}{default-format-url}/managing_resources/enabling-gpu-support-in-openshift-data-science_user-mgmt[Enabling GPU support in {productname-short}].
endif::[]
--

Environment variables:: Specifies the name and value of variables to be set on the notebook server. Setting environment variables during server startup means that you do not need to define them in the body of your notebooks, or with the Jupyter command line interface. Some recommended environment variables are shown in the table.
+
.Recommended environment variables
[cols="1,4",header]
|===
| Environment variable option | Recommended variable names

| AWS
a| * `AWS_ACCESS_KEY_ID` specifies your Access Key ID for Amazon Web Services.
* `AWS_SECRET_ACCESS_KEY` specifies your Secret access key for the account specified in `AWS_ACCESS_KEY_ID`.

|===


ifndef::upstream[]
[role="_additional-resources"]
.Additional resources
* link:{rhodsdocshome}{default-format-url}/getting_started_with_{url-productname-long}/creating-a-project-workbench_get-started#launching-jupyter-and-starting-a-notebook-server_get-started[Launching Jupyter and starting a notebook server]
endif::[]
