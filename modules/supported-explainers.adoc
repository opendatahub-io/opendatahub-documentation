:_module-type: REFERENCE
:stem: 

[id="supported-explainers_{context}"]
= Supported explainers

{productname-long} supports the following explainers:

*LIME*

_Local Interpretable Model-agnostic Explanations_ (LIME) footnote:1[Marco Tulio Ribeiro, Sameer Singh, Carlos Guestrin. "Why Should I Trust You?": Explaining the Predictions of Any Classifier." _Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data mining_, 2016. Pages 1135-1144.] is a saliency explanation method. LIME aims to explain a prediction &#119901; &#61; &#40;&#119909;, &#119910;&#41; (an input-output pair) generated by a black-box model &#119891;&#58;  &#8477;^&#119889;^ &#8594; &#8477;. The explanations come in the form of a "saliency" stem:[w_i] attached to each feature stem:[x_i] in the prediction input stem:[x]. LIME generates a local explanation stem:[\xi(x)] according to the following model:

image::images/explainer-lime.png[LIME model, scale=60, align="center"]

* stem:[\pi_x] is a proximity function
* stem:[G] the family of interpretable models
* stem:[\Omega(g)] is a measure of complexity of an explanation stem:[g \in G]
* stem:[L(f, g, \pi_x)] is a measure of how unfaithful stem:[g] is in approximating stem:[f] in the locality defined by stem:[\pi_x]

In the original paper, G is the class of linear models and πx is an exponential kernel on a distance function stem:[D] (for example, cosine distance). LIME converts samples stem:[x_i] from the original domain into interpretable samples as binary vectors stem:[x^{\prime}_i \in {0, 1}]. An encoded data set stem:[E] is built by taking nonzero elements of stem:[x^{\prime}_i], recovering the original representation stem:[z \in \mathbb{R}^d] and then computing stem:[f(z)]. A weighted linear model stem:[g] (with weights provided via stem:[\pi_x]) is then trained on the generated sparse data set stem:[E] and the model weights stem:[w] are used as feature weights for the final explanation stem:[\xi(x)].

*SHAP*

_SHapley Additive exPlanations_ (SHAP), footnote:[Scott Lundberg, Su-In Lee. "A Unified Approach to Interpreting Model Predictions." _Advances in Neural Information Processing Systems_, 2017.] seeks to unify several common explanation methods, notably LIME footnote:1[] and DeepLIFT, footnote:[Avanti Shrikumar, Peyton Greenside, Anshul Kundaje. "Learning Important Features Through Propagating Activation Differences." _CoRR abs/1704.02685_, 2017.] under a common umbrella of additive feature attributions. These methods explain how an input stem:[x = [x_1, x_2, ..., x_M ]] affects the output of some model stem:[f] by transforming stem:[x \in \mathbb{R}^M] into simplified inputs stem:[z^{\prime} \in 0, 1^M] , such that stem:[z^{\prime}_i] indicates the inclusion or exclusion of feature stem:[i]. The simplified inputs are then passed to an explanatory model stem:[g] that takes the following form:

image::images/explainer-shap.png[SHAP explanatory model, scale=60, align="center"]

In that form, each value stem:[\phi_i] marks the contribution that feature stem:[i] had on the output model (called the attribution), and stem:[\phi_0] marks the null output of the model; the model output when every feature is excluded. Therefore, this presents an easily interpretable explanation of the importance of each feature and a framework to permute the various input features to establish their collection contributions.

The final result of the algorithm are the Shapley values of each feature, which give an itemized "receipt" of all the contributing factors to the decision. For example, a SHAP explanation of a loan application might be as follows:

[%autowidth]
|===
|Feature | Shapley Value φ

|Null Output | 50%
|Income | +10%
|# Children | -15%
|Age | +22%
|Own Home? | -30%
|Acceptance% | 37%
|Deny | 63%
|===

From this, the applicant can see that the biggest contributor to their denial was their home ownership status, which reduced their acceptance probability by 30 percentage points. Meanwhile, their number of children was of particular benefit, increasing their probability by 22 percentage points.


