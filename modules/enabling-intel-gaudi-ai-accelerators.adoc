:_module-type: PROCEDURE

[id='enabling-intel-gaudi-ai-accelerators_{context}']
= Enabling Intel Gaudi AI accelerators

[role='_abstract']
Before you can use Intel Gaudi AI accelerators in {productname-short}, you must install the required dependencies, deploy the Intel Gaudi Base Operator, and configure the environment.

.Prerequisites
* You have logged in to {openshift-platform}.
* You have the `cluster-admin` role in {openshift-platform}.
* You have installed your Intel Gaudi accelerator and confirmed that it is detected in your environment.
* Your OpenShift environment supports EC2 DL1 instances if you are running on Amazon Web Services (AWS).
* You have installed the {openshift-cli} as described in the appropriate documentation for your cluster:
ifdef::upstream,self-managed[]
** link:https://docs.redhat.com/en/documentation/openshift_container_platform/{ocp-latest-version}/html/cli_tools/openshift-cli-oc#installing-openshift-cli[Installing the OpenShift CLI^] for OpenShift Container Platform  
** link:https://docs.redhat.com/en/documentation/red_hat_openshift_service_on_aws/{rosa-latest-version}/html/cli_tools/openshift-cli-oc#installing-openshift-cli[Installing the OpenShift CLI^] for {rosa-productname}
endif::[]
ifdef::cloud-service[]
** link:https://docs.redhat.com/en/documentation/openshift_dedicated/{osd-latest-version}/html/cli_tools/openshift-cli-oc#installing-openshift-cli[Installing the OpenShift CLI^] for OpenShift Dedicated  
** link:https://docs.redhat.com/en/documentation/red_hat_openshift_service_on_aws_classic_architecture/{rosa-classic-latest-version}/html/cli_tools/openshift-cli-oc#installing-openshift-cli[Installing the OpenShift CLI^] for {rosa-classic-productname}
endif::[]

.Procedure
. Install the latest version of the Intel Gaudi Base Operator, as described in link:https://docs.habana.ai/en/latest/Installation_Guide/Additional_Installation/OpenShift_Installation/index.html[Intel Gaudi Base Operator OpenShift installation].
. By default, {openshift-platform} sets a per-pod PID limit of 4096. If your workload requires more processing power, such as when you use multiple Gaudi accelerators or when using vLLM with Ray, you must manually increase the per-pod PID limit to avoid `Resource temporarily unavailable` errors. These errors occur due to PID exhaustion. {org-name} recommends setting this limit to 32768, although values over 20000 are sufficient.
.. Run the following command to label the node: 
+
[source]
----
oc label node <node_name> custom-kubelet=set-pod-pid-limit-kubelet
----
.. Optional: To prevent workload distribution on the affected node, you can mark the node as unschedulable and then drain it in preparation for maintenance. For more information, see link:https://docs.redhat.com/en/documentation/openshift_container_platform/{ocp-latest-version}/html/nodes/working-with-nodes#nodes-nodes-working-evacuating_nodes-nodes-working[Understanding how to evacuate pods on nodes].
.. Create a `custom-kubelet-pidslimit.yaml` KubeletConfig resource file: 
+
[source]
----
oc create -f custom-kubelet-pidslimit.yaml
----
.. Populate the file with the following YAML code. Set the `PodPidsLimit` value to 32768:
+
[source,YAML]
----
apiVersion: machineconfiguration.openshift.io/v1
kind: KubeletConfig
metadata:
  name: custom-kubelet-pidslimit
spec:
  kubeletConfig:
    PodPidsLimit: 32768
  machineConfigPoolSelector:
    matchLabels:
      custom-kubelet: set-pod-pid-limit-kubelet
----
.. Apply the configuration: 
+
[source]
----
oc apply -f custom-kubelet-pidslimit.yaml
----
+
This operation causes the node to reboot. For more information, see link:https://docs.redhat.com/en/documentation/openshift_container_platform/{ocp-latest-version}/html/nodes/working-with-nodes#nodes-nodes-rebooting[Understanding node rebooting].
.. Optional: If you previously marked the node as unschedulable, you can allow scheduling again after the node reboots.

ifndef::upstream[]
. Create a custom workbench image for Intel Gaudi AI accelerators, as described in link:{rhoaidocshome}{default-format-url}/managing_openshift_ai/creating-custom-workbench-images[Creating custom workbench images].
endif::[]
ifdef::upstream[]
. Create a custom workbench image for Intel Gaudi AI accelerators, as described in link:{odhdocshome}/managing-odh/#creating-custom-workbench-images[Creating custom workbench images].
endif::[]
//downstream - all
ifndef::upstream[]
. After installing the Intel Gaudi Base Operator, create a hardware profile, as described in link:{rhoaidocshome}{default-format-url}/working_with_accelerators/#working-with-hardware-profiles_accelerators[Working with hardware profiles].
endif::[]
//upstream only
ifdef::upstream[]
. After installing the Intel Gaudi Base Operator, create a hardware profile, as described in link:{odhdocshome}/working-with-accelerators/#working-with-hardware-profiles_accelerators[Working with hardware profiles].
endif::[]

.Verification
From the *Administrator* perspective, go to the *Ecosystem* -> *Installed Operators* page. Confirm that the following Operators appear:

* Intel Gaudi Base Operator
* Node Feature Discovery (NFD)
* Kernel Module Management (KMM)

//[role='_additional-resources']
//.Additional resources