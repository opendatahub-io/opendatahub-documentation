:_module-type: CONCEPT

[id='requesting-a-lime-explanation_{context}']
= Requesting a LIME explanation

[role='_abstract']
To understand how a model makes its predictions and decisions, you can use a _Local Interpretable Model-agnostic Explanations_ (LIME) explainer. LIME explains a model's predictions by showing how much each feature affected the outcome. For example, for a model predicting not to target a user for a marketing campaign, LIME provides a list of weights, both positive and negative, indicating how each feature influenced the model's outcome.

For more information, see link:{odhdocshome}/monitoring-data-science-models/#supported-explainers_explainers[Supported explainers].

//You can request a LIME explanation by using the {productname-short} dashboard or by using the OpenShift command-line interface (CLI).

include::requesting-a-lime-explanation-using-cli.adoc[leveloffset=+1]
