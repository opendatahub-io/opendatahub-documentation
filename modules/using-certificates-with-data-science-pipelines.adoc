:_module-type: PROCEDURE

[id='using-certificates-with-data-science-pipelines_{context}']
= Using certificates with data science pipelines 

ifdef::upstream[]
If you want to use self-signed certificates, you have added them to a central Certificate Authority (CA) bundle as described in link:{odhdocshome}/installing-open-data-hub/#understanding-certificates_certs[Understanding certificates in {productname-short}].

No additional configuration is necessary to use those certificates with data science pipelines.
endif::[]
ifdef::cloud-service[]
If you want to use self-signed certificates, you have added them to a central Certificate Authority (CA) bundle as described in link:{rhoaidocshome}{default-format-url}/installing_and_uninstalling_{url-productname-short}/working-with-certificates_certs[Working with certificates].

No additional configuration is necessary to use those certificates with data science pipelines.
endif::[]
ifdef::self-managed[]
If you want to use self-signed certificates, you have added them to a central Certificate Authority (CA) bundle as described in link:{rhoaidocshome}{default-format-url}/installing_and_uninstalling_{url-productname-short}/working-with-certificates_certs[Working with certificates] (for disconnected environments, see link:{rhoaidocshome}{default-format-url}/installing_and_uninstalling_{url-productname-short}_in_a_disconnected_environment/working-with-certificates_certs[Working with certificates]).

No additional configuration is necessary to use those certificates with data science pipelines.
endif::[]

== Providing a CA bundle only for data science pipelines

Perform the following steps to provide a Certificate Authority (CA) bundle just for data science pipelines.

.Procedure
. Log in to {openshift-platform}.
. From *Workloads* -> *ConfigMaps*, create a ConfigMap with the required bundle in the same data science project or namespace as the target data science pipeline:
+
[source]
----
kind: ConfigMap
apiVersion: v1
metadata:
    name: custom-ca-bundle
data:
    ca-bundle.crt: |
    # contents of ca-bundle.crt
----
. Add the following snippet to the `.spec.apiserver.caBundle` field of the underlying Data Science Pipelines Application (DSPA):
+
[source]
----
apiVersion: datasciencepipelinesapplications.opendatahub.io/v1
kind: DataSciencePipelinesApplication
metadata:
    name: data-science-dspa
spec:
    ...
    apiServer:
    ...
    cABundle:
        configMapName: custom-ca-bundle
        configMapKey: ca-bundle.crt
----

The pipeline server pod redeploys with the updated bundle and uses it in the newly created pipeline pods.

.Verification

Perform the following steps to confirm that your CA bundle was successfully mounted.

. Log in to the {openshift-platform} console.
. Go to the {openshift-platform} project that corresponds to the data science project.
. Click the *Pods* tab.
. Click the pipeline server pod with the `ds-pipeline-dspa-<hash>` prefix.
. Click *Terminal*.
. Enter `cat /dsp-custom-certs/dsp-ca.crt`.
. Verify that your CA bundle is present within this file.

You can also confirm that your CA bundle was successfully mounted by using the CLI:

. In a terminal window, log in to the OpenShift cluster where {productname-short} is deployed.
+
----
oc login
----
. Set the `dspa` value:
+
----
dspa=dspa
----
. Set the `dsProject` value, replacing `$YOUR_DS_PROJECT` with the name of your data science project:
+
----
dsProject=$YOUR_DS_PROJECT
----
. Set the `pod` value:
+
----
pod=$(oc get pod -n ${dsProject} -l app=ds-pipeline-${dspa} --no-headers | awk '{print $1}')
----
. Display the contents of the `/dsp-custom-certs/dsp-ca.crt` file:
+
----
oc -n ${dsProject} exec $pod -- cat /dsp-custom-certs/dsp-ca.crt
----
. Verify that your CA bundle is present within this file.
