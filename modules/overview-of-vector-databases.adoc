:_module-type: CONCEPT

[id="overview-of-vector-databases_{context}"]
= Overview of vector databases

[role="_abstract"]
Vector databases are a core component of retrieval-augmented generation (RAG) in {productname-short}. They store and index vector embeddings that represent the semantic meaning of text or other data. When integrated with Llama Stack, vector databases enable applications to retrieve relevant context and combine it with large language model (LLM) inference.

Vector databases provide the following capabilities:

* Store vector embeddings generated by embedding models.
* Support efficient similarity search to retrieve semantically related content.
* Enable RAG workflows by supplying the LLM with contextually relevant data.

In {productname-short}, vector databases are configured and managed through the Llama Stack Operator as part of a `LlamaStackDistribution`.  
Starting with version 3.2, PostgreSQL is the default and recommended metadata store for Llama Stack, supporting production-ready persistence, concurrency, and scalability.

The following vector database options are supported in {productname-short}:

* *Inline Milvus*  
  Inline Milvus runs embedded within the Llama Stack Distribution (LSD) pod and is suitable for development and small-scale RAG workloads.  
  In {productname-short} 3.2 and later, Inline Milvus uses PostgreSQL as the backing metadata store by default.  
  This option provides a simplified deployment model while retaining durable metadata storage.

* *Inline FAISS*  
  Inline FAISS uses the FAISS (Facebook AI Similarity Search) library to provide an in-process vector store for RAG workflows.  
  Inline FAISS is designed for experimentation, prototyping, and development scenarios where simplicity and low operational overhead are priorities.  
  In {productname-short} 3.2 and later, Inline FAISS also relies on PostgreSQL for metadata storage.

* *Remote Milvus*  
  Remote Milvus runs as a standalone vector database service, either within the cluster or as an external managed deployment.  
  This option is suitable for large-scale or production-grade RAG workloads that require high availability, horizontal scalability, and isolation from the Llama Stack server.  
  In {openshift-platform} environments, Milvus typically requires an accompanying etcd service for coordination.  
  For more information, see link:https://docs.redhat.com/en/documentation/openshift_container_platform/{ocp-latest-version}/html/etcd/index[Providing redundancy with etcd].

* *Remote PostgreSQL with pgvector*  
  PostgreSQL with the pgvector extension provides a production-ready vector database option that integrates vector similarity search directly into PostgreSQL.  
  This option is well suited for environments that already operate PostgreSQL and require durable storage, transactional consistency, and centralized management.  
  pgvector enables Llama Stack to store embeddings and perform similarity search without deploying a separate vector database service.

Consider the following guidance when choosing a vector database for your RAG workloads:

* Use **Inline Milvus** or **Inline FAISS** for development, testing, or early experimentation.
* Use **Remote Milvus** when you require large-scale vector indexing and high-throughput similarity search.
* Use **PostgreSQL with pgvector** when you want production-ready persistence and integration with existing PostgreSQL-based data platforms.

Starting with {productname-short} 3.2, SQLite-based storage is no longer recommended for production deployments. PostgreSQL-based backends provide improved reliability, concurrency, and scalability as Llama Stack moves toward general availability.