:_module-type: CONCEPT
[id="overview-of-vector-databases_{context}"]
= Overview of vector databases

[role="_abstract"]
Vector databases are a crucial component of retrieval-augmented generation (RAG) in {productname-short}. They store and index vector embeddings that represent the semantic meaning of text or other data. When you integrate vector databases with Llama Stack in {productname-short}, you can build RAG applications that combine large language models (LLMs) with relevant, domain-specific knowledge.

Vector databases provide the following capabilities:

* Store vector embeddings generated by embedding models.
* Support efficient similarity search to retrieve semantically related content.
* Enable RAG workflows by supplying the LLM with contextually relevant data from a specific domain.

When you deploy RAG workloads in {productname-short}, you can deploy vector databases through the Llama Stack Operator.  
Currently, {productname-short} supports the following vector databases:

* *Inline Milvus Lite*  
  An Inline Milvus vector database runs embedded within the Llama Stack Distribution (LSD) pod and is suitable for lightweight experimentation and small-scale development. Inline Milvus stores data in a local SQLite database and is limited in scale and persistence.

* *Inline FAISS*  
  Inline FAISS provides an alternative lightweight vector store for RAG workloads. FAISS (Facebook AI Similarity Search) is an open-source library for efficient similarity search and clustering of dense vectors. When configured inline with a SQLite backend, FAISS runs entirely within the Llama Stack container and stores embeddings locally without requiring a separate database service. Inline FAISS is ideal for testing and experimental RAG deployments.

* *Remote Milvus*  
  A remote Milvus vector database runs as a standalone service in your project namespace or as an external managed deployment.  
  Remote Milvus is best for production-grade RAG use cases because it provides persistence, scalability, and isolation from the Llama Stack Distribution (LSD) pod.  
  In {openshift-platform} environments, you must deploy Milvus with an etcd service directly in your project.  
  For more information on using etcd services, see https://docs.redhat.com/en/documentation/openshift_container_platform/{ocp-latest-version}/html/etcd/index[Providing redundancy with etcd].

* *Remote PostgreSQL with pgvector*  
  A remote PostgreSQL vector database with the pgvector extension enabled runs as a standalone database service that is accessed by the Llama Stack server.  
  This option allows you to store and query vector embeddings in PostgreSQL, enabling organizations to reuse existing database infrastructure, operational tooling, and access controls.  
  Remote PostgreSQL with pgvector is suitable for RAG workloads that require persistent storage and integration with established PostgreSQL environments.

Consider the following points when you decide which vector database to use for your RAG workloads:

* Use **inline Milvus Lite** if you want to experiment quickly with RAG in a self-contained setup and do not require persistence across pod restarts.
* Use **inline FAISS** if you need a lightweight, in-process vector store with local persistence through SQLite and no network dependency.
* Use **remote Milvus** if you need reliable storage, high availability, and the ability to scale RAG workloads in your {productname-short} environment.
* Use **remote PostgreSQL with pgvector** if you already operate PostgreSQL and want to integrate vector search into existing database workflows while supporting persistent RAG workloads.
