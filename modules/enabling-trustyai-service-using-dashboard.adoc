:_module-type: PROCEDURE

[id='enabling-trustyai-service-using-dashboard_{context}']
= Enabling the TrustyAI Service by using the dashboard

[role='_abstract']
Enable an instance of the TrustyAI service on each data science project that contains models that the data scientist wants to monitor. The TrustyAI service instance provides the URL that the data scientist uses to monitor and analyze any number of models deployed into a data science project.

The following procedure describes how to use the {productname-short} dashboard to enable an instance of the TrustyAI service.

.Prerequisites

ifdef::upstream,self-managed[]
* On the OpenShift cluster where {productname-short} is installed, you have enabled user workload monitoring as described in link:https://docs.openshift.com/container-platform/{ocp-latest-version}/monitoring/enabling-monitoring-for-user-defined-projects.html[Enabling monitoring for user-defined projects].
endif::[]
ifdef::cloud-service[]
* On the OpenShift cluster where {productname-short} is installed, you have enabled user workload monitoring as described in link:https://docs.openshift.com/dedicated/monitoring/enabling-alert-routing-for-user-defined-projects.html[Enabling monitoring for user-defined projects] (OpenShift Dedicated) or https://docs.openshift.com/rosa/monitoring/enabling-alert-routing-for-user-defined-projects.html[Enabling monitoring for user-defined projects] (Red Hat OpenShift Service on AWS).

endif::[]

ifdef::upstream[]
* You have enabled the multi-model serving platform as described in link:{odhdocshome}/serving_models/enabling-the-multi-model-serving-platform_model-serving[Enabling the multi-model serving platform].
endif::[]
ifndef::upstream[]
* You have enabled the multi-model serving platform as described in link:{rhoaidocshome}{default-format-url}/serving_models/serving-small-and-medium-sized-models_model-serving#enabling-the-multi-model-serving-platform_model-serving[Enabling the multi-model serving platform].
endif::[]


[NOTE]
====
The monitoring models for bias (TrustyAI feature) is supported only on a _multi-model serving platform_ that is based on the ModelMesh component. It is not supported on a _single-model serving platform_ that is based on the KServe component.
====

ifdef::upstream[]
* You have installed {productname-short} as described in link:https://opendatahub.io/docs/quick-installation-new-operator/[Quick Installation(v2)].

* The `trustyai` component is set to *Managed* for the {productname-short} Operator.
+
To verify this setting, navigate to *Operators* -> *Installed Operators* -> *{productname-short} Operator* -> *Data Science Cluster*. Select the *default* instance and then click *YAML*. Scroll down to view the `spec:components` setting:
+
----
 trustyai:
      devFlags: {}
      managementState: Managed
----
endif::[]

ifndef::upstream[]

ifdef::self-managed[]
* You have installed {productname-short} as described in link:{rhoaidocshome}{default-format-url}/installing_and_uninstalling_{url-productname-short}/installing-and-deploying-openshift-ai_install#installing-the-openshift-data-science-operator_operator-install[Installing the {productname-long} Operator].
endif::[]

ifdef::cloud-service[]
* You have installed {productname-short} as described in link:{rhoaidocshome}{default-format-url}/installing_and_uninstalling_{url-productname-short}/installing-and-deploying-openshift-ai_install#installing-openshift-ai-managed_install[Installing OpenShift AI on your OpenShift cluster].
endif::[]

* The `trustyai` component is set to *Managed* for the {productname-long} Operator.
+
To verify this setting, navigate to *Operators* -> *Installed Operators* -> *{productname-long} Operator* -> *Data Science Cluster*. Select the *default* instance and then click *YAML*. Scroll down to view the `spec:components` setting:
+
----
 trustyai:
      devFlags: {}
      managementState: Managed
----
endif::[]
+
*NOTE:* If the `trustyai` component is set to *Removed*, edit the YAML file to set it to *Managed*.

* You have logged in to {productname-short}.

ifndef::upstream[]
* If you are using specialized {productname-short} groups, you are part of the user group or admin group (for example, {oai-user-group} or {oai-admin-group}) in OpenShift.

* The data scientist has created a data science project, as described in link:{rhoaidocshome}{default-format-url}/working_on_data_science_projects/working-on-data-science-projects_nb-server#creating-a-data-science-project_nb-server[Creating a data science project], that contains (or will contain) the models that the data scientist wants to monitor.  
endif::[]

ifdef::upstream[]
* If you are using specialized {productname-short} groups, you are part of the user group or admin group (for example, {odh-user-group} or {odh-admin-group}) in OpenShift.

* The data scientist has created a data science project, as described in link:{odhdocshome}/working_on_data_science_projects#working-on-data-science-projects_nb-server[Creating a data science project], that contains (or will contain) the models that the data scientist wants to monitor.  
endif::[]

.Procedure
. Log in to {productname-short}.
. From the {productname-short} dashboard, click *Data Science Projects*.
. In the *Data Science Projects* page, click the name of the project that contains (or will contain) the models that the data scientist wants to monitor.
. In the project details, page, click *Settings*.
. Select the *Enable model bias monitoring* checkbox.

.Verification
ifdef::upstream,self-managed[]
. In the {openshift-platform} web console, click *Workloads* → *Pods*.
endif::[]
ifdef::cloud-service[]
. In the OpenShift web console, click *Workloads* → *Pods*.
endif::[]
. From the project list, select the project namespace in which you enabled TrustyAI. 
. Confirm that there is a running pod for the TrustyAI service. The pod has a naming pattern similar to the following example:
+
----
trustyai-service-5d45b5884f-96h5z
----
