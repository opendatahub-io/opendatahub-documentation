:_module-type: PROCEDURE

[id='using-lab-tuning_{context}']
= Using LAB-tuning

[role='_abstract']

ifndef::upstream[]
[IMPORTANT]
====
ifdef::self-managed[]
LAB-tuning is currently available in {productname-long} {vernum} as a Technology Preview feature.
endif::[]
ifdef::cloud-service[]
LAB-tuning is currently available in {productname-long} as a Technology Preview feature.
endif::[]
Technology Preview features are not supported with {org-name} production service level agreements (SLAs) and might not be functionally complete.
{org-name} does not recommend using them in production.
These features provide early access to upcoming product features, enabling customers to test functionality and provide feedback during the development process.

For more information about the support scope of {org-name} Technology Preview features, see link:https://access.redhat.com/support/offerings/techpreview/[Technology Preview Features Support Scope].
====
endif::[]

To customize a model with LAB-tuning in {productname-short}, complete the following tasks:

* Register a base model from the model catalog.
* Start a LAB-tuning run from the registered model.
* Monitor the run's progress.
* Review and deploy the fine-tuned model from the registry.

== Registering a base model

To start LAB-tuning, you must first register a base model, or `LAB starter` model, that will be customized using the synthetic data generated from your taxonomy.

.Prerequisites
* You have logged in to {productname-short}.
ifndef::upstream[]
* Your cluster administrator has configured LAB-tuning in your cluster, as described in link:{rhoaidocshome}{default-format-url}/enabling_lab-tuning/index[Enabling LAB-tuning].
* You have access to an available model registry in your deployment.
* You have created your taxonomy, prepared an OCI storage location for the LAB-tuned model, created a data science project, and deployed teacher and judge models, as described in link:{rhoaidocshome}{default-format-url}/customizing_models_with_lab-tuning/preparing-lab-tuning-resources_lab-tuning[Preparing LAB-tuning resources].
endif::[]
ifdef::upstream[]
* Your cluster administrator has configured LAB-tuning in your cluster, as described in link:{odhdocshome}/customizing-models-with-lab-tuning/#enabling-lab-tuning_lab-tuning[Enabling LAB-tuning].
* You have access to an available model registry in your deployment.
* You have created your taxonomy, prepared an OCI storage location for the LAB-tuned model, created a data science project, and deployed teacher and judge models, as described in link:{odhdocshome}/customizing-models-with-lab-tuning/#preparing-lab-tuning-resources_lab-tuning[Preparing LAB-tuning resources].
endif::[]

.Procedure
. From the {productname-short} dashboard, click *Models* -> *Model catalog*.
+
The *Model catalog* page opens.
. Select a model with the `LAB starter` label.
+
The details page for the model opens.
. Click *Register model*.
+
The *Register model* page opens.
. In the *Model details* section, configure details to apply to all versions of the model:
.. In the **Model name** field, enter a name for the model.
.. Optional: In the **Model description** field, enter a description for the model.
. In the *Version details* section, enter details to apply to the first version of the model:
.. In the *Version name* field, enter a name for the model version.
.. Optional: In the *Version description* field, enter a description for the first version of the model.
.. Optional: In the *Source model format* field, enter the name of the model format.
.. Optional: In the *Source model format version* field, enter the version of the model format.
. Use the default *Model location*. 
. Click *Register model*.

.Verification
The details page for the registered base model opens.

== Starting a LAB-tuning run from the registered model

After registering a base model, you can start a LAB-tuning run to create your customized large language model (LLM). When you configure the run, you will provide the following details:

* The Git repository URL for your taxonomy.
* The URLs where the teacher and judge models are deployed and the credentials needed to access them.
* The hardware profile to use for data generation, training, and evaluation.
* Any hyperparameters to apply to the tuning process.
* The location to store the LAB-tuned model and the credentials needed to access the storage location.

.Prerequisites
* You have logged in to {productname-short}.
ifndef::upstream[]
* Your cluster administrator has configured LAB-tuning in your cluster, as described in link:{rhoaidocshome}{default-format-url}/enabling_lab-tuning/index[Enabling LAB-tuning].
* You have access to an available model registry in your deployment.
* You have created your taxonomy, prepared an OCI storage location for the LAB-tuned model, created a data science project, and deployed teacher and judge models, as described in link:{rhoaidocshome}{default-format-url}/customizing_models_with_lab-tuning/preparing-lab-tuning-resources_lab-tuning[Preparing LAB-tuning resources].
* You have registered a base model with the `LAB starter` label from the model catalog, as described in link:{rhoaidocshome}{default-format-url}/customizing_models_with_lab-tuning/using-lab-tuning_lab-tuning#registering_a_base_model[Registering a base model].
endif::[]
ifdef::upstream[]
* Your cluster administrator has configured LAB-tuning in your cluster, as described in link:{odhdocshome}/customizing-models-with-lab-tuning/#enabling-lab-tuning_lab-tuning[Enabling LAB-tuning].
* You have access to an available model registry in your deployment.
* You have created your taxonomy, prepared an OCI storage location for the LAB-tuned model, created a data science project, and deployed teacher and judge models, as described in link:{odhdocshome}/customizing-models-with-lab-tuning/#preparing-lab-tuning-resources_lab-tuning[Preparing LAB-tuning resources].
* You have registered a base model with the `LAB starter` label from the model catalog, as described in link:{odhdocshome}/customizing-models-with-lab-tuning/#_registering_a_base_model[Registering a base model].
endif::[]

.Procedure
. From the {productname-short} dashboard, click *Models* -> *Model registry*.
+
The *Model registry* page opens.
. Click the name of the model you registered.
+
The details page for the registered model opens.
. On the *Versions* tab of the model details page, click the name of the version you want to LAB-tune.
+
The details page for the version opens.
. Review the version details.
. Click *LAB-tune*.
+
The *Start a LAB-tuning run* dialog opens.
. Select your project from the *Data science project* drop-down list.
. Click *Continue to run details*.
+
. The *Start a LAB-tuning run* page opens.
. Review the *Project details*, *Pipeline details*, and *Base model* sections for accuracy.
. In the *Taxonomy details* section, enter your *Taxonomy GIT URL*. 
. If your Git repository requires authentication, select either the *SSH key* or *Username and token* method and enter the appropriate credentials.
. In the *LAB teacher model* and *LAB judge model* sections, configure the following settings:
.. Select *Authenticated endpoint* if your model requires token authentication, otherwise select *Unauthenticated endpoint*. 
.. Enter the *Endpoint* ending with `/v1`. For example: `https://mixtral-my-project.apps.my-cluster.com/v1`
+
[TIP]
====
To find authentication details for your judge and teacher models, go to the *Models* tab of your data science project. For *Endpoint* and *Model name*, click *Internal and external endpoint details* for your model. For *Token*, expand the section for your model and find the *Token authentication* section.
====
.. Enter the *Model name*. 
.. If authenticated, enter the *Token*.
. In the *Training hardware* section, configure the following settings:
.. For *Hardware profile*, select a hardware profile to match the hardware requirements of your workload to available node resources. 
.. For *Training nodes*, enter the total number of nodes to use for the run. One node is used for the evaluation run phase.
.. For *Storage class*, select a storage class that is compatible with LAB-tuning and distributed training.
. Optional: In the *Hyperparameters* section, configure advanced settings for the run.
. In the *Fine-tuned model details* section, configure settings for the fine-tuned version of the base model:
.. For *Model output storage location*, select an *Existing connection* location to store the fine-tuned model output, or select *Create connection* to create a new connection.
.. For *OCI storage location* field, enter the full *Model URI* where the LAB-tuned model will be stored. For example: `oci://quay.io/my-org/fine-tuned-model-name:version`
+
The value of the URI is different from the connection. The connection provides access, while the URI defines the specific location.
. Select the *Add model to registry* checkbox so that you can store, share, version, and deploy the LAB-tuned model in the model registry.
.. For *Model version name*, enter a name for the new LAB-tuned model version.
. Click *Start run*.

.Verification
* The *Runs* page opens for the pipeline version.

== Monitoring your LAB-tuning run

To monitor the status of your LAB-tuning run, follow these steps:

. From the {productname-short} dashboard, click *Data science pipelines* -> *Runs*. 
. Select your project from the *Project* list. 
ifndef::upstream[]
. Check the status for the run. For more information, see link:{rhoaidocshome}{default-format-url}/working_with_data_science_pipelines/managing-pipeline-runs_ds-pipelines#viewing-active-pipeline-runs_ds-pipelines[Viewing active pipeline runs].
. When the status is `Succeeded`, click the name of the run to view the pipeline graph and details. For more information, see link:{rhoaidocshome}{default-format-url}/working_with_data_science_pipelines/managing-data-science-pipelines_ds-pipelines#viewing-the-details-of-a-pipeline-version_ds-pipelines[Viewing the details of a pipeline version].
endif::[]
ifdef::upstream[]
. Check the status for the run. For more information, see link:{odhdocshome}/working-with-data-science-pipelines/#viewing-active-pipeline-runs_ds-pipelines[Viewing active pipeline runs].
. When the status is `Succeeded`, click the name of the run to view the pipeline graph and details. For more information, see link:{odhdocshome}/working-with-data-science-pipelines/#viewing-the-details-of-a-pipeline-version_ds-pipelines[Viewing the details of a pipeline version].
endif::[]

== Reviewing and deploying your LAB-tuned model

When the pipeline run is finished, your LAB-tuned model is available in the storage location that you specified during the LAB-tune run configuration.

If you selected *Add model to registry* when you configured the run, the LAB-tuned model is in the model registry as a new version of the registered base model. 

To view and deploy your LAB-tuned model from the model registry, follow these steps:

. From the {productname-short} dashboard, click *Models* > *Model registry*.
+
The *Model registry* page opens.
. Click the name of the base model you registered.
+
The details page for the registered model opens.
. On the *Versions* tab of the model details page, click the name of the new version.
+
The details page for the version opens.
. To deploy the LAB-tuned model, click *Deploy*.

