:_module-type: PROCEDURE

ifdef::context[:parent-context: {context}]
[id="configuring-regex-guardrails-gateway_{context}"]
= Configuring the regex detector and guardrails gateway
[role='_abstract']

The regex detector and guardrails gateway are sidecar containers that you can deploy with the `GuardrailsOrchestrator` service, either individually or together. Use the `GuardrailsOrchestrator` custom resource (CR) to enable them.

.Prerequisites
* You have cluster administrator privileges for your {openshift-platform} cluster.
* You have downloaded and installed the {openshift-platform} command-line interface (CLI). For more information, see link:https://docs.redhat.com/en/documentation/openshift_container_platform/{ocp-latest-version}/html/cli_tools/openshift-cli-oc[Installing the OpenShift CLI^].
* You are familiar with how to create a `ConfigMap` for monitoring a user-defined workflow. You perform similar steps in this procedure. For more information, see link:https://docs.redhat.com/en/documentation/openshift_container_platform/{ocp-latest-version}/html-single/nodes/index#nodes-pods-configmap-overview_configmaps[Understanding config maps].

ifdef::upstream[]
* You have configured KServe to use `RawDeployment` mode. For more information, see link:{odhdocshome}/serving_models/#deploying-models-on-the-single-model-serving-platform_serving-large-models[Deploying models on the single-model serving platform^].
endif::[]

ifndef::upstream[]
* You have configured KServe to use `RawDeployment` mode. For more information, see link:{rhoaidocshome}{default-format-url}/serving_models/serving-large-models_serving-large-models#deploying-models-on-the-single-model-serving-platform_serving-large-models[Deploying models on the single-model serving platform^].
endif::[]

* You have the TrustyAI component in your {productname-short} `DataScienceCluster` set to `Managed`.
* You have a large language model (LLM) for chat generation or text classification, or both, deployed in your namespace.  

.Procedure

. Define a `ConfigMap` object in a YAML file to specify the `regexDetectorImage`. For example, create a YAML file called `regex_image_cm.yaml` with the following content:
+
.Example `regex_gateway_images_cm.yaml`
[source,yaml]
----
apiVersion: v1
kind: ConfigMap
metadata:
  name: gorch-regex-gateway-image-config
data:
  regexDetectorImage: 'quay.io/repository/trustyai/regex-detector@sha256:efab6cd8b637b9c35d311aaf639dfedee7d28de3ee07b412ab473deadecd3606'            <1>
  GatewayImage: 'quay.io/repository/trustyai/vllm-orchestrator-gateway@sha256:c511b386d61a728acdfe8a1ac7a16b3774d072dd053718e5b9c5fab0f025ac3b' <2>
----
<1> The regex detector is a sidecar image that provides regex-based detections.
<2> The guardrails gateway is a sidecar image that emulates the vLLM chat completions API and saves preset detector configurations.

. Deploy the `regex_gateway_images_cm.yaml` config map:
+
[source,terminal]
----
$ oc apply -f regex_gateway_images_cm.yaml -n <TEST_NAMESPACE>
----

. Define the guardrails gateway `ConfigMap` object to specify the `detectors` and `routes`. For example, create a YAML file called `detectors_cm.yaml` with the following contents:
+
.Example `detectors_cm.yaml`
[source,yaml]
----
kind: ConfigMap
apiVersion: v1
metadata:
  name: fms-orchestr8-config-gateway
  labels:
    app: fmstack-nlp
data:
  config.yaml: |
    orchestrator:   <1>
      host: "localhost"
      port: 8032
    detectors:      <2>
      - name: regex_language
        input: true <3>
        output: true
        detector_params:
          regex:
            - email
            - ssn
      - name: hap
        detector_params: {}
    routes:         <4>
      - name: all
        detectors:
          - regex_language
          - hap
      - name: passthrough
        detectors:
----
<1> The orchestrator service.
<2> A list of preconfigured regular expressions for common detection actions. These regular expressions detect personal identifying information, `email` and `ssn`.
<3> The detector will be used for both input and output. 
<4> The resulting endpoints for the  detectors. For example, `pii` is served at `$GUARDRAILS_GATEWAY_URL/pii/v1/chat/completions` and uses the `regex` detector. The `passthrough` preset does not use any detectors.

. Deploy the guardrails gateway `detectors_cm.yaml` config map:
+
[source,terminal]
----
$ oc apply -f detectors_cm.yaml -n <TEST_NAMESPACE>
----

. Specify the `ConfigMap` objects you created in the `GuardrailsOrchestrator` custom resource(CR). For example, create a YAML file named `orchestrator_cr.yaml` with the following contents:
+
.Example `orchestrator_cr.yaml` CR
[source,yaml]
----
apiVersion: trustyai.opendatahub.io/v1alpha1
kind: GuardrailsOrchestrator
metadata:
  name: gorch-sample
spec:
  orchestratorConfig: "fms-orchestr8-config-nlp"   
  enableBuiltInDetectors: True  <1>
  enableGuardrailsGateway: True  <2>
  guardrailsGatewayConfig: "fms-orchestr8-config-gateway" <3>
  replicas: 1
----
<1> The `enableBuiltInDetectors`, if set to `True`, injects regex detectors as a sidecar container into the orchestrator pod.
<2> The `enableGuardrailsGateway`, if set to `True`, injects the guardrails gateway as a sidecar container into the orchestrator pod.
<3> The `guardrailsGatewayConfig` field specifies a `ConfigMap` that reroutes the orchestrator and regex detector routes to specific paths.
	
. Deploy the orchestrator custom resource. This creates a service account, deployment, service, and route object in your namespace.
+
[source,terminal]
----
oc apply -f orchestrator_cr.yaml -n <TEST_NAMESPACE>
----

.Verification
. Check the health of the orchestrator pod by using the `/info` endpoint of the orchestrator:
+
[source,terminal]
----
GORCH_ROUTE=$(oc get routes guardrails-orchestrator-health -o jsonpath='{.spec.host}')
curl -s https://$GORCH_ROUTE/info | jq
----
+
.Example response
[source,terminal]
----
{
  "services": {
    "chat_generation": {
      "status": "HEALTHY"
    },
    "regex": {
      "status": "HEALTHY"
    }
  }
}
----
+
In this example namespace, the Guardrails Orchestrator coordinates requests from the `regex` detector, over a single `chat_generation` LLM.
