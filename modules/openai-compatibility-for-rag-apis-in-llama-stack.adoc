:module-type: CONCEPT
[id="openai-compatibility-for-rag-apis-in-llama-stack_{context}"]
= OpenAI compatibility for RAG APIs in Llama Stack

[role="_abstract"]
{productname-short} supports OpenAI-compatible request and response schemas for Llama Stack RAG workflows. You can use OpenAI clients and schemas for files, vector stores, and the Responses API to implement retrieval-augmented generation end-to-end.

OpenAI compatibility enables the following capabilities:

* You can use OpenAI SDKs and tools with Llama Stack by configuring the client `base_url` to point to the Llama Stack service endpoint.
* You can manage files and vector stores by using OpenAI-compatible endpoints. 
* You can invoke RAG workflows by using the Responses API with vector store-backed file search.

[role="_additional-resources"]
.Additional resources
* link:https://llamastack.github.io/docs/providers/openai[OpenAI API Compatibility]
* link:https://platform.openai.com/docs/api-reference/introduction[OpenAI API Reference]
* link:https://github.com/llamastack/llama-stack-client-python/blob/main/api.md[llama-stack-client-python]