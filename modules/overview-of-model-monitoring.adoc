:_module-type: CONCEPT

[id='overview-of-model-monitoring_{context}']
= Overview of model monitoring

[role='_abstract']

ifndef::upstream[]
[IMPORTANT]
====
ifdef::self-managed[]
Model monitoring (the TrustyAI feature) is currently available in {productname-long} {vernum} as a Technology Preview feature.
endif::[]
ifdef::cloud-service[]
Model monitoring (the TrustyAI feature) is currently available in {productname-long} as a Technology Preview feature.
endif::[]
Technology Preview features are not supported with {org-name} production service level agreements (SLAs) and might not be functionally complete.
{org-name} does not recommend using them in production.
These features provide early access to upcoming product features, enabling customers to test functionality and provide feedback during the development process.

For more information about the support scope of {org-name} Technology Preview features, see link:https://access.redhat.com/support/offerings/techpreview/[Technology Preview Features Support Scope].
====
endif::[]

To ensure that machine-learning models are transparent, fair, and reliable, data scientists can use the TrustyAI feature in {productname-short} to monitor their data science models.

Data scientists can monitor their data science models in {productname-short} for the following:

ifdef::upstream[]
Bias::
Check for unfair patterns or biases in data and model predictions to ensure your model's decisions are fair and unbiased.
endif::[]

Data drift::
Detect changes in data over time by comparing current real-world data to the original training data. This helps identify shifts or deviations that could impact model performance, ensuring the model remains accurate and reliable.

Explainability::
Understand how your model makes its predictions and decisions.
