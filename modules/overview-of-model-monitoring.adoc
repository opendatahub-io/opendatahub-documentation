:_module-type: CONCEPT

[id='overview-of-model-monitoring_{context}']
= Overview of model monitoring

[role='_abstract']

ifndef::upstream[]
[IMPORTANT]
====
ifdef::self-managed[]
Model monitoring with TrustyAI is currently available in {productname-long} {vernum} as a Technology Preview feature.
endif::[]
ifdef::cloud-service[]
Model monitoring with TrustyAI is currently available in {productname-long} as a Technology Preview feature.
endif::[]
Technology Preview features are not supported with {org-name} production service level agreements (SLAs) and might not be functionally complete.
{org-name} does not recommend using them in production.
These features provide early access to upcoming product features, enabling customers to test functionality and provide feedback during the development process.

For more information about the support scope of {org-name} Technology Preview features, see link:https://access.redhat.com/support/offerings/techpreview/[Technology Preview Features Support Scope].
====
endif::[]

To ensure that machine-learning models are transparent, fair, and reliable, data scientists can use TrustyAI in {productname-short} to monitor their data science models.

Data scientists can monitor their data science models in {productname-short} for the following metrics:

Bias::
Check for unfair patterns or biases in data and model predictions to ensure your model's decisions are unbiased.

Data drift::
Detect changes in input data distributions over time by comparing the latest real-world data to the original training data. Comparing the data identifies shifts or deviations that could impact model performance, ensuring the model remains accurate and reliable.

Explainability::
Understand how your model makes its predictions and decisions.
