:_module-type: PROCEDURE

[id="viewing-metrics-for-the-single-model-serving-platform_{context}"]
= Viewing model-serving runtime metrics for the single-model serving platform

[role="_abstract"]
When a cluster administrator has configured monitoring for the single-model serving platform, non-admin users can use the OpenShift web console to view model-serving runtime metrics for the KServe component. 

.Prerequisites
ifdef::self-managed[]
* A cluster administrator has configured monitoring for the single-model serving platform.
* You have been link:https://docs.openshift.com/container-platform/{ocp-latest-version}/monitoring/enabling-monitoring-for-user-defined-projects.html#granting-users-permission-to-monitor-user-defined-projects_enabling-monitoring-for-user-defined-projects[assigned^] the `monitoring-rules-view` role.
* You are familiar with how to link:https://access.redhat.com/documentation/en-us/openshift_container_platform/{ocp-latest-version}/html/building_applications/odc-monitoring-project-and-application-metrics-using-developer-perspective#odc-monitoring-your-project-metrics_monitoring-project-and-application-metrics-using-developer-perspective[monitor project metrics^] in the {openshift-platform} web console.
endif::[]
ifdef::cloud-service[]
* You have access to the OpenShift cluster as a developer or as a user with view permissions for the project that you are viewing metrics for.
* You are familiar with querying metrics in user-defined projects. See link:https://docs.openshift.com/dedicated/observability/monitoring/managing-metrics.html#querying-metrics-for-user-defined-projects-as-a-developer_managing-metrics[Querying metrics for user-defined projects as a developer^] (Red Hat OpenShift Dedicated) or link:https://docs.openshift.com/rosa/observability/monitoring/managing-metrics.html#querying-metrics-for-user-defined-projects-as-a-developer_managing-metrics[Querying metrics for user-defined projects as a developer^] (Red Hat OpenShift Service on AWS).
endif::[]

.Procedure
ifdef::self-managed[]
. Log in to the {openshift-platform} web console.
endif::[]
ifdef::cloud-service[]
. Log in to the OpenShift web console.
endif::[]
. Switch to the *Developer* perspective.
. In the left menu, click *Observe*.
ifdef::upstream,self-managed[]
. As described in link:https://access.redhat.com/documentation/en-us/openshift_container_platform/{ocp-latest-version}/html/building_applications/odc-monitoring-project-and-application-metrics-using-developer-perspective#odc-monitoring-your-project-metrics_monitoring-project-and-application-metrics-using-developer-perspective[monitoring project metrics^], use the web console to run queries for `caikit_*`, `tgi_*`, `ovms_*` and `vllm:*` model-serving runtime metrics. You can also run queries for `istio_*` metrics that are related to OpenShift Service Mesh.
.. For example, you can check the number of successful inference requests over a period of time for a model deployed with the vLLM runtime, using the following query:
+
[source,subs="+quotes"]
----
sum(increase(vllm:request_success_total{namespace='${namespace}',model_name='${model_name}'}[${rate_interval}]))
----

.. Similarly, you can also check the number of successful inference requests over a period of time for a model deployed with the TGIS runtime, using the following query:
+
[source,subs="+quotes"]
----
sum(increase(tgi_request_success{namespace=${namespace}, pod=~'${model_name}-predictor-.*'}[${rate_interval}]))
----

endif::[]
ifdef::cloud-service[]
. As described in link:https://docs.openshift.com/dedicated/observability/monitoring/managing-metrics.html#querying-metrics-for-user-defined-projects-as-a-developer_managing-metrics[Querying metrics for user-defined projects as a developer^] (Red Hat OpenShift Dedicated) or link:https://docs.openshift.com/rosa/observability/monitoring/managing-metrics.html#querying-metrics-for-user-defined-projects-as-a-developer_managing-metrics[Querying metrics for user-defined projects as a developer^] (Red Hat OpenShift Service on AWS), use the web console to run queries for `caikit_*`, `tgi_*`, `ovms_*` and `vLLM:*` model-serving runtime metrics. You can also run queries for `istio_*` metrics that are related to OpenShift Service Mesh. A few example queries are listed below:
.. You can check the number of successful inference requests over a period of time for a model deployed with the vLLM runtime, using the following query:
+
[source,subs="+quotes"]
----
sum(increase(vllm:request_success_total{namespace='${namespace}',model_name='${model_name}'}[${rate_interval}]))
----

.. You can also check the number of successful inference requests over a period of time for a model deployed with the TGIS runtime, using the following query:
+
[source,subs="+quotes"]
----
sum(increase(tgi_request_success{namespace=${namespace}, pod=~'${model_name}-predictor-.*'}[${rate_interval}]))
----

endif::[]

[role="_additional-resources"]
.Additional resources
* link:https://docs.openvino.ai/2024/ovms_docs_metrics.html#available-metrics-families[OVMS metrics^]
* link:https://github.com/IBM/text-generation-inference?tab=readme-ov-file#metrics[TGIS metrics^]
* link:https://docs.vllm.ai/en/v0.3.3/serving/metrics.html[vLLM metrics^]
