:_module-type: PROCEDURE

[id="viewing-metrics-for-the-single-model-serving-platform_{context}"]
= Viewing model-serving runtime metrics for the single-model serving platform

[role="_abstract"]
When a cluster administrator has configured monitoring for the single-model serving platform, non-admin users can use the OpenShift web console to view model-serving runtime metrics for the KServe component. 

.Prerequisites
ifdef::self-managed[]
* A cluster administrator has configured monitoring for the single-model serving platform.
* You have been assigned the `monitoring-rules-view` role. For more information, see link:https://docs.redhat.com/en/documentation/openshift_container_platform/{ocp-latest-version}/html/monitoring/enabling-monitoring-for-user-defined-projects#granting-users-permission-to-configure-monitoring-for-user-defined-projects_enabling-monitoring-for-user-defined-projects[Granting users permission to configure monitoring for user-defined projects^].
* You are familiar with how to monitor project metrics in the {openshift-platform} web console. For more information, see 
link:https://docs.redhat.com/en/documentation/openshift_container_platform/{ocp-latest-version}/html/building_applications/odc-monitoring-project-and-application-metrics-using-developer-perspective#odc-monitoring-your-project-metrics_monitoring-project-and-application-metrics-using-developer-perspective[Monitoring your project metrics^]. 
endif::[]
ifdef::cloud-service[]
* You have access to the OpenShift cluster as a developer or as a user with view permissions for the project that you are viewing metrics for.
* You are familiar with querying metrics in user-defined projects. See link:https://docs.redhat.com/en/documentation/openshift_dedicated/{osd-latest-version}/html-single/building_applications/index#odc-monitoring-project-and-application-metrics-using-developer-perspective[Monitoring project and application metrics using the Developer perspective in Red Hat OpenShift Dedicated^] or link:https://docs.redhat.com/en/documentation/red_hat_openshift_service_on_aws/{rosa-latest-version}/html/building_applications/odc-monitoring-project-and-application-metrics-using-developer-perspective[Monitoring project and application metrics using the Developer perspective in Red Hat OpenShift Service on AWS^].
endif::[]

.Procedure
. Log in to the {openshift-platform} web console.
. Switch to the *Developer* perspective.
. In the left menu, click *Observe*.
ifdef::upstream,self-managed[]
. As described in link:https://docs.redhat.com/en/documentation/openshift_container_platform/{ocp-latest-version}/html/building_applications/odc-monitoring-project-and-application-metrics-using-developer-perspective#odc-monitoring-your-project-metrics_monitoring-project-and-application-metrics-using-developer-perspective[Monitoring your project metrics^], use the web console to run queries for model-serving runtime metrics. You can also run queries for metrics that are related to OpenShift Service Mesh. Some examples are shown.
.. The following query displays the number of successful inference requests over a period of time for a model deployed with the vLLM runtime:
+
[source,subs="+quotes"]
----
sum(increase(vllm:request_success_total{namespace='${namespace}',model_name='${model_name}'}[${rate_interval}]))
----
+
[NOTE]
--
Certain vLLM metrics are available only after an inference request is processed by a deployed model. To generate and view these metrics, you must first make an inference request to the model.
--
.. The following query displays the number of successful inference requests over a period of time for a model deployed with the standalone TGIS runtime:
+
[source,subs="+quotes"]
----
sum(increase(tgi_request_success{namespace=${namespace}, pod=~'${model_name}-predictor-.*'}[${rate_interval}]))
----

.. The following query displays the number of successful inference requests over a period of time for a model deployed with the Caikit Standalone runtime:
+
[source,subs="+quotes"]
----
sum(increase(predict_rpc_count_total{namespace='${namespace}',code='OK',model_id='${model_name}'}[${rate_interval}]))
----

.. The following query displays the number of successful inference requests over a period of time for a model deployed with the OpenVINO Model Server runtime:
+
[source,subs="+quotes"]
----
sum(increase(ovms_requests_success{namespace='${namespace}',name='${model_name}'}[${rate_interval}]))
----

endif::[]
ifdef::cloud-service[]
. As described in link:https://docs.redhat.com/en/documentation/openshift_dedicated/{osd-latest-version}/html/building_applications/odc-monitoring-project-and-application-metrics-using-developer-perspective#odc-monitoring-your-project-metrics_monitoring-project-and-application-metrics-using-developer-perspective[Monitoring your project metrics in Red Hat OpenShift Dedicated^] or link:https://docs.redhat.com/en/documentation/red_hat_openshift_service_on_aws/{rosa-latest-version}/html/building_applications/odc-monitoring-project-and-application-metrics-using-developer-perspective#odc-monitoring-your-project-metrics_monitoring-project-and-application-metrics-using-developer-perspective[Monitoring your project metrics in Red Hat OpenShift Service on AWS^], use the web console to run queries for `caikit_*`, `tgi_*`, `ovms_*` and `vllm:*` model-serving runtime metrics. You can also run queries for `istio_*` metrics that are related to OpenShift Service Mesh. Some examples are shown.
.. The following query displays the number of successful inference requests over a period of time for a model deployed with the vLLM runtime:
+
[source,subs="+quotes"]
----
sum(increase(vllm:request_success_total{namespace='${namespace}',model_name='${model_name}'}[${rate_interval}]))
----

.. The following query displays the number of successful inference requests over a period of time for a model deployed with the standalone TGIS runtime:
+
[source,subs="+quotes"]
----
sum(increase(tgi_request_success{namespace=${namespace}, pod=~'${model_name}-predictor-.*'}[${rate_interval}]))
----

.. The following query displays the number of successful inference requests over a period of time for a model deployed with the Caikit Standalone runtime:
+
[source,subs="+quotes"]
----
sum(increase(predict_rpc_count_total{namespace='${namespace}',code='OK',model_id='${model_name}'}[${rate_interval}]))
----

.. The following query displays the number of successful inference requests over a period of time for a model deployed with the OpenVINO Model Server runtime:
+
[source,subs="+quotes"]
----
sum(increase(ovms_requests_success{namespace='${namespace}',name='${model_name}'}[${rate_interval}]))
----

endif::[]

[role="_additional-resources"]
.Additional resources
* link:https://docs.openvino.ai/2024/ovms_docs_metrics.html#available-metrics-families[OVMS metrics^]
* link:https://github.com/IBM/text-generation-inference?tab=readme-ov-file#metrics[TGIS metrics^]
* link:https://docs.vllm.ai/en/latest/serving/metrics.html[vLLM metrics^]
