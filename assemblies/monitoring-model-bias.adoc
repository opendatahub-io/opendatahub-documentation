:_module-type: ASSEMBLY

ifdef::context[:parent-context: {context}]

:context: bias-monitoring

[id="monitoring-model-bias_{context}"]
= Monitoring model bias

[role='_abstract']

As a data scientist or machine learning engineer, you can monitor your models for bias, such as algorithmic deficiencies that might skew the outcomes or decisions that the model produces. This type of monitoring can help ensure that the model is not biased against features like particular specific groups of people or personal traits.

{productname-long} provides a set of metrics that help you to monitor your models for bias. You can use the {productname-short} interface to choose an available metric and then configure model-specific details such as a protected attribute, the privileged and unprivileged groups, the outcome you want to monitor, and a threshold for bias. You then see a chart of the calculated values for a specified number of model inferences.

For more information about the specific bias metrics, see link:https://opendatahub.io/docs/monitoring-data-science-models/#using-bias-metrics_bias-monitoring[Using bias metrics].

include::modules/creating-a-bias-metric.adoc[leveloffset=+1]

include::modules/duplicating-a-bias-metric.adoc[leveloffset=+2]

include::modules/deleting-a-bias-metric.adoc[leveloffset=+1]

include::modules/viewing-bias-metrics.adoc[leveloffset=+1]

include::modules/using-bias-metrics.adoc[leveloffset=+1]

ifdef::parent-context[:context: {parent-context}]
ifndef::parent-context[:!context:]
