:_module-type: ASSEMBLY

ifdef::context[:parent-context: {context}]

[id="llama-stack-adv-examples_{context}"]
= Llama Stack application examples

Llama Stack allows you to create AI-driven applications in your {productname-short} cluster. Llama Stack includes a default `run.yaml` file that enables the APIs to expose backend provider configurations. You can update and customize this `run.yaml` and create a ConfigMap that uses the `run.yaml` configurations.

The following documentation includes various example applications you can deploy, including:

* Deploying a RAG stack in a data science project.
* Evaluating RAG systems with Llama Stack.
* Configuring Llama Stack with OAuth authentication.

include::../assemblies/deploying-a-rag-stack-in-a-project.adoc[leveloffset=+1]
include::../assemblies/evaluating-rag-systems-with-llama-stack.adoc[leveloffset=+1]
include::../assemblies/using-postgresql-in-llama-stack.adoc[leveloffset=+1]
include::../modules/auth-on-llama-stack.adoc[leveloffset=+1]
include::../modules/llama-stack-high-avail-and-auto.adoc[leveloffset=+1]

ifdef::parent-context[:context: {parent-context}]
ifndef::parent-context[:!context:]