:_module-type: ASSEMBLY

ifdef::context[:parent-context: {context}]
[id="enabling-ai-safety_{context}"]
= Enabling AI safety

The TrustyAI Guardrails Orchestrator service is a tool to invoke detections on text generation inputs and outputs, as well as standalone detections.

It is underpinned by the open-source project link:https://github.com/foundation-model-stack/fms-guardrails-orchestrator[FMS-Guardrails Orchestrator] from IBM. You can deploy the Guardrails Orchestrator service through a Custom Resource Definition (CRD) that is managed by the TrustyAI Operator.

The following sections describe the Guardrails components, how to deploy them and provide example use cases of how to protect your AI applications using these tools:

Deploy a Guardrails Orchestrator instance:: 
The guardrails orchestrator is the main networking layer of the guardrails ecosystem, and “orchestrates” the network requests between the user, generative models, and detector servers. 

Configure and use the built-in detectors:: 
The Guardrails framework provides a set of “built-in” detectors out-of-the-box, that provides a number of simple detection algorithms. You can use the following detector with `trustyai_fms` orchestrator server, which is an external provider for Llama Stack that allows you to configure and use the Guardrails Orchestrator and compatible detection models through the Llama Stack API.:
+
* *Regex Detectors*: Pattern-based content detection for structured rule enforcement. These are the built-in detectors in the Guardrails Orchestrator service. Learn more about the link:https://github.com/trustyai-explainability/guardrails-regex-detector[guardrails-regex-detector].


Use Hugging Face models as detectors in Guardrails Orchestrator::
Any text classification model from link:https://huggingface.co/ibm-granite/granite-guardian-hap-38m[Huggingface] can be used as a detector model within the Guardrails ecosystem.
+
* *Hugging Face Detectors*: Compatible with most Hugging Face `AutoModelForSequenceClassification` models, such as `granite-guardian-hap-38m` or `deberta-v3-base-prompt-injection-v2`. Learn more about the detector algorithms for the link:https://github.com/trustyai-explainability/guardrails-detectors[FMS Guardrails Orchestrator].
* *vLLM Detector Adapter*: Content detection compatible with Hugging Face `AutoModelForCausalLM` models, for example `ibm-granite/granite-guardian-3.1-2b`. Learn more about link:https://github.com/foundation-model-stack/vllm-detector-adapter[vllm-detector-adapter].

Configure and use the guardrails gateway:: 
The optional Guardrails Gateway lets you create preset guardrailing pipelines that can be interacted with via /chat/completions endpoints.

*Monitor user-inputs to your LLM* 
Enable a safer LLM by filtering hateful, profane, or toxic inputs.

*Enable the OpenTelemetry exporter for metrics and tracing* 
Provide observability for the security and governance mechanisms of AI applications.

== Deploying and configuring Guardrails components
Set up the Orchestrator, Detectors, and Gateway. 

include::modules/deploying-the-guardrails-orchestrator-service.adoc[leveloffset=+1]
include::modules/auto-configuring-guardrails.adoc[leveloffset=+1]
include::modules/guardrails-orchestrator-parameters.adoc[leveloffset=+1]
include::modules/guardrails-detectors.adoc[leveloffset=+1]
include::modules/configuring-the-built-in-detector-and-guardrails-gateway.adoc[leveloffset=+1]
[role='_additional-resources']
.Additional resources
ifndef::upstream[]
* To learn how to use the built-in detectors with `trustyai_fms` orchestrator server external provider for Llama Stack to detect PII, see link:{rhoaidocshome}{default-format-url}/monitoring_data_science_models#detecting-pii-by-using-guardrails-with-llama-stack_[Adding a model server to your data science project].
endif::[]

include::modules/configuring-the-guardrails-detector-hugging-face-serving-runtime.adoc[leveloffset=+1]
include::modules/using-hugging-face-models-with-guardrails-orchestrator.adoc[leveloffset=+1]
include::modules/configuring-the-opentelemetry-exporter.adoc[leveloffset=+1]


ifdef::parent-context[:context: {parent-context}]
ifndef::parent-context[:!context:]
